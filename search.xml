<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[文件系统接口]]></title>
    <url>%2F2019%2F06%2F13%2F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[文件管理主要内容： 文件系统基础：包括文件概念、文件的逻辑结构（顺序文件，索引文件，索引顺序文件）、目录结构（文件控制块和索引结点，单级目录结构和两级目录结构，树形目录结构，图形目录结构）、文件共享和文件保护（访问类型，访问控制）。 文件系统实现：包括文件系统层次结构、目录实现、文件实现。 磁盘组织与管理：包括磁盘的结构、磁盘调度算法、磁盘的管理。 文件的概念和定义文件(File)是操作系统中的一个重要概念。在系统运行时，计算机以进程为基本单位进行资源的调度和分配；而在用户进行的输入、输出中，则以文件为基本单位。大多数应用程序的输入都是通过文件来实现的，其输出也都保存在文件中，以便信息的长期存及将来的访问。当用户将文件用于应用程序的输入、输出时，还希望可以访问文件、修改文件和保存文件等，实现对文件的维护管理，这就需要系统提供一个文件管理系统，操作系统中的文件系统(File System)就是用于实现用户的这些管理要求。从用户的角度看，文件系统是操作系统的重要部分之一。用户关心的是如何命名、分类和查找文件，如何保证文件数据的安全性以及对文件可以进行哪些操作等。而对其中的细节，如文件如何存储在辅存上、如何管理文件辅存区域等关心甚少。文件系统提供了与二级存储相关的资源的抽象，让用户能在不了解文件的各种属性、文件存储介质的特征以及文件在存储介质上的具体位置等情况下，方便快捷地使用文件。 用户通过文件系统建立文件，提供应用程序的输入、输出，对资源进行管理。首先了解文件的结构，我们通过自底向上的方式来定义。 数据项数据项是文件系统中最低级的数据组织形式，可分为以下两种类型：基本数据项：用于描述一个对象的某种属性的一个值，如姓名、日期或证件号等，是数据中可命名的最小逻辑数据单位，即原子数据。组合数据项：由多个基本数据项组成。 记录记录是一组相关的数据项的集合，用于描述一个对象在某方面的属性，如一个考生报名记录包括考生姓名、出生日期、报考学校代号、身份证号等一系列域。 文件文件是指由创建者所定义的一组相关信息的集合，逻辑上可分为有结构文件和无结构文件两种。在有结构文件中，文件由一组相似记录组成，如报考某学校的所有考生的报考信息记录，又称记录式文件；而无结构文件则被看成是一个字符流，比如一个二进制文件或字符文件，又称流式文件。 虽然上面给出了结构化的表述，但实际上关于文件并无严格的定义。通常在操作系统中将程序和数据组织成文件。文件可以是数字、字母或二进制代码，基本访问单元可以是字节、 行或记录。文件可以长期存储于硬盘或其他二级存储器中,允许可控制的进程间共享访问，能够被组织成复杂的结构。 文件的属性、基本操作以及文件的打开和关闭文件的属性文件有一定的属性，这根据系统的不同而有所不同，但是通常都包括如下属性： ①名称：文件名称唯一，以容易读取的形式保存。②标识符：标识文件系统内文件的唯一标签,通常为数字，它是对人不可读的一种内部名称。③类型：被支持不同类型的文件系统所使用。④位置：指向设备和设备上文件的指针。⑤大小：文件当前大小（用字节、字或块表示），也可包含文件允许的最大值。⑥保护：对文件进行保护的访问控制信息。⑦时间、日期和用户标识：文件创建、上次修改和上次访问的相关信息，用于保护、 安全和跟踪文件的使用。 所有文件的信息都保存在目录结构中，而目录结构也保存在外存上。文件信息当需要时再调入内存。通常，目录条目包括文件名称及其唯一标识符，而标识符定位其他属性的信息。 文件的基本橾作文件属于抽象数据类型。为了恰当地定义文件，就需要考虑有关文件的操作。操作系统提供系统调用，它对文件进行创建、写、读、定位和截断。. ①创建文件：创建文件有两个必要步骤，一是在文件系统中为文件找到空间；二是在目录中为新文件创建条目，该条目记录文件名称、在文件系统中的位置及其他可能信息。②写文件：为了写文件，执行一个系统调用，指明文件名称和要写入文件的内容。对于给定文件名称，系统搜索目录以查找文件位置。系统必须为该文件维护一个写位置的指针。每当发生写操作，便更新写指针。③读文件：为了读文件，执行一个系统调用，指明文件名称和要读入文件块的内存位置。同样，需要搜索目录以找到相关目录项，系统维护一个读位置的指针。每当发生读操作时，更新读指针。一个进程通常只对一个文件读或写，所以当前操作位置可作为每个进程当前文件位置指针。由于读和写操作都使用同一指针，节省了空间也降低了系统复杂度。④文件重定位（文件寻址）：按某条件搜索目录，将当前文件位置设为给定值，并且不会读、写文件。⑤删除文件：先从目录中找到要删除文件的目录项，使之成为空项，然后回收该文件所占用的存储空间。⑥截断文件：允许文件所有属性不变，并删除文件内容，即将其长度设为0并释放其空间。 这6个基本操作可以组合执行其他文件操作。例如，一个文件的复制，可以创建新文件、 从旧文件读出并写入到新文件。 文件的打开与关闭因为许多文件操作都涉及为给定文件搜索相关目录条目，许多系统要求在首次使用文件时，使用系统调用open，将指明文件的属性（包括该文件在外存上的物理位置）从外存拷贝到内存打开文件目录表的一个表目中，并将该表目的编号（或称为索引）返回给用户。操作系统维护一个包含所有打开文件信息的表（打开文件表，open-file table）。当用户需要一个文件操作时，可通过该表的一个索引指定文件，就省略了搜索环节。当文件不再使用时，进程可以关闭它，操作系统从打开文件表中删除这一条目。 大部分操作系统要求在文件使用之前就被显式地打开。操作open会根据文件名搜索目录，并将目录条目复制到打开文件表。如果调用open的请求（创建、只读、读写、添加等）得到允许，进程就可以打开文件，而open通常返回一个指向打开文件表中的一个条目的指针。通过使用该指计（而非文件名）进行所有I/O操作，以简化步骤并节省资源。 整个系统表包含进程相关信息，如文件在磁盘的位置、访问日期和大小。一个进程打开一个文件，系统打开文件表就会为打开的文件增加相应的条目。当另一个进程执行open时，只不过是在其进程打开表中增加一个条目，并指向整个系统表的相应条目。通常，系统打开文件表的每个文件时，还用一个文件打开计数器(Open Count)，以记录多少进程打开了该文件。每个关闭操作close则使count递减，当打开计数器为0时，表示该文件不再被使用。系统将回收分配给该文件的内存空间等资源，若文件被修改过，则将文件写回外存，并将系统打开文件表中相应条目删除，最后释放文件的文件控制块(File Control Block, FCB)。 每个打开文件都有如下关联信息： 文件指针：系统跟踪上次读写位置作为当前文件位置指针，这种指针对打开文件的某个进程来说是唯一的，因此必须与磁盘文件属性分开保存。 文件打开计数：文件关闭时，操作系统必须重用其打开文件表条目，否则表内空间会不够用。因为多个进程可能打开同一个文件，所以系统在删除打开文件条目之前，必须等待最后一个进程关闭文件。该计数器跟踪打开和关闭的数量，当该计数为0 时，系统关闭文件，删除该条目。 文件磁盘位置：绝大多数文件操作都要求系统修改文件数据。该信息保存在内存中以免为每个操作都从磁盘中读取。 访问权限：每个进程打开文件都需要有一个访问模式（创建、只读、读写、添加等)。该信息保存在进程的打开文件表中以便操作系统能允许或拒绝之后的I/O请求。 文件的逻辑结构：无结构文件(流式文件)和有结构文件(记录式文件)文件的逻辑结构是从用户观点出发看到的文件的组织形式。文件的物理结构是从实现观点出发，又称为文件的存储结构，是指文件在外存上的存储组织形式。文件的逻辑结构与存储介质特性无关，但文件的物理结构与存储介质的特性有很大关系。 按逻辑结构，文件有无结构文件和有结构文件两种类型：无结构文件和有结构文件。 无结构文件（流式文件）无结构文件是最简单的文件组织形式。无结构文件将数据按顺序组织成记录并积累保存，它是有序相关信息项的集合，以字节(Byte)为单位。由于无结构文件没有结构，因而对记录的访问只能通过穷举搜索的方式，故这种文件形式对大多数应用不适用。但字符流的无结构文件管理简单，用户可以方便地对其进行操作。所以，那些对基本信息单位操作不多的文件较适于釆用字符流的无结构方式，如源程序文件、目标代码文件等。 有结构文件（记录式文件）有结构文件按记录的组织形式可以分为： 顺序文件。文件中的记录一个接一个地顺序排列，记录可以是定长的或变长的，可以顺序存储或以链表形式存储，在访问时需要顺序搜索文件。顺序文件有以下两种结构： 第一种是串结构，记录之间的顺序与关键字无关。通常的办法是由时间决定，即按存入时间的先后排列，最先存入的记录作为第1个记录，其次存入的为第2个记录，依此类推。 第二种是顺序结构，指文件中的所有记录按关键字顺序排列。 在对记录进行批量操作时，即每次要读或写一大批记录，对顺序文件的效率是所有逻辑文件中最高的；此外，也只有顺序文件才能存储在磁带上，并能有效地工作，但顺序文件对查找、修改、增加或删除单个记录的操作比较困难。 索引文件。如下图所示。对于定长记录文件，如果要查找第i个记录，可直接根据下式计算来获得第i个记录相对于第一个记录的地址： 然而，对于可变长记录的文件，要查找第i个记录时，必须顺序地查找前i-1个记录，从而获得相应记录的长度L，然后才能按下式计算出第i个记录的首址： 注意：假定每个记录前用一个字节指明该记录的长度。 索引文件示意图 变长记录文件只能顺序查找，系统开销较大。为此可以建立一张索引表以加快检索速度，索引表本身是定长记录的顺序文件。在记录很多或是访问要求高的文件中，需要引入索引以提供有效的访问。实际中，通过索引可以成百上千倍地提高访问速度。 索引顺序文件。索引顺序文件是顺序和索引两种组织形式的结合。索引顺序文件将顺序文件中的所有记录分为若干个组，为顺序文件建立一张索引表，在索引表中为每组中的第一个记录建立一个索引项，其中含有该记录的关键字值和指向该记录的指针。 如下图所示，主文件名包含姓名和其他数据项。姓名为关键字，索引表中为每组的第一个记录（不是每个记录）的关键字值，用指计指向主文件中该记录的起始位置。索引表只包含关键字和指计两个数据项，所有姓名关键字递增排列。主文件中记录分组排列，同一个组中关键字可以无序，但组与组之间关键字必须有序。查找一个记录时，通过索引表找到其所在的组，然后在该组中使用顺序查找就能很快地找到记录。 索引顺序文件示意图 对于含有N个记录的顺序文件，查找某关键字值的记录时平均需要查找N/2次。在索引顺序文件中，假设N个记录分为N1/2组，索引表中有N1/2个表项，每组有N1/2个记录，在查找某关键字值的记录时，先顺序查找索引表，需要查找N1/2/2次，然后再在主文件中对应的组中顺序查找，也需要查找N1/2/2次，这样总共查找N1/2/2+N1/2/2=N1/2次。显然，索引顺序文件提高了查找效率，如果记录数很多，可以釆用两级或多级索引。 索引文件和索引顺序文件都提高了存取的速度，但因为配置索引表而增加了存储空间。 直接文件或散列文件(Hash File)给定记录的键值或通过Hash函数转换的键值直接决定记录的物理地址。这种映射结构不同于顺序文件或索引文件，没有顺序的特性。 散列文件有很高的存取速度，但是会引起冲突，即不同关键字的散列函数值相同。 文件目录结构：单级、两级、多级(树形)和无环图目录结构与文件管理系统和文件集合相关联的是文件目录，它包含有关文件的信息，包括属性、 位置和所有权等，这些信息主要是由操作系统进行管理。首先我们来看目录管理的基本要求: 从用户的角度看，目录在用户（应用程序）所需要的文件名和文件之间提供一种映射，所以目录管理要实现“按名存取”；目录存取的效率直接影响到系统的性能，所以要提高对目录的检索速度；在共享系统中，目录还需要提供用于控制访问文件的信息。此外，文件允许重名也是用户的合理和必然要求，目录管理通过树形结构来解决和实现。 文件控制块和索引结点同进程管理一样，为实现目录管理，操作系统中引入了文件控制块的数据结构。 文件控制块。文件控制块(FCB)是用来存放控制文件需要的各种信息的数据结构，以实现“按名存取”。FCB的有序集合称为文件目录，一个FCB就是一个文件目录项。为了创建一个新文件，系统将分配一个FCB并存放在文件目录中，成为目录项。 FCB主要包含以下信息： 基本信息，如文件名、文件的物理位置、文件的逻辑结构、文件的物理结构等。 存取控制信息，如文件存取权限等。 使用信息，如文件建立时间、修改时间等。 索引结点。在检索目录文件的过程中，只用到了文件名，仅当找到一个目录项（查找文件名与目录项中文件名匹配）时，才需要从该目录项中读出该文件的物理地址。也就是说，在检索目录时，文件的其他描述信息不会用到，也不需调入内存。因此，有的系统（如UNIX，见表4-1）釆用了文件名和文件描述信息分开的方法，文件描述信息单独形成一个称为索引结点的数据结构，简称为 i 结点。在文件目录中的每个目录项仅由文件名和指向该文件所对应的i结点的指针构成。UNIX的文件目录结构 一个FCB的大小是64字节，盘块大小是1KB，则在每个盘块中可以存放16个FCB（注意，FCB必须连续存放）。而在UNIX系统中一个目录项仅占16字节，其中14字节是文件名，2字节是 i 结点指针。在1KB的盘块中可存放64个目录项。这样，可使查找文件时平均启动磁盘次数减少到原来的1/4，大大节省了系统开销。 存放在磁盘上的索引结点称为磁盘索引结点，UNIX中的每个文件都有一个唯一的磁盘索引结点，主要包括以下几个方面： 文件主标识符，拥有该文件的个人或小组的标识符。 文件类型，包括普通文件、目录文件或特别文件。 文件存取权限，各类用户对该文件的存取权限。 文件物理地址，每个索引结点中含有13个地址项，即 iaddr(0) ~ iaddr(12)，它们以直接或间接方式给出数据文件所在盘块的编号。 文件长度，以字节为单位。 文件链接计数，在本文件系统中所有指向该文件的文件名的指针计数。 文件存取时间，本文件最近被进程存取的时间、最近被修改的时间以及索引结点最‘ 近被修改的时间。 文件被打开时，磁盘索引结点复制到内存的索引结点中，以便于使用。在内存索引结点中又增加了以下内容： 索引结点编号，用于标识内存索引结点。 状态，指示i结点是否上锁或被修改。 访问计数，每当有一进程要访问此i结点时，计数加1，访问结束减1。 逻辑设备号，文件所属文件系统的逻辑设备号。 链接指针，设置分别指向空闲链表和散列队列的指针。 目录结构在理解一个文件系统的需求前，我们首先来考虑在目录这个层次上所需要执行的操作，这有助于后面文件系统的整体理解。 搜索：当用户使用一个文件时，需要搜索目录，以找到该文件的对应目录项。 创建文件：当创建一个新文件时，需要在目录中增加一个目录项。 删除文件：当删除一个文件时，需要在目录中删除相应的目录项。 显示目录：用户可以请求显示目录的内容，如显示该用户目录中的所有文件及属性。 修改目录：某些文件属性保存在目录中，因而这些属性的变化需要改变相应的目录项。 操作时，考虑以下几种目录结构： 单级目录结构。在整个文件系统中只建立一张目录表，每个文件占一个目录项，如下图所示。 单级目录结构 当访问一个文件时，先按文件名在该目录中查找到相应的FCB，经合法性检查后执行相应的操作。当建立一个新文件时，必须先检索所有目录项以确保没有“重名”的情况，然后在该目录中增设一项，把FCB的全部信息保存在该项中。当删除一个文件时，先从该目录中找到该文件的目录项，回收该文件所占用的存储空间，然后再清除该目录项。 单级目录结构实现了 “按名存取”，但是存在查找速度慢、文件不允许重名、不便于文件共享等缺点，而且对于多用户的操作系统显然是不适用的。 两级目录结构。单级目录很容易造成文件名称的混淆，可以考虑釆用两级方案，将文件目录分成主文件目录(Master File Directory, MFD)和用户文件目录（User File Directory, UFD)两级，如下图所示。 两级目录结构 主文件目录项记录用户名及相应用户文件目录所在的存储位置。用户文件目录项记录该用户文件的FCB信息。当某用户欲对其文件进行访问时，只需搜索该用户对应的UFD，这既解决了不同用户文件的“重名”问题，也在一定程度上保证了文件的安全。 两级目录结构可以解决多用户之间的文件重名问题，文件系统可以在目录上实现访问限制。但是两级目录结构缺乏灵活性，不能对文件分类。 多级目录结构（树形目录结构)。将两级目录结构的层次关系加以推广，就形成了多级目录结构，即树形目录结构，如图4-5所示。 用户要访问某个文件时用文件的路径名标识文件，文件路径名是个字符串，由从根目录出发到所找文件的通路上的所有目录名与数据文件名用分隔符链接起来而成。从根目录出发的路径称绝对路径。当层次较多时，每次从根目录查询浪费时间，于是加入了当前目录，进程对各文件的访问都是相对于当前目录进行的。当用户要访问某个文件时，使用相对路径标识文件，相对路径由从当前目录出发到所找文件通路上所有目录名与数据文件名用分隔符“/”链接而成。 树形目录结构 上图是Linux操作系统的目录结构，“/dev/hda”就是一个绝对路径。若当前目录为 “/bin”，则“./ls”就是一个相对路径，其中符号表示当前工作目录。 通常，每个用户都有各自的“当前目录”,登录后自动进入该用户的“当前目录”。操作系统提供一条专门的系统调用，供用户随时改变“当前目录”。例如，UNIX系统中， “/etc/passwd”文件就包含有用户登录时默认的“当前目录”，可用cd命令改变“当前目录”。 树形目录结构可以很方便地对文件进行分类，层次结构清晰，也能够更有效地进行文件的管理和保护。但是，在树形目录中查找一个文件，需要按路径名逐级访问中间结点，这就增加了磁盘访问次数，无疑将影响查询速度。 无环图目录结构。树形目录结构可便于实现文件分类，但不便于实现文件共享，为此在树形目录结构的基础上增加了一些指向同一结点的有向边，使整个目录成为一个有向无环图。引入无环图目录结构是为了实现文件共享，如下图所示。 当某用户要求删除一个共享结点时，若系统只是简单地将它删除，当另一共享用户需要访问时，却无法找到这个文件而发生错误。为此可以为每个共享结点设置一个共享计数器，每当图中增加对该结点的共享链时，计数器加 1;每当某用户提出删除该结点时，计数器减1。仅当共享计数器为0时，才真正删除该结点，否则仅删除请求用户的共享链。 图形目录结构 共享文件（或目录）不同于文件拷贝（副本）。如果有两个文件拷贝，每个程序员看到的是拷贝而不是原件；但如果一个文件被修改，那么另一个程序员的拷贝不会有改变。对于共享文件，只存在一个真正文件，任何改变都会为其他用户所见。 无环图目录结构方便实现了文件的共享,但使得系统的管理变得更加复杂。 共享文件：硬链接和软链接文件共享使多个用户（进程）共享同一份文件，系统中只需保留该文件的一份副本。如果系统不能提供共享功能，那么每个需要该文件的用户都要有各自的副本，会造成对存储空间的极大浪费。随着计算机技术的发展，文件共享的范围已由单机系统发展到多机系统，进而通过网络扩展到全球。这些文件的分享是通过分布式文件系统、远程文件系统、分布式信息系统实现的。这些系统允许多个客户通过C/S模型共享网络中的服务器文件。 现代常用的两种文件共享方法有： 基于索引结点的共享方式（硬链接）在树形结构的目录中，当有两个或多个用户要共享一个子目录或文件时，必须将共享文件或子目录链接到两个或多个用户的目录中，才能方便地找到该文件，如下图所示。 基于索引结点的共享方式 在这种共享方式中引用索引结点，即诸如文件的物理地址及其他的文件属性等信息，不再是放在目录项中，而是放在索引结点中。在文件目录中只设置文件名及指向相应索引结点的指针。在索引结点中还应有一个链接计数count,用于表示链接到本索引结点（亦即文件） 上的用户目录项的数目。当count=2时，表示有两个用户目录项链接到本文件上，或者说是有两个用户共享此文件。 当用户A创建一个新文件时，它便是该文件的所有者，此时将count置为1。当有用户 B要共享此文件时，在用户B的目录中增加一个目录项，并设置一指针指向该文件的索引结点。此时，文件主仍然是用户A，count=2。如果用户A不再需要此文件，不能将文件直接删除。因为，若删除了该文件，也必然删除了该文件的索引结点，这样便会便用户B的指针悬空，而用户B则可能正在此文件上执行写操作，此时用户B会无法访问到文件。因此用户A不能删除此文件，只是将该文件的count减1，然后删除自己目录中的相应目录项。用户B仍可以使用该文件。当COunt=0时，表示没有用户使用该文件，系统将负责删除该文件。如图4-8给出了用户B链接到文件上的前、后情况。 利用符号链实现文件共享（软链接）为使用户B能共享用户A的一个文件F,可以由系统创建一个LINK类型的新文件，也取名为F，并将文件F写入用户B的目录中，以实现用户B的目录与文件F的链接。在新文件中只包含被链接文件F的路径名。这样的链接方法被称为符号链接。 文件共享中的链接计数 新文件中的路径名则只被看做是符号链，当用户B要访问被链接的文件F且正要读 LINK类新文件时，操作系统根据新文件中的路径名去读该文件，从而实现了用户B对文件 F的共享。 在利用符号链方式实现文件共享时，只有文件的拥有者才拥有指向其索引结点的指针。而共享该文件的其他用户则只有该文件的路径名，并不拥有指向其索引结点的指针。这样，也就不会发生在文件主删除一共享文件后留下一悬空指针的情况。当文件的拥有者把一个共享文件删除后，其他用户通过符号链去访问它时，会出现访问失败，于是将符号链删除，此时不会产生任何影响。当然，利用符号链实现文件共享仍然存在问题，例如：一个文件釆用符号链方式共享，当文件拥有者将其删除，而在共享的其他用户使用其符号链接访问该文件之前，又有人在同一路径下创建了另一个具有同样名称的文件，则该符号链将仍然有效，但访问的文件已经改变，从而导致错误。 在符号链的共享方式中，当其他用户读共享文件时，需要根据文件路径名逐个地查找目录，直至找到该文件的索引结点。因此，每次访问时，都可能要多次地读盘，使得访问文件的开销变大并增加了启动磁盘的频率。此外，符号链的索引结点也要耗费一定的磁盘空间。符号链方式有一个很大的优点，即网络共享只需提供该文件所在机器的网络地址以及该机器中的文件路径即可。 上述两种链接方式都存在一个共同的问题，即每个共享文件都有几个文件名。换言之，每增加一条链接，就增加一个文件名。这实质上就是每个用户都使用自己的路径名去访问共享文件。当我们试图去遍历整个文件系统时，将会多次遍历到该共享文件。 硬链接和软链接都是文件系统中的静态共享方法，在文件系统中还存在着另外的共享需求，即两个进程同时对同一个文件进行操作，这样的共享可以称为动态共享。 文件保护：文件访问类型和访问控制为了防止文件共享可能会导致文件被破坏或未经核准的用户修改文件，文件系统必须控制用户对文件的存取，即解决对文件的读、写、执行的许可问题。为此，必须在文件系统中建立相应的文件保护机制。 文件保护通过口令保护、加密保护和访问控制等方式实现。其中，口令保护和加密保护是为了防止用户文件被他人存取或窃取，而访问控制则用于控制用户对文件的访问方式。 访问类型对文件的保护可以从限制对文件的访问类型中出发。可加以控制的访问类型主要有以下几种： 读：从文件中读。 写：向文件中写。 执行：将文件装入内存并执行。 添加：将新信息添加到文件结尾部分。 删除：删除文件，释放空间。 列表清单：列出文件名和文件属性。 此外还可以对文件的重命名、复制、编辑等加以控制。这些高层的功能可以通过系统程序调用低层系统调用来实现。保护可以只在低层提供。例如，复制文件可利用一系列的读请求来完成。这样，具有读访问用户同时也具有复制和打印的权限了。 访问控制解决访问控制最常用的方法是根据用户身份进行控制。而实现基于身份访问的最为普通的方法是为每个文件和目录增加一个访问控制列表(Access-Control List, ACL)，以规定每个用户名及其所允许的访问类型。 这种方法的优点是可以使用复杂的访问方法。其缺点是长度无法预期并且可能导致复杂的空间管理，使用精简的访问列表可以解决这个问题。 精简的访问列表釆用拥有者、组和其他三种用户类型。 拥有者：创建文件的用户。 组：一组需要共享文件且具有类似访问的用户。 其他：系统内的所有其他用户。 这样只需用三个域列出访问表中这三类用户的访问权限即可。文件拥有者在创建文件时，说明创建者用户名及所在的组名，系统在创建文件时也将文件主的名字、所属组名列在该文件的FCB中。用户访问该文件时，按照拥有者所拥有的权限访问文件，如果用户和拥有者在同一个用户组则按照同组权限访问，否则只能按其他用户权限访问。UNIX操作系统即釆用此种方法。 口令和密码是另外两种访问控制方法。 口令指用户在建立一个文件时提供一个口令，系统为其建立FCB时附上相应口令，同时告诉允许共享该文件的其他用户。用户请求访问时必须提供相应口令。这种方法时间和空间的开销不多，缺点是口令直接存在系统内部，不够安全。 密码指用户对文件进行加密，文件被访问时需要使用密钥。这种方法保密性强，节省了存储空间，不过编码和译码要花费一定时间。 口令和密码都是防止用户文件被他人存取或窃取，并没有控制用户对文件的访问类型。 注意两个问题： 现代操作系统常用的文件保护方法，是将访问控制列表与用户、组和其他成员访问控制方案一起组合使用。 对于多级目录结构而言，不仅需要保护单个文件，而且还需要保护子目录内的文件, 即需要提供目录保护机制。目录操作与文件操作并不相同，因此需要不同的保护机制。]]></content>
      <categories>
        <category>计算机</category>
        <category>操作系统</category>
        <category>存储管理</category>
      </categories>
      <tags>
        <tag>计算机</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[I/O管理]]></title>
    <url>%2F2019%2F06%2F13%2FI-O%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[输入输出管理本章主要内容：I/O管理概述（I/O控制方式、I/O软件层次结构）和I/O核心子系统（I/O调度概念、局速缓存与缓冲区、设备分配与回收、假脱机技术(SPOOLing)）。 I/O设备及其分类I/O设备管理是操作系统设计中最凌乱也最具挑战性的部分。由于它包含了很多领域的不同设备以及与设备相关的应用程序，因此很难有一个通用且一致的设计方案。所以在理解设备管理之前，应该先了解具体的I/O设备类型。 计算机系统中的I/O设备按使用特性可分为以下类型： 人机交互类外部设备：用于同计算机用户之间交互的设备，如打印机、显示器、鼠标、键盘等。这类设备数据交换速度相对较慢，通常是以字节为单位进行数据交换。 存储设备：用于存储程序和数据的设备，如磁盘、磁带、光盘等。这类设备用于数据交换，速度较快，通常以多字节组成的块为单位进行数据交换。 网络通信设备：用于与远程设备通信的设备，如各种网络接口、调制解调器等。其速度介于前两类设备之间。网络通信设备在使用和管理上与前两类设备也有很大不同。 除了上面最常见的分类方法，I/O设备还可以按以下方法分类： 按传输速率分类： 低速设备：传输速率仅为每秒几个到数百个字节的一类设备，如键盘、鼠标等。 中速设备：传输速率在每秒数千个字节至数万个字节的一类设备，如行式打印机、 激光打印机等。 高速设备：传输速率在数百个千字节至千兆字节的一类设备，如磁带机、磁盘机、 光盘机等。 按信息交换的单位分类： 块设备：由于信息的存取总是以数据块为单位，所以存储信息的设备称为块设备。它属于有结构设备，如磁盘等。磁盘设备的基本特征是传输速率较高，以及可寻址，即对它可随机地读/写任一块。 字符设备：用于数据输入/输出的设备为字符设备，因为其传输的基本单位是字符。它属于无结构类型，如交互式终端机、打印机等。它们的基本特征是传输速率低、不可寻址，并且在输入/输出时常釆用中断驱动方式。 I/O(输入/输出)控制方式设备管理的主要任务之一是控制设备和内存或处理机之间的数据传送，外围设备和内存之间的输入/输出控制方式有四种，下面分别介绍。 程序直接控制方式如图(a)所示，计算机从外部设备读取数据到存储器，每次读一个字的数据。对读入的每个字，CPU需要对外设状态进行循环检查，直到确定该字已经在I/O控制器的数据寄存器中。在程序直接控制方式中，由于CPU的高速性和I/O设备的低速性，致使CPU的绝大部分时间都处于等待I/O设备完成数据I/O的循环测试中，造成了 CPU资源的极大浪费。在该方式中，CPU之所以要不断地测试I/O设备的状态，就是因为在CPU中没有釆用中断机构，使I/O设备无法向CPU报告它已完成了一个字符的输入操作。 程序直接控制方式虽然简单易于实现，但是其缺点也是显而易见的，由于cpu和I/O设备只能串行工作，导致CPU的利用率相当低。 中断驱动方式中断驱动方式的思想是，允许I/O设备主动打断CPU的运行并请求服务，从而“解放”CPU，使得其向I/O控制器发送读命令后可以继续做其他有用的工作。如图(b)所示，我们从I/O控制器和CPU两个角度分别来看中断驱动方式的工作过程：从I/O控制器的角度来看，I/O控制器从CPU接收一个读命令，然后从外围设备读数据。一旦数据读入到该I/O控制器的数据寄存器，便通过控制线给CPU发出一个中断信号，表示数据已准备好，然后等待CPU请求该数据。I/O控制器收到CPU发出的取数据请求后，将数据放到数据总线上，传到CPU的寄存器中。至此，本次I/O操作完成，I/O控制器又可幵始下一次I/O操作。 I/O控制方式 从CPU的角度来看，CPU发出读命令，然后保存当前运行程序的上下文（现场，包括程序计数器及处理机寄存器），转去执行其他程序。在每个指令周期的末尾，CPU检查中断。当有来自I/O控制器的中断时，CPU保存当前正在运行程序的上下文，转去执行中断处理程序处理该中断。这时，CPU从I/O控制器读一个字的数据传送到寄存器，并存入主存。接着， CPU恢复发出I/O命令的程序（或其他程序）的上下文，然后继续运行。 中断驱动方式比程序直接控制方式有效，但由于数据中的每个字在存储器与I/O控制器之间的传输都必须经过CPU,这就导致了中断驱动方式仍然会消耗较多的CPU时间。 DMA方式(直接内存存取)在中断驱动方式中，I/O设备与内存之间的数据交换必须要经过CPU中的寄存器，所以速度还是受限，而DMA（直接存储器存取）方式的基本思想是在I/O设备和内存之间开辟直接的数据交换通路，彻底“解放” CPU。DMA方式的特点是： 基本单位是数据块。 所传送的数据，是从设备直接送入内存的，或者相反。 仅在传送一个或多个数据块的开始和结束时，才需CPU干预，整块数据的传送是在DMA控制器的控制下完成的。下图列出了DMA控制器的组成。DMA控制器的组成 为了实现在主机与控制器之间成块数据的直接交换，必须在DMA控制器中设置如下四类寄存器： 命令/状态寄存器(CR)：用于接收从CPU发来的I/O命令或有关控制信息，或设备的状态。 内存地址寄存器(MAR)：在输入时，它存放把数据从设备传送到内存的起始目标地址；在输出时，它存放由内存到设备的内存源地址。 数据寄存器(DR)：用于暂存从设备到内存，或从内存到设备的数据。 数据计数器(DC)：存放本次CPU要读或写的字（节）数。 如图(c)所示，DMA方式的工作过程是：CPU读写数据时，它给I/O控制器发出一条命令，启动DMA控制器，然后继续其他工作。之后CPU就把控制操作委托给DMA控制器，由该控制器负责处理。DMA控制器直接与存储器交互，传送整个数据块，每次传送一个字，这个过程不需要CPU参与。当传送完成后，DMA控制器发送一个中断信号给处理器。因此只有在传送开始和结束时才需要CPU的参与。 DMA控制方式与中断驱动方式的主要区别是中断驱动方式在每个数据需要传输时中断CPU，而DMA控制方式则是在所要求传送的一批数据全部传送结束时才中断CPU；此外，中断驱动方式数据传送是在中断处理时由CPU控制完成的，而DMA控制方式则是在DMA 控制器的控制下完成的。 通道控制方式I/O通道是指专门负责输入/输出的处理机。I/O通道方式是DMA方式的发展，它可以进一步减少CPU的干预，即把对一个数据块的读（或写）为单位的干预，减少为对一组数据块的读（或写）及有关的控制和管理为单位的干预。同时，又可以实现CPU、通道和I/O设备三者的并行操作，从而更有效地提高整个系统的资源利用率。 例如，当CPU要完成一组相关的读（或写）操作及有关控制时，只需向I/O通道发送一条I/O指令，以给出其所要执行的通道程序的首地址和要访问的I/O设备，通道接到该指令后，通过执行通道程序便可完成CPU指定的I/O任务，数据传送结束时向CPU发中断请求。I/O通道与一般处理机的区别是：通道指令的类型单一，没有自己的内存，通道所执行的通道程序是放在主机的内存中的，也就是说通道与CPU共享内存。 I/O通道与DMA方式的区别是：DMA方式需要CPU来控制传输的数据块大小、传输的内存位置，而通道方式中这些信息是由通道控制的。另外，每个DMA控制器对应一台设备与内存传递数据，而一个通道可以控制多台设备与内存的数据交换。 I/O子系统的层次结构I/O软件涉及的面非常广，往下与硬件有着密切的联系，往上又与用户直接交互，它与进程管理、存储器管理、文件管理等都存在着一定的联系，即它们都可能需要I/O软件来实现I/O操作。 为了使复杂的I/O软件具有清晰的结构，良好的可移植性和适应性，在I/O软件中普遍釆用了层次式结构，将系统输入/输出功能组织成一系列的层次，每一层都利用其下层提供的服务，完成输入/输出功能中的某些子功能，并屏蔽这些功能实现的细节，向高层提供服务。在层次式结构的I/O软件中，只要层次间的接口不变，对某一层次中的软件的修改都不会引起其下层或高层代码的变更，仅最底层才涉及硬件的具体特性。 I/O层次结构 一个比较合理的层次划分如上图所示。整个I/O系统可以看成具有四个层次的系统结构，各层次及其功能如下： 用户层I/O软件：实现与用户交互的接口，用户可直接调用在用户层提供的、与I/O操作有关的库函数，对设备进行操作。一般而言，大部分的I/O软件都在操作系统内部，但仍有一小部分在用户层，包括与用户程序链接在一起的库函数，以及完全运行于内核之外的一些程序。用户层软件必须通过一组系统调用来获取操作系统服务。 设备独立性软件：用于实现用户程序与设备驱动器的统一接口、设备命令、设备保护、以友设备分配与释放等，同时为设备管理和数据传送提供必要的存储空间。设备独立性也称设备无关性，使得应用程序独立于具体使用的物理设备。为了实现设备独立性而引入了逻辑设备和物理设备这两个概念。在应用程序中，使用逻辑设备名来请求使用某类设备；而在系统实际执行时，必须将逻辑设备名映射成物理设备名使用。 使用逻辑设备名的好处是： 增加设备分配的灵活性； 易于实现I/O重定向，所谓I/O重定向，是指用于I/O操作的设备可以更换（即重定向），而不必改变应用程序。 为了实现设备独立性，必须再在驱动程序之上设置一层设备独立性软件。总的来说，设备独立性软件的主要功能可分以为以下两个方面： 执行所有设备的公有操作。包括：对设备的分配与回收；将逻辑设备名映射为物理设备名；对设备进行保护，禁止用户直接访问设备；缓冲管理；差错控制；提供独立于设备的大小统一的逻辑块，屏蔽设备之间信息交换单位大小和传输速率的差异。 向用户层（或文件层）提供统一接口。无论何种设备，它们向用户所提供的接口应该是相同的。例如，对各种设备的读/写操作，在应用程序中都统一使用read/write命令等。 设备驱动程序：与硬件直接相关，负责具体实现系统对设备发出的操作指令，驱动 I/O设备工作的驱动程序。通常，每一类设备配置一个设备驱动程序，它是I/O进程与设备控制器之间的通信程序，常以进程形式存在。设备驱动程序向上层用户程序提供一组标准接口，设备具体的差别被设备驱动程序所封装，用于接收上层软件发来的抽象I/O要求，如read和write命令，转换为具体要求后，发送给设备控制器，控制I/O设备工作；它也将由设备控制器发来的信号传送给上层软件。从而为I/O内核子系统隐藏设备控制器之间的差异。 中断处理程序：用于保存被中断进程的CPU环境，转入相应的中断处理程序进行处理，处理完并恢复被中断进程的现场后，返回到被中断进程。中断处理层的主要任务有：进行进程上下文的切换，对处理中断信号源进行测试，读取设备状态和修改进程状态等。由于中断处理与硬件紧密相关，对用户而言，应尽量加以屏蔽，故应放在操作系统的底层，系统的其余部分尽可能少地与之发生联系。 硬件设备：I/O设备通常包括一个机械部件和一个电子部件。为了达到设计的模块性和通用性，一般将其分开：电子部件称为设备控制器（或适配器），在个人计算机中，通常是一块插入主板扩充槽的印刷电路板；机械部件则是设备本身。设备控制器通过寄存器与CPU通信，在某些计算机上，这些寄存器占用内存地址的一部分，称为内存映像I/O；另一些计算机则釆用I/O专用地址，寄存器独立编址。操作系统通过向控制器寄存器写命令字来执行I/O功能。控制器收到一条命令后，CPU可以转向进行其他工作，而让设备控制器自行完成具体的I/O操作。当命令执行完毕后，控制器发出一个中断信号，操作系统重新获得CPU的控制权并检查执行结果，此时，CPU仍旧是从控制器寄存器中读取信息来获得执行结果和设备的状态信息。 设备控制器的主要功能为： 接收和识别CPU或通道发来的命令，如磁盘控制器能接收读、写、查找等命令。 实现数据交换，包括设备和控制器之间的数据传输；通过数据总线或通道，控制器和主存之间的数据传输。 发现和记录设备及自身的状态信息，供CPU处理使用。 设备地址识别。 为实现上述功能，设备控制器（如下图）必须包含以下组成部分： 设备控制器与CPU的接口。该接口有三类信号线：数据线、地址线和控制线。数据线通常与两类寄存器相连接：数据寄存器（存放从设备送来的输入数据或从CPU送来的输出数据）和控制/状态寄存器（存放从CPU送来的控制信息或设备的状态信息)。 设备控制器与设备的接口。设备控制器连接设备需要相应数量的接口，一个接口连接一台设备。每个接口中都存在数据、控制和状态三种类型的信号。 I/O控制逻辑。用于实现对设备的控制。它通过一组控制线与CPU交互，对从CPU收到的I/O命令进行译码。CPU启动设备时，将启动命令发送给控制器，同时通过地:址线把地址发送给控制器，由控制器的I/O逻辑对地址进行译码，并相应地对所选设备进行控制。设备控制器的组成 I/O子系统概述和I/O调度的概念I/O子系统概述由于I/O设备种类繁多，功能和传输速率差异巨大，需要多种方法来进行设备控制。这些方法共同组成了操作系统内核的I/O子系统，它将内核的其他方面从繁重的I/O设备管理中解放出来。I/O核心子系统提供的服务主要有I/O调度、缓冲与高速缓存、设备分配与回收、假脱机、设备保护和差错处理等。 I/O调度概念I/O调度就是确定一个好的顺序来执行这些I/O请求。应用程序所发布的系统调用的顺序不一定总是最佳选择，所以需要I/o调度来改善系统整体性能，使进程之间公平地共享设备访问，减少I/O完成所需要的平均等待时间。 操作系统开发人员通过为每个设备维护一个请求队列来实现调度。当一个应用程序执行阻塞I/O系统调用时，该请求就加到相应设备的队列上。I/O调度会重新安排队列顺序以改善系统总体效率和应用程序的平均响应时间。 I/O子系统还可以使用主存或磁盘上的存储空间的技术，如缓冲、高速缓冲、假脱机等，来改善计算机效率。 高速缓存与缓冲区磁盘高速缓存(Disk Cache)操作系统中使用磁盘高速缓存技术来提高磁盘的I/O速度，对高速缓存复制的访问要比原始数据访问更为高效。例如，正在运行的进程的指令既存储在磁盘上，也存储在物理内存上，也被复制到CPU的二级和一级高速缓存中。 不过，磁盘高速缓存技术不同于通常意义下的介于CPU与内存之间的小容量高速存储器，而是指利用内存中的存储空间来暂存从磁盘中读出的一系列盘块中的信息。因此，磁盘高速缓存在逻辑上属于磁盘，物理上则是驻留在内存中的盘块。 高速缓存在内存中分为两种形式：一种是在内存中开辟一个单独的存储空间作为磁速缓存，大小固定；另一种是把未利用的内存空间作为一个缓沖池，供请求分页系统和磁盘I/O时共享。 缓冲区(Buffer)在设备管理子系统中，引入缓冲区的目的主要有： 缓和CPU与I/O设备间速度不匹配的矛盾。 减少对CPU的中断频率，放宽对CPU中断响应时间的限制。 解决基本数据单元大小（即数据粒度）不匹配的问题。 提高CPU和I/O设备之间的并行性。 其实现方法有： 釆用硬件缓冲器，但由于成本太高，除一些关键部位外，一般不釆用硬件缓冲器 釆用缓冲区（位于内存区域）。 根据系统设置缓冲器的个数，缓冲技术可以分为： 单缓冲在设备和处理机之间设置一个缓冲区。设备和处理机交换数据时，先把被交换数据写入缓冲区，然后需要数据的设备或处理机从缓冲区取走数据。 如下图所示，在块设备输入时，假定从磁盘把一块数据输入到缓冲区的时间为T，操作系统将该缓冲区中的数据传送到用户区的时间为M，而CPU对这一块数据处理的时间为 C。由于T和C是可以并行的，当T&gt;C时，系统对每一块数据的处理时间为M十T，反之则为M+C，故可把系统对每一块数据的处理时间表示为Max(C, T)+M。 单缓冲工作示意图 双缓冲 根据单缓冲的特点，CPU在传送时间M内处于空闲状态，由此引入双缓冲。I/O设备输入数据时先装填到缓冲区1，在缓冲区1填满后才开始装填缓冲区2，与此同时处理机可以从缓冲区1中取出数据放入用户进程处理，当缓冲区1中的数据处理完后，若缓冲区2已填满，则处理机又从缓冲区2中取出数据放入用户进程处理，而I/O设备又可以装填缓冲区1。双缓冲机制提高了处理机和输入设备的并行操作的程度。 如下图所示，系统处理一块数据的时间可以粗略地认为是MAC(C, T)。如果C&lt;T，可使块设备连续输入（图中所示情况)；如果C&gt;T，则可使CPU不必等待设备输入。对于字符设备，若釆用行输入方式，则釆用双缓冲可使用户在输入完第一行之后，在CPU执行第一行中的命令的同时，用户可继续向第二缓冲区输入下一行数据。而单缓冲情况下则必须等待一行数据被提取完毕才可输入下一行的数据。 双缓冲工作示意图 如果两台机器之间通信仅配置了单缓冲，如下图(a)所示。那么，它们在任一时刻都只能实现单方向的数据传输。例如，只允许把数据从A机传送到B机，或者从B机传送到A 机，而绝不允许双方同时向对方发送数据。为了实现双向数据传输，必须在两台机器中都设置两个缓冲区，一个用做发送缓冲区，另一个用做接收缓冲区，如下图(b)所示。 双机通信时缓冲区的设置 循环缓冲包含多个大小相等的缓冲区，每个缓冲区中有一个链接指针指向下一个缓冲区，最后一个缓冲区指针指向第一个缓冲区，多个缓冲区构成一个环形。循环缓冲用于输入/输出时，还需要有两个指针in和out。对输入而言，首先要从设备接收数据到缓冲区中，in指针指向可以输入数据的第一个空缓冲区；当运行进程需要数据时，从循环缓冲区中取一个装满数据的缓冲区，并从此缓冲区中提取数据，out指针指向可以提取数据的第一个满缓冲区。输出则正好相反。 缓冲池由多个系统公用的缓冲区组成，缓冲区按其使用状况可以形成三个队列：空缓冲队列、装满输入数据的缓冲队列（输入队列）和装满输出数据的缓沖队列（输出队列）。还应具有四种缓冲区：用于收容输入数据的工作缓冲区、用于提取输入数据的工作缓冲区、 用于收容输出数据的工作缓冲区及用于提取输出数据的工作缓冲区，如下图所示。 缓冲区的工作方式 当输入进程需要输入数据时，便从空缓冲队列的队首摘下一个空缓冲区，把它作为收容输入工作缓冲区，然后把输入数据输入其中，装满后再将它挂到输入队列队尾。当计算进程需要输入数据时，便从输入队列取得一个缓冲区作为提取输入工作缓冲区，计算进程从中提取数据，数据用完后再将它挂到空缓冲队列尾。当计算进程需要输出数据时，便从空缓冲队列的队首取得一个空缓冲区，作为收容输出工作缓冲区，当其中装满输出数据后，再将它挂到输出队列队尾。当要输出时，由输出进程从输出队列中取得一个装满输出数据的缓冲区，作为提取输出工作缓冲区，当数据提取完后，再将它挂到空缓冲队列的队尾。 高速缓存与缓冲区的对比高速缓存是可以保存数据拷贝的高速存储器，访问高速缓存比访问原始数据更高效速度更快。其对比见下表。 高速缓存和缓冲区的对比 输入/输出(I/O)设备分配与回收设备分配概述设备分配是指根据用户的I/O请求分配所需的设备。分配的总原则是充分发挥设备的使用效率，尽可能地让设备忙碌，又要避免由于不合理的分配方法造成进程死锁。从设备的特性来看，釆用下述三种使用方式的设备分别称为独占设备、共享设备和虚拟设备三类。 独占式使用设备。指在申请设备时，如果设备空闲，就将其独占，不再允许其他进程申请使用，一直等到该设备被释放才允许其他进程申请使用。例如，打印机，在使用它打印时，只能独占式使用，否则在同一张纸上交替打印不同任务的内容，无法正常阅读。 分时式共享使用设备。独占式使用设备时，设备利用率很低，当设备没有独占使用的要求时，可以通过分时共享使用，提高利用率。例如，对磁盘设备的I/O操作，各进程的每次I/O操作请求可以通过分时来交替进行。 以SPOOLing方式使用外部设备。SPOOLing技术是在批处理操作系统时代引入的，即假脱机I/O技术。这种技术用于对设备的操作，实质上就是对I/O操作进行批处理。 设备分配的数据结构设备分配依据的主要数据结构有设备控制表(DCT)、控制器控制表(COCT)、通道控制表(CHCT)和系统设备表(SDT)，各数据结构功能如下： 设备控制表DCT：系统为每一个设备配置一张DCT,如下图所示。它用于记录设备的特性以及与I/O控制器连接的情况。DCT包括设备标识符、设备类型、设备状态、指向控制器控制表COCT的指针等。其中，设备状态指示设备是忙还是空闲，设备队列指针指向等待使用该设备的进程组成的等待队列，控制表指针指向与该设备相连接的设备控制器。 设备控制表 控制器控制表COCT：每个控制器都配有一张COCT，如下图a所示。它反映设备控制器的使用状态以及和通道的连接情况等。 通道控制表CHCT：每个通道配有一张CHCT，如下图b所示。 系统设备表SDT：整个系统只有一张SDT，如下图c所示。它记录已连接到系统中的所有物理设备的情况，每个物理设备占一个表目。COCT、CHCT 和 SDT 由于在多道程序系统中，进程数多于资源数，会引起资源的竞争。因此，要有一套合理的分配原则，主要考虑的因素有：I/O设备的固有属性，I/O设备的分配算法，设备分配的安全性以及设备独立性。 设备分配的策略 设备分配原则：设备分配应根据设备特性、用户要求和系统配置情况。分配的总原则既要充分发挥设备的使用效率，又要避免造成进程死锁，还要将用户程序和具体设备隔离开。 设备分配方式：设备分配方式有静态分配和动态分配两种。 静态分配主要用于对独占设备的分配，它在用户作业开始执行前，由系统一次性分配该作业所要求的全部设备、控制器（和通道)。一旦分配后，这些设备、控制器（和通道）就一直为该作业所占用，直到该作业被撤销。静态分配方式不会出现死锁，但设备的使用效率低。因此，静态分配方式弁不符合分配的总原则。动态分配是在进程执行过程中根据执行需要进行。当进程需要设备时，通过系统调用命令向系统提出设备请求，由系统按照事先规定的策略给进程分配所需要的设备、I/O控制器，一旦用完之后，便立即释放。动态分配方式有利于提高设备的利用率，但如果分配算法使用不当，则有可能造成进程死锁。 设备分配算法：常用的动态设备分配算法有先请求先分配、优先级高者优先等。 对于独占设备，既可以釆用动态分配方式也可以静态分配方式，往往釆用静态分配方式，即在作业执行前，将作业所要用的这一类设备分配给它。共享设备可被多个进程所共享，一般釆用动态分配方式，但在每个I/O传输的单位时间内只被一个进程所占有，通常釆用先请求先分配和优先级高者先分的分配算法。 设备分配的安全性设备分配的安全性是指设备分配中应防止发生进程死锁。 安全分配方式：每当进程发出I/O请求后便进入阻塞状态，直到其I/O操作完成时才被唤醒。这样，一旦进程已经获得某种设备后便阻塞，不能再请求任何资源，而且在它阻塞时也不保持任何资源。优点是设备分配安全；缺点是CPU和I/O设备是串行工作的（对同一进程而言)。 不安全分配方式：进程在发出I/O请求后继续运行，需要时又发出第二个、第三个 I/O请求等。仅当进程所请求的设备已被另一进程占用时，才进入阻塞状态。优点是一个进程可同时操作多个设备，从而使进程推进迅速；缺点是这种设备分配有可能产生死锁。 逻辑设备名到物理设备名的映射为了提高设备分配的灵活性和设备的利用率、方便实现I/O重定向，因此引入了设备独立性。设备独立性是指应用程序独立于具体使用的物理设备。 为了实现设备独立性，在应用程序中使用逻辑设备名来请求使用某类设备，在系统中设置一张逻辑设备表(Logical Unit Table, LUT)，用于将逻辑设备名映射为物理设备名。LUT 表项包括逻辑设备名、物理设备名和设备驱动程序入口地址；当进程用逻辑设备名来请求分配设备时，系统为它分配相应的物理设备，并在LUT中建立一个表项，以后进程再利用逻辑设备名请求I/0操作时，系统通过查找LUT来寻找相应的物理设备和驱动程序。 在系统中可釆取两种方式建立逻辑设备表： 在整个系统中只设置一张LUT。这样，所有进程的设备分配情况都记录在这张表中，故不允许有相同的逻辑设备名，主要适用于单用户系统中。 为每个用户设置一张LUT。当用户登录时，系统便为该用户建立一个进程，同时也为之建立一张LUT，并将该表放入进程的PCB中。 SPOOLing技术(假脱机技术)为了缓和CPU的高速性与I/O设备低速性之间的矛盾而引入了脱机输入/输出技术。该技术是利用专门的外围控制机，将低速I/O设备上的数据传送到高速磁盘上；或者相反。 SPOOLing的意思是外部设备同时联机操作，又称为假脱机输入/输出操作，是操作系统中釆用的一项将独占设备改造成共享设备的技术。 SPOOLing系统组成如下图所示。 输入井和输出井在磁盘上开辟出的两个存储区域。输入井模拟脱机输入时的磁盘，用于收容I/O设备输 入的数据。输出井模拟脱机输出时的磁盘，用于收容用户程序的输出数据。 SPOOLing系统的组成 输入缓冲区和输出缓冲区在内存中开辟的两个缓冲区。输入缓冲区用于暂存由输入设备送来的数据，以后再传送 到输入井。输出缓冲区用于暂存从输出井送来的数据，以后再传送到输出设备。 输入进程和输出进程输入进程模拟脱机输入时的外围控制机，将用户要求的数据从输入机通过输入缓冲区再送到输入井。当CPU需要输入数据时，直接将数据从输入井读入内存。输出进程模拟脱机 输出时的外围控制机，把用户要求输出的数据先从内存送到输出并，待输出设备空闲时，再 将输出井中的数据经过输出缓冲区送到输出设备。 共享打印机是使用SPOOLing技术的一个实例，这项技术已被广泛地用于多用户系统和 局域网络中。当用户进程请求打印输出时，SPOOLing系统同意为它打印输出，但并不真正立即把打印机分配给该用户进程，而只为它做两件事： 由输出进程在输出井中为之申请一个空闲磁盘块区，并将要打印的数据送入其中。 输出进程再为用户进程申请一张空白的用户请求打印表，并将用户的打印要求填入其中，再将该表挂到请求打印队列上。 SPOOLing系统的主要特点有：提高了 I/O的速度；将独占设备改造为共享设备；实现 了虚拟设备功能。 输入/输出(I/O)知识点汇总 分配设备。首先根据I/O请求中的物理设备名查找系统设备表（SDT),从中找出该设备的DCT（设备控制表），再根据DCT中的设备状态字段，可知该设备是否正忙。若忙，便将请求I/O 进程的PCB挂在设备队列上；空闲则按照一定算法计算设备分配的安全性，安全则将设备分配给请求进程，否则仍将其PCB挂到设备队列。 分配控制器。系统把设备分配给请求I/O的进程后，再到其DCT中找出与该设备连接的控制器的COCT（控制器控制表）,从COCT中的状态字段中可知该控制器是否忙碌。若忙，便将请求I/O 进程的PCB挂在该控制器的等待队列上；空闲便将控制器分配给进程。 分配通道。在该COCT中又可找到与该控制器连接的通道的CHCT（通道控制表）,再根据CHCT 内的状态信息，可知该通道是否忙碌。若忙，便将请求I/O的进程挂在该通道的等待队列上；空闲便将该通道分配给进程。只有在上述三者都分配成功时，这次设备的分配才算成功。然后，便可启动该I/O设备进行数据传送。 为使独占设备的分配具有更强的灵活性，提高分配的成功率，还可以从以下两方面对基本的设备分配程序加以改进： 增加设备的独立性。进程使用逻辑设备名请求I/O。这样，系统首先从SDT中找出第一个该类设备的DCT。若该设备忙，又查找第二个该类设备的DCT。仅当所有该类设备都忙时，才把进程挂在该类设备的等待队列上；只要有一个该类设备可用，系统便进一步计算分配该设备的安全性。 考虑多通路情况。为防止I/O系统的“瓶颈”现象，通常釆用多通路的I/O系统结构。此时对控制器和通道的分配同样要经过几次反复，即若设备（控制器）所连接的第一个控制器（通道）忙时，应查看其所连接的第二个控制器（通道)，仅当所有的控制器（通道）都忙时，此次的控制器（通道）分配才算失败，才把进程挂在控制器（通道）的等待队列上。而只要有一个控制器（通道）可用，系统便可将它分配给进程。]]></content>
      <categories>
        <category>计算机</category>
        <category>操作系统</category>
        <category>存储管理</category>
      </categories>
      <tags>
        <tag>计算机</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[磁盘]]></title>
    <url>%2F2019%2F06%2F12%2F%E7%A3%81%E7%9B%98%2F</url>
    <content type="text"><![CDATA[磁盘的结构磁盘(Disk)是由表面涂有磁性物质的金属或塑料构成的圆形盘片，通过一个称为磁头的导体线圈从磁盘中存取数据。在读/写操作期间，磁头固定，磁盘在下面高速旋转。如下图所示，磁盘的盘面上的数据存储在一组同心圆中，称为磁道。每个磁道与磁头一样宽, 一个盘面有上千个磁道。磁道又划分为几百个扇区，每个扇区固定存储大小（通常为512B), 一个扇区称为一个盘块。相邻磁道及相邻扇区间通过一定的间隙分隔开，以避免精度错误。 注意，由于扇区按固定圆心角度划分，所以密度从最外道向里道增加，磁盘的存储能力受限于最内道的最大记录密度。 磁盘安装在一个磁盘驱动器中，它由磁头臂、用于旋转磁盘的主轴和用于数据输入/输 出的电子设备组成。如图4-24所示，多个盘片垂直堆叠，组成磁盘组，每个盘面对应一个 磁头，所有磁头固定在一起，与磁盘中心的距离相同且一起移动。所有盘片上相对位置相同 的磁道组成柱面。按照这种物理结构组织，扇区就是磁盘可寻址的最小存储单位，磁盘地址 用“柱面号•盘面号•扇区号（或块号）”表示。磁盘按不同方式可以分为若干类型：磁头相对于盘片的径向方向固定的称为固定头磁盘，每个磁道一个磁头；磁头可移动的称为活动头磁盘，磁头臂可以来回伸缩定位磁道。磁 盘永久固定在磁盘驱动器内的称为固定盘磁盘；可移动和替换的称为可换盘磁盘。 磁盘调度算法一次磁盘读写操作的时间由寻找（寻道）时间、延迟时间和传输时间决定： 寻找时间Ts：活动头磁盘在读写信息前，将磁头移动到指定磁道所需要的时间。这个时间除跨越n条磁道的时间外，还包括启动磁臂的时间s，即： 式中，m是与磁盘驱动器速度有关的常数，约为0.2ms，磁臂的启动时间约为2ms。 延迟时间Tr：磁头定位到某一磁道的扇区（块号）所需要的时间，设磁盘的旋转速度为r，则： 对于硬盘，典型的旋转速度为5400r/m，相当于一周11.1ms，则Tr为5.55ms;对于软盘，其旋转速度在300~600r/m之间，则Tr为50~100ms。 传输时间Tt：从磁盘读出或向磁盘写入数据所经历的时间，这个时间取决于每次所读/写的字节数b和磁盘的旋转速度： 式中，r为磁盘每秒钟的转数；N为一个磁道上的字节数。 在磁盘存取时间的计算中，寻道时间与磁盘调度算法相关，下面将会介绍分析几种算法，而延迟时间和传输时间都与磁盘旋转速度相关，且为线性相关，所以在硬件上，转速是磁盘性能的一个非常重要的参数。 总平均存取时间Ta可以表示为： 虽然这里给出了总平均存取时间的公式，但是这个平均值是没有太大实际意义的，因为在实际的磁盘I/O操作中，存取时间与磁盘调度算法密切相关。调度算法直接决定寻找时间，从而决定了总的存取时间。 目前常用的磁盘调度算法有以下几种： 先来先服务(First Come First Served, FCFS)算法FCFS算法根据进程请求访问磁盘的先后顺序进行调度，这是一种最简单的调度算法，如下图所示。该算法的优点是具有公平性。如果只有少量进程需要访问，且大部分请求都是访问簇聚的文件扇区，则有望达到较好的性能；但如果有大量进程竞争使用磁盘，那么这种算法在性能上往往接近于随机调度。所以，实际磁盘调度中考虑一些更为复杂的调度算法。 FCFS磁盘调度算法 例如，磁盘请求队列中的请求顺序分别为55、58、39、18、90、160、150、38、184，磁头初始位置是100磁道，釆用FCFS算法磁头的运动过程如图4-25所示。磁头共移动了 (45+3+19+21+72+70+10+112+146)=498 个磁道，平均寻找长度=498/9=55.3。 最短寻找时间优先(Shortest Seek Time First, SSTF)算法SSTF算法选择调度处理的磁道是与当前磁头所在磁道距离最近的磁道，以使每次的寻找时间最短。当然，总是选择最小寻找时间并不能保证平均寻找时间最小，但是能提供比 FCFS算法更好的性能。这种算法会产生“饥饿”现象。如下图所示，若某时刻磁头正在 18号磁道，而在18号磁道附近频繁地增加新的请求，那么SSTF算法使得磁头长时间在18 号磁道附近工作，将使184号磁道的访问被无限期地延迟，即被“饿死”。 SSTF磁盘调度算法 例如，磁盘请求队列中的请求顺序分别为55、58、39、18、90、160、150、38、184，磁头初始位置是100磁道，釆用SSTF算法磁头的运动过程如图4-26所示。磁头共移动了 (10+32+3+16+1+20+132+10+24)=248 个磁道，平均寻找长度=248/9=27.5。 扫描(SCAN)算法（又称电梯算法）SCAN算法在磁头当前移动方向上选择与当前磁头所在磁道距离最近的请求作为下一次服务的对象，如下图所示。由于磁头移动规律与电梯运行相似，故又称为电梯调度算法。SCAN算法对最近扫描过的区域不公平，因此，它在访问局部性方面不如FCFS算法和 SSTF算法好。 SCAN磁盘调度算法 例如，磁盘请求队列中的请求顺序分别为55、58、39、18、90、160、150、38、184，磁头初始位置是100 磁道。釆用SCAN算法时，不但要知道磁头的当前位置，还要知道磁头的移动方向，假设磁头沿磁道号增大的顺序移动，则磁头的运动过程如图4-27所示。磁头共移动了(50+10+24+94+32+3+16+1+20)=250 个磁道，平均寻找长度=250/9=27.8。 循环扫描(Circulair SCAN, C-SCAN)算法在扫描算法的基础上规定磁头单向移动来提供服务，回返时直接快速移动至起始端而不服务任何请求。由于SCAN算法偏向于处理那些接近最里或最外的磁道的访问请求，所以使用改进型的C-SCAN算法来避免这个问题。 釆用SCAN算法和C-SCAN算法时磁头总是严格地遵循从盘面的一端到另一端，显然，在实际使用时还可以改进，即磁头移动只需要到达最远端的一个请求即可返回，不需要到达磁盘端点。这种形式的SCAN算法和C-SCAN算法称为LOOK和C-LOOK调度。这是因为它们在朝一个给定方向移动前会查看是否有请求。注意，若无特别说明，也可以默认SCAN 算法和C-SCAN算法为LOOK和C-LOOK调度。 C-SCAN磁盘调度算法 例如，磁盘请求队列中的请求顺序分别为55、58、39、18、90、160、150、38、184，磁头初始位置是100磁道。釆用C-SCAN算法时，假设磁头沿磁道号增大的顺序移动，则磁头的运动过程如图4-28所示。磁头共移动了(50+10+24+166+20+1+16+3+32)=322个磁道，平均寻道长度=322/9=35.8。 对比以上几种磁盘调度算法，FCFS算法太过简单，性能较差，仅在请求队列长度接近于1时才较为理想；SSTF算法较为通用和自然；SCAN算法和C-SCAN算法在磁盘负载较大时比较占优势。它们之间的比较见下表。 磁盘调度算法比较 除减少寻找时间外，减少延迟时间也是提高磁盘传输效率的重要因素。可以对盘面扇区进行交替编号，对磁盘片组中的不同盘面错位命名。假设每个盘面有8个扇区，磁盘片组共8个盘面，则可以釆用如下图所示的编号。 磁盘片组扇区编号 磁盘是连续自转设备，磁头读/写一个物理块后，需要经过短暂的处理时间才能开始读/ 写下一块。假设逻辑记录数据连续存放在磁盘空间中，若在盘面上按扇区交替编号连续存放，则连续读/写多个记录时能减少磁头的延迟时间；同柱面不同盘面的扇区若能错位编号，连续读/写相邻两个盘面的逻辑记录时也能减少磁头延迟时间。 由于传输时间由磁盘转速决定，所以无法通过其他方法减少传输时间。以上图为例，在随机扇区访问情况下，定位磁道中的一个扇区平均需要转过4个扇区，这时，延迟时间是传输时间的4倍，这是一种非常低效的存取方式。理想化的情况是不需要定位而直接连续读取扇区，没有延迟时间，这样磁盘数据存取效率可以成倍提高。但是由于读取扇区的顺序是不可预测的，所以延迟时间不可避免。图4-29中的编号方式是读取连续编号扇区时的一种方法。 磁盘的管理：磁盘初始化、引导块、坏块磁盘初始化一个新的磁盘只是一个含有磁性记录材料的空白盘。在磁盘能存储数据之前，它必须分成扇区以便磁盘控制器能进行读和写操作，这个过程称为低级格式化（物理分区）。低级格式化为磁盘的每个扇区釆用特别的数据结构。每个扇区的数据结构通常由头、数据区域（通常为512B大小）和尾部组成。头部和尾部包含了一些磁盘控制器所使用的信息。 为了使用磁盘存储文件，操作系统还需要将自己的数据结构记录在磁盘上：第一步将磁盘分为由一个或多个柱面组成的分区（即我们熟悉的C盘、D盘等形式的分区）；第二步对物理分区进行逻辑格式化（创建文件系统)，操作系统将初始的文件系统数据结构存储到磁盘上，这些数据结构包括空闲和已分配的空间以及一个初始为空的目录。 引导块计算机启动时需要运行一个初始化程序（自举程序），它初始化CPU、寄存器、设备控制器和内存等，接着启动操作系统。为此，该自举程序应找到磁盘上的操作系统内核，装入内存，并转到起始地址，从而开始操作系统的运行。 自举程序通常保存在ROM中，为了避免改变自举代码需要改变ROM硬件的问题，故只在ROM中保留很小的自举装入程序，将完整功能的自举程序保存在磁盘的启动块上，启动块位于磁盘的固定位。拥有启动分区的磁盘称为启动磁盘或者系统磁盘。 坏块由于磁盘有移动部件且容错能力弱，所以容易导致一个或多个扇区损坏。部分磁盘甚至从出厂时就有坏扇区。根据所使用的磁盘和控制器，对这些块有多种处理方式。 对于简单磁盘，如电子集成驱动器（IDE)。坏扇区可手工处理，如MS-DOS的Format 命令执行逻辑格式化时便会扫描磁盘以检查坏扇区。坏扇区在FAT表上会标明，因此程序不会使用。 对于复杂的磁盘，如小型计算机系统接口（SCSI)，其控制器维护一个磁盘坏块链表。该链表在出厂前进行低级格式化时就初始化了，并在磁盘的整个使用过程中不断更新。低级格式化将一些块保留作为备用，对操作系统透明。控制器可以用备用块来逻辑地替代坏块，这种方案称为扇区备用。 文件系统知识点总结磁盘结构引导控制块(Boot Control Block)包括系统从该分区引导操作系统所需要的信息。如果磁盘没有操作系统，那么这块的内容为空。它通常为分区的第一块。UFS称之为引导块(Boot Block)； NTFS 称之为分区引导扇区(Partition Boot Sector)。 分区控制块(Partition Control Block)包括分区详细信息，如分区的块数、块的大小、 空闲块的数量和指计、空闲FCB的数量和指针等。UPS称之为超级块(Superblock)；而NTFS 称之为主控文件表(Master File Table)。 内存结构内存分区表包含所有安装分区的信息。 内存目录结构用来保存近来访问过的目录信息。对安装分区的目录，可以包括一个指向分区表的指针。 系统范围的打开文件表，包括每个打开文件的FCB复制和其他信息。 单个进程的打开文件表，包括一个指向系统范围内已打开文件表中合适条目和其他信息的指针。 文件系统实现概述为了创建一个文件，应用程序调用逻辑文件系统。逻辑文件系统知道目录结构形式，它将分配一个新的FCB 给文件，把相应目录读入内存，用新的文件名更新该目录和FCB,并将结果写回到磁盘。图4-32显示了一个典型 的 FCB。 典型的FCB 一旦文件被创建，它就能用于I/O，不过首先要打开文件。调用open将文件名传给文件系统，文件系统根据给定文件名搜索目录结构。部分目录结构通常缓存在内存中以加快目录操作。找到文件后，其FCB复制到系统范围的打开文件表。该表不但存储FCB，也有打开该文件的进程数量的条目。 然后，单个进程的打开文件表中会增加一个条目，并通过指针将系统范围的打开文件表的条目同其他域（文件当前位置的指针和文件打开模式等）相连。调用open返回的是一个 指向单个进程的打开文件表中合适条目的指针。所以文件操作都是通过该指针进行。 文件名不必是打开文件表的一部分，因为一旦完成对FCB在磁盘上的定位，系统就不 再使用文件名了。对于访问打开文件表的索引，UNIX称之为文件描述符(File Descriptor)；而Windows 2000称之为文件句柄(File Handle)。因此，只要文件没有被关闭，所有文件操 作通过打开文件表来进行。 当一个进程关闭文件，就删除一个相应的单个进程打开文件表的条目即目录项，系统范 围内打开文件表的打开数也会递减。当打开文件的所有用户都关闭了一个文件时，更新的文 件信息会复制到磁盘的目录结构中，系统范围的打开文件表的条目也将删除。 在实际中，系统调用open会首先搜索系统范围的打开文件表以确定某文件是否已被其 他进程所使用。如果是，就在单个进程的打开文件表中创建一项，并指向现有系统范围的打 开文件表的相应条目。该算法在文件已打开时，能节省大量开销。 混合索引分配的实现混合索引分配已在UNIX系统中釆用。在UNK SystemV的索引结点中，共设置了 13 个地址项，即iaddr(O)~iaddr(12)，如下图所示。在BSD UNIX的索引结点中，共设置了 13个地址项，它们都把所有的地址项分成两类，即直接地址和间接地址。 UNIX系统的inode结构示意图 1. 直接地址 为了提高对文件的检索速度，在索引结点中可设置10个直接地址项，即用iaddr(O)~iaddr(9)来存放直接地址。换言之，在这里的每项中所存放的是该文件数据所在盘块的盘块号。假如每个盘块的大小为4KB，当文件不大于40KB时，便可直接从索引结点中读出该文件的全部盘块号。 2. 一次间接地址 对于大、中型文件，只釆用直接地址并不现实。可再利用索引结点中的地址项iaddr(lO) 来提供一次间接地址。这种方式的实质就是一级索引分配方式。图中的一次间址块也就是索引块，系统将分配给文件的多个盘块号记入其中。在一次间址块中可存放1024个盘块号，因而允许文件长达4MB。 3. 多次间接地址 当文件长度大于4MB+40KB（—次间址与10个直接地址项）时，系统还须釆用二次间 址分配方式。这时，用地址项iaddr(11)提供二次间接地址。该方式的实质是两级索引分配方 式。系统此时是在二次间址块中记入所有一次间址块的盘号。在釆用二次间址方式时，文件 最大长度可达4GB。同理，地址项iaddr(12)作为三次间接地址，其所允许的文件最大长度可达4TB。]]></content>
      <categories>
        <category>计算机</category>
        <category>操作系统</category>
        <category>存储管理</category>
      </categories>
      <tags>
        <tag>计算机</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL]]></title>
    <url>%2F2019%2F06%2F10%2FSQL%2F</url>
    <content type="text"><![CDATA[认识SQL (1) 什么是SQL？1.SQL 指结构化查询语言2.SQL 使我们有能力访问数据库3.SQL 是一种 ANSI 的标准计算机语言 注意：ANSI，美国标准 (2) SQL能做什么？SQL 面向数据库执行查询SQL 可从数据库取回数据SQL 可在数据库中插入新的记录SQL 可更新数据库中的数据SQL 可从数据库删除记录SQL 可创建新数据库SQL 可在数据库中创建新表SQL 可在数据库中创建存储过程SQL 可在数据库中创建视图SQL 可以设置表、存储过程和视图的权限 (3) 数据库系统什么是数据库?举个例子来说明这个问题：每个人都有很多亲戚和朋友，为了保持与他们的联系，我们常常用一个笔记本将他们的姓名、地址、电话等信息都记录下来，这样要査谁的电话或地址就很方便了。这个“通讯录”就是一个最简单的“数据库”，每个人的姓名、地址、电话等信息就是这个数据库中的“数据”。我们可以在笔记本这个“数据库”中添加新朋友的个人信息，也可以由于某个朋友的电话变动而修改他的电话号码这个“数据”。不过说到底，我们使用笔记本这个“数据库”还是为了能随时査到某位亲戚或朋友的地址、邮编或电话号码这些“数据”。数据库(Database)是按照数据结构来组织、储存和管理数据的建立在计算机存储设备上的仓库。MS Access、DB2、Informix、MS SQL Server、Oracle、Sybase 以及其他数据库系统（PS:好多我也没用过。）他们都有一些相似的地方，比如(SELECT、UPDATE、DELETE、INSERT、WHERE 等等)，当然大多数据库都有自己的扩张。可以了解了解。 (4) 数据库表一个数据库通常包含一个或多个表。每个表由一个名字标识(表名)，表是相关的数据项的集合，它由列和行组成。 字段。每个表都可以分解为更小的项。这些项被称为“字段”。字段是表里的一列，用于保持每条记录的特定信息。 记录或一行数据。记录，也被称为一行数据，是表里的各行。在关系型数据库的表里，一行数据是指一条完整的记录。 列。列是表里的垂直的一项，包含表里特定字段的全部信息。 主键。主键用于区分表里的每一条数据，它通常是在表创建过程中初始化的。主键的特性确保了每一条记录都是唯一的。 NULL值。NULL 是表示“没有值”的专用术语。如果表中某个字段的值是NULL，其表现形式就是字段为空，其值就是没有值。NULL并不等于0或空格。值为NULL的字段在表创建过程中会保持为空。 索引为了提高访问数据库的效率，可以对数据库使用索引。当数据库较大时，为了查找指定的记录，则使用索引和不使用索引的效率有很大差别。索引实际上是一种特殊类型的表，其中含有关键字段的值(由用户定义)和指向实际记录位置的指针，这些值和指针按照特定的顺序(也由用户定义)存储，从而可以以较快的速度查找到所需要的数据记录。 数据库语言SQLDML(数据库操作语言)DDL(数据库定义语言)DQL(数据库查询语言)DCL(数据库控制语言) SQL DML用于更新、删除和插入记录的语法。UPDATE - 更新数据库表中的数据DELETE - 从数据库表中删除数据INSERT INTO - 向数据库表中插入数据 SQL DDL用于创建或删除表格，也可以定义索引（键），规定表之间的关系，以及添加表间的约束。CREATE DATABASE - 创建新数据库ALTER DATABASE - 修改数据库CREATE TABLE - 创建新表ALTER TABLE - 变更（改变）数据库表DROP TABLE - 删除表CREATE INDEX - 创建索引（搜索键）DROP INDEX - 删除索引 SQL DQL用于执行查询的语法，基本结构是由SELECT子句，FROM子句，WHERE子句组成的查询块。SELECT &lt;字段名&gt;FROM &lt;表名或视图&gt;WHERE &lt;条件&gt; SQL DCL用于创建与用户访问相关的对象，以及控制用户的权限ALTER PASSWORDGRANT &lt;授权&gt;REVOKECREATE SYNONYM]]></content>
      <categories>
        <category>计算机</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>计算机</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件系统实现]]></title>
    <url>%2F2019%2F06%2F10%2F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[文件系统层次结构现代操作系统有多种文件系统类型（如FAT32、NTFS、 ext2、ext3、ext4等），因此文件系统的层次结构也不尽相同。下图是一种合理的层次结构。 文件系统层次结构 用户调用接口文件系统为用户提供与文件及目录有关的调用，如新建、打开、读写、关闭、删除文件，建立、删除目录等。此层由若干程序模块组成，每一模块对应一条系统调用，用户发出系统调用时，控制即转入相应的模块。 文件目录系统文件目录系统的主要功能是管理文件目录，其任务有管理活跃文件目录表、管理读写状态信息表、管理用户进程的打开文件表、管理与组织在存储设备上的文件目录结构、调用下一级存取控制模块。 存取控制验证实现文件保护主要由该级软件完成，它把用户的访问要求与FCB中指示的访问控制权限进行比较，以确认访问的合法性。 逻辑文件系统与文件信息缓冲区逻辑文件系统与文件信息缓冲区的主要功能是根据文件的逻辑结构将用户要读写的逻辑记录转换成文件逻辑结构内的相应块号。 物理文件系统物理文件系统的主要功能是把逻辑记录所在的相对块号转换成实际的物理地址。 分配模块分配模块的主要功能是管理辅存空间，即负责分配辅存空闲空间和回收辅存空间。 设备管理程序模块设备管理程序模块的主要功能是分配设备、分配设备读写用缓冲区、磁盘调度、启动设备、处理设备中断、释放设备读写缓冲区、释放设备等。 文件系统的实现：目录实现和文件实现目录实现在读文件前，必须先打开文件。打开文件时，操作系统利用路径名找到相应目录项，目 录项中提供了查找文件磁盘块所需要的信息。目录实现的基本方法有线性列表和哈希表两种。 线性列表最简单的目录实现方法是使用存储文件名和数据块指针的线性表。创建新文件时，必须 首先搜索目录表以确定没有同名的文件存在，然后在目录表后增加一个目录项。删除文件则 根据给定的文件名搜索目录表，接着释放分配给它的空间。若要重用目录项，有许多方法： 可以将目录项标记为不再使用，或者将它加到空闲目录项表上，还可以将目录表中最后一个 目录项复制到空闲位置，并降低目录表长度。釆用链表结构可以减少删除文件的时间。其优 点在于实现简单，不过由于线性表的特殊性，比较费时。 哈希表哈希表根据文件名得到一个值，并返回一个指向线性列表中元素的指针。这种方法的优点是查找非常迅速，插入和删除也较简单，不过需要一些预备措施来避免冲突。最大的困难是哈希表长度固定以及哈希函数对表长的依赖性。 目录查询是通过在磁盘上反复搜索完成，需要不断地进行I/O操作，开销较大。所以如前面所述，为了减少I/O操作，把当前使用的文件目录复制到内存，以后要使用该文件时只要在内存中操作，从而降低了磁盘操作次数，提高了系统速度。 文件实现文件分配方式文件分配对应于文件的物理结构，是指如何为文件分配磁盘块。常用的磁盘空间分配方法有三种：连续分配、链接分配和索引分配。有的系统（如RD0S操作系统）对三种方法都支持，但是更普遍的是一个系统只提供一种方法的支持。 连续分配。连续分配方法要求每个文件在磁盘上占有一组连续的块，如下图所示。 磁盘地址定义了磁盘上的一个线性排序。这种排序使作业访问磁盘时需要的寻道数和寻道时间最小。连续分配 文件的连续分配可以用第一块的磁盘地址和连续块的数量来定义。如果文件有n块长并从位置b开始，那么该文件将占有块b, b+1, b+2, …, b+n-1。 一个文件的目录条目包括 开始块的地址和该文件所分配区域的长度。 连续分配支持顺序访问和直接访问。其优点是实现简单、存取速度快。缺点在于，文件长度不宜动态增加，因为一个文件末尾后的盘块可能已经分配给其他文件，一旦需要增加，就需要大量移动盘块。此外，反复增删文件后会产生外部碎片（与内存管理分配方式中的碎片相似)，并且很难确定一个文件需要的空间大小，因而只适用于长度固定的文件。 链接分配。链接分配是釆取离散分配的方式，消除了外部碎片，故而显著地提高了磁盘空间的利用率；又因为是根据文件的当前需求，为它分配必需的盘块，当文件动态增长时，可以动态地再为它分配盘块，故而无需事先知道文件的大小。此外，对文件的增、删、改也非常方便。链接分配又可以分为隐式链接和显式链接两种形式。 隐式连接如下图所示。每个文件对应一个磁盘块的链表；磁盘块分布在磁盘的任何 地方，除最后一个盘块外，每一个盘块都有指向下一个盘块的指针，这些指针对用户是透明的。目录包括文件第一块的指针和最后一块的指针。 创建新文件时，目录中增加一个新条目。每个目录项都有一个指向文件首块的指针。该指针初始化为NULL以表示空文件，大小字段为0。写文件会通过空闲空间管理系统找到空 闲块，将该块链接到文件的尾部，以便写入。读文件则通过块到块的指针顺序读块。 隐式链接分配的缺点在于无法直接访问盘块，只能通过指针顺序访问文件，以及盘块指 针消耗了一定的存储空间。隐式链接分配的稳定性也是一个问题，系统在运行过程中由于软 件或者硬件错误导致链表中的指针丢失或损坏，会导致文件数据的丢失。 隐式链接分配 显式链接，是指把用于链接文件各物理块的指针，显式地存放在内存的一张链接表中。 该表在整个磁盘仅设置一张，每个表项中存放链接指针，即下一个盘块号。在该表中，凡是 属于某一文件的第一个盘块号，或者说是每一条链的链首指针所对应的盘块号，均作为文件 地址被填入相应文件的FCB的“物理地址”字段中。由于查找记录的过程是在内存中进行 的，因而不仅显著地提高了检索速度，而且大大减少了访问磁盘的次数。由于分配给文件的 所有盘块号都放在该表中，故称该表为文件分配表（File Allocation Table, FAT)。 索引分配链接分配解决了连续分配的外部碎片和文件大小管理的问题。但是，链接分配不能有效支持直接访问（FAT除外）。索引分配解决了这个问题，它把每个文件的所有的盘块号都集中放在一起构成索引块（表），如下图所示。索引分配 每个文件都有其索引块，这是一个磁盘块地址的数组。索引块的第i个条目指向文件的 第i个块。目录条目包括索引块的地址。要读第i块，通过索引块的第i个条目的指针来查 找和读入所需的块。 创建文件时，索引块的所有指针都设为空。当首次写入第i块时，先从空闲空间中取得 一个块，再将其地址写到索引块的第i个条目。索引分配支持直接访问，且没有外部碎片问 题。其缺点是由于索引块的分配，增加了系统存储空间的开销。索引块的大小是一个重要的 问题，每个文件必须有一个索引块，因此索引块应尽可能小，但索引块太小就无法支持大文 件。可以釆用以下机制来处理这个问题。 链接方案：一个索引块通常为一个磁盘块，因此，它本身能直接读写。为了处理大文件， 可以将多个索引块链接起来。 多层索引：多层索引使第一层索引块指向第二层的索引块，第二层索引块再指向文件块。 这种方法根据最大文件大小的要求，可以继续到第三层或第四层。例如，4096B的块，能在 索引块中存入1024个4B的指针。两层索引允许1048576个数据块，即允许最大文件为4GB。 混合索引：将多种索引分配方式相结合的分配方式。例如，系统既釆用直接地址，又采 用单级索引分配方式或两级索引分配方式。 三种分配方式的比较。 此外，访问文件需要两次访问外存——首先要读取索引块的内容，然后再访问具体的磁 盘块，因而降低了文件的存取速度。为了解决这一问题，通常将文件的索引块读入内存的缓 冲区中，以加快文件的访问速度。 文件存储空间管理 文件存储器空间的划分与初始化。一般来说，一个文件存储在一个文件卷中。文件卷可以是物理盘的一部分，也可以是整个物理盘，支持超大型文件的文件卷也可以由多个物理盘组成，如图4-15所示。 在一个文件卷中，文件数据信息的空间（文件区）和存放文件控制信息FCB的空间（目录区）是分离的。由于存在很多种类的文件表示和存放格式，所以现代操作系统中一般都有很多不同的文件管理模块，通过它们可以访问不同格式的逻辑卷中的文件。逻辑卷在提供文件服务前，必须由对应的文件程序进行初始化，划分好目录区和文件区，建立空闲空间管理表格及存放逻辑卷信息的超级块。 文件存储器空间管理。文件存储设备分成许多大小相同的物理块，并以块为单位交换信息，因此，文件存储设备的管理实质上是对空闲块的组织和管理，它包括空闲块的组织、 分配与回收等问题。 逻辑卷与物理盘的关系 ①空闲表法空闲表法属于连续分配方式，它与内存的动态分配方式类似，为每个文件分配一块连续的存储空间。系统为外存上的所有空闲区建立一张空闲盘块表，每个空闲区对应于一个空闲表项，其中包括表项序号、该空闲区第一个盘块号、该区的空闲盘块数等信息。再将所有空闲区按其起始盘块号递增的次序排列，见表4-3。 空闲盘区的分配与内存的动态分配类似，同样是釆用首次适应算法、循环首次适应算法等。例如，在系统 为某新创建的文件分配空闲盘块时，先顺序地检索空闲 盘块表的各表项，直至找到第一个其大小能满足要求的 空闲区，再将该盘区分配给用户，同时修改空闲盘块表。 系统在对用户所释放的存储空间进行回收时，也釆取类似于内存回收的方法，即要考虑回收区是否与空闲表中插入点的前区和后区相邻接，对 相邻接者应予以合并。 空闲盘块表 ②空闲链表法将所有空闲盘区拉成一条空闲链，根据构成链所用的基本元素不同，可把链表分成两种 形式：空闲盘块链和空闲盘区链。 空闲盘块链是将磁盘上的所有空闲空间，以盘块为单位拉成一条链。当用户因创建文件 而请求分配存储空间时，系统从链首开始，依次摘下适当的数目的空闲盘块分配给用户。当 用户因删除文件而释放存储空间时，系统将回收的盘块依次插入空闲盘块链的末尾。这种方 法的优点是分配和回收一个盘块的过程非常简单，但在为一个文件分配盘块时，可能要重复 多次操作。 空闲盘区链是将磁盘上的所有空闲盘区（每个盘区可包含若干个盘块）拉成一条链。在 每个盘区上除含有用于指示下一个空闲盘区的指针外，还应有能指明本盘区大小（盘块数） 的信息。分配盘区的方法与内存的动态分区分配类似，通常釆用首次适应算法。在回收盘区 时，同样也要将回收区与相邻接的空闲盘区相合并。 ③位示图法位示图是利用二进制的一位来表示磁盘中一个盘块的使用情况，磁盘上所有的盘块都有 一个二进制位与之对应。当其值为“0”时，表示对应的盘块空闲；当其值为“1”时，表示 对应的盘块已分配。位示图法示意如图4-16所示。 盘块的分配： 顺序扫描位示图，从中找出一个或一组其值为“0”的二进制位。 将所找到的一个或一组二进制位，转换成与之对应的盘块号。假定找到的其值为“0” 的二进制位，位于位示图的第i行、第j列，则其相应的盘块号应按下式计算（n代表每行的位数）： b=n(i-1)+j 修改位示图，令map[i,j]=1。 盘块的回收：将回收盘块的盘块号转换成位示图中的行号和列号。转换公式为 i=(b-1)DIV n +l j=(b-l)MOD n +1修改位示图，令map[i,j]=0。④成组链接法空闲表法和空闲链表法都不适合用于大型文件系统，因为这会使空闲表或空闲链表太 大。在UNIX系统中釆用的是成组链接法，这种方法结合了空闲表和空闲链表两种方法，克 月艮了表太大的缺点。其大致的思想是:把顺序的n个空闲扇区地址保存在第一个空闲扇区内， 其后一个空闲扇区内则保存另一顺序空闲扇区的地址，如此继续，直至所有空闲扇区均予以 链接。系统只需要保存一个指向第一个空闲扇区的指针。假设磁盘最初全为空闲扇区；其成 组链接如下图所示。通过这种方式可以迅速找到大批空闲块地址。 成组链接法示意图 表示文件存储器空闲空间的“位向量”表或第一个成组链块以及卷中的目录区、文件区 划分信息都需要存放在辅存储器中，一般放在卷头位置，在UNIX系统中称为“超级块”。 在对卷中文件进行操作前，“超级块”需要预先读入系统空间的主存，并且经常保持主存“超 级块”与辅存卷中“超级块”的一致性。 注意：位示图法，行和列都是从1开始编号。特别注意， 如果题目中指明从0开始编号，则上述的计算方法要进行相应调整。]]></content>
      <categories>
        <category>计算机</category>
        <category>操作系统</category>
        <category>存储管理</category>
      </categories>
      <tags>
        <tag>计算机</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库系统概念]]></title>
    <url>%2F2019%2F06%2F09%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[名词解释DB(Database) 数据库DB是长期存储在计算机内的，有组织的、统一管理的相关数据的集合。DB能为各种用户共享，具有较小的冗余度、数据间联系紧密而又有较高的数据独立性等特点。 DBMS(Database Management System) 数据库管理系统DBMS是位于用户与操作系统（OS）之间的一层数据管理软件，它为用户或应用程序提供访问DB的方法，包括DB的建立、查询、更新等各种数据控制。DBMS总是基于某种模型，可以分为层次型、网状型、关系型和面向对象型等。 DBS(Database System) 数据库系统DBS是实现有组织地、动态地存储大量关联数据、方便多用户访问的计算机硬件、软件和数据资源组成的系统，即它是采用数据库技术的计算机系统。 数据库技术数据库技术是研究数据库的结构、存储、设计、管理和使用的一门软件科学。 联系的元数联系（Relationship）是实体间的相互关系。与一个联系有关的实体集个数，称为联系的元数。 1:1联系二元联系的一种类型。一对一联系：如果实体集E1中每个实体至多和实体集E2中的一个实体有联系，反之亦然，那么实体集E1和E2的联系称为“一对一联系”，记为“1:1”。 1：N联系二元联系的一种类型。一对多联系：如果实体集E1中每个实体可以与实体集E2中任意个（零个或多个）实体间有联系，而E2中每个实体至多和E1中一个实体有联系，那么称E1对E2的联系是“一对多联系”，记为“1：N”。 M：N联系二元联系的一种类型。多对多联系：如果实体集E1中的每个实体可以与实体集E2中任意个（零个或多个）实体间有联系，反之亦然，那么称E1与E2的联系是“多对多联系”，记为“M：N”。 数据模型模型（Model）是对现实世界的抽象。在数据库技术中，我们用数据模型（Data Model）的概念描述数据库的结构和语义，对现实世界的数据进行抽象。根据数据抽象的级别定义了四种模型：概念数据模型、逻辑数据模型、外部数据模型和内部数据模型。一般在提及时省略“数据”两字。 概念模型表达用户需求观点的数据全局逻辑结构的模型，称为“概念模型”。 逻辑模型表达计算机实现观点的DB全局逻辑结构的模型，称为“逻辑模型”。 层次模型（hierarchical Model）：用树型（层次）结构表示实体类型及实体间联系的数据模型称为层次模型。树中的节点是记录类型，每个非根节点有且只有一个父节点。上层记录类型和下一层记录类型之间的联系是1：N联系。 网状模型（Network Model）：用有向图结构表示实体类型及实体间联系的数据模型称为网状模型。 关系模型（Relational Model）：关系模型是由若干个关系模式（Relational Schema）组成的集合。 外部模型表达用户使用观点的DB局部逻辑结构的模型，称为“外部模型”。 内部模型表达DB物理结构的模型，称为“内部模型”。 三层模式和两级映像在用户（或应用程序）到数据库之间，DB的数据结构有三个层次：外部模型、逻辑模型和内部模型。这三个层次要用DB的数据定义语言（Data Definition language，简记为DDL）定义，定义以后的内容称为“模式”（Schema），即外模式、逻辑模式和内模式。 外模式：是用户与数据库系统的接口，是用户用到的那部分数据的描述。外模式由若干个外部记录类型组成。 逻辑模式：是数据库中全部数据的整体逻辑结构的描述。它由若干个逻辑记录类型组成，还包含记录间联系、数据的完整性安全性等要求。 内模式：是数据库在物理存储方面的描述，定义所有内部记录类型、索引和文件的组织方式，以及数据控制方面的细节。 外模式/逻辑模式映像：存在于外模式和逻辑模式之间，用于定义外模式和逻辑模式之间的对应性。这个映像一般是放在外模式中描述的。 逻辑模式/内模式映像：存在于逻辑模式和内模式之间，用于定义逻辑模式和内模式之间的对应性。这个映像一般是放在内模式中描述的。 数据独立性（Data Indepandence）是指应用程序和数据库的数据结构之间相互独立，不受影响。在修改数据结构时，尽可能不修改应用程序，则称系统达到了数据独立性目标。数据独立性分成物理数据独立性和逻辑数据独立性两个级别。 物理独立性：如果数据库的内模式要修改，即数据库的物理结构有所变化，那么只要对逻辑模式/内模式映像（即“对应性”）作相应的修改，可以使逻辑模式尽可能保持不变。也就是对内模式的修改尽量不影响逻辑模式，当然对于外模式和应用程序的影响更小，这样，我们称数据库达到了物理数据独立性（简称物理独立性）。 逻辑独立性：如果数据库的逻辑模式要修改，譬如增加记录类型或增加数据项，那么只要对外模式/逻辑模式映像作相应修改，可以使外模式和应用程序尽可能保持不变。这样，我们称数据库达到了逻辑数据独立性（简称逻辑独立性）。 语言主语言编写应用程序的语言可以是COBOL、PL/I、C、C++、Java一类高级程序设计语言，这些语言称为主语言或宿主语言（host language）。 DDL数据定义语言（Data Definition Language，简记为DDL）。 DML数据操纵语言（Data Manipulation Language，简记为DML）。 过程性语言过程性DML是指用户编程时，不仅需要指出”做什么“（需要什么样的数据），还需要指出”怎么做“（怎样获得这些数据） 非过程性语言非过程性DML是指用户编程时，只需要指出“做什么”，不需要指出“怎么做”。 DD数据库系统中存放三级结构定义的数据库称为数据字典（Data Dicationary，DD）。对数据库的操作都要通过DD才能实现。DD中还存放数据库运行时的统计信息，例如记录个数、访问次数等。 DD系统管理DD的子系统称为“DD系统”。 数据库管理人工管理阶段的数据管理的特点 数据不保存在计算机内。 没有专用的软件对数据进行管理。 只有程序（Program）的概念，没有文件（File）的概念。数据的组织方式必须由程序员自行设计与安排。 数据面向程序。即一组数据对应一个程序。 文件系统阶段的数据管理特点 数据以“文件”形式可长期保存在外部存储器的磁盘上。 数据的逻辑结构与物理结构有了区别，但比较简单。 文件组织已多样化。 数据不再属于某个特定程序，可以重复使用，即数据面向应用。 对数据的操作以记录为单位。 文件系统阶段的数据管理缺陷 数据冗余（Redundancy）。 数据不一致（Inconsistency）。 数据不一致（Poor Data Relationship）。 数据管理的数据库阶段产生的三件标志性事情 1968年美国IBM公司推出层次模型的IMS（Information Management System）系统； 1969年美国CODASYL（Conference On Data System Language）组织发布了DBTG（Data Base Task Group）报告。总结了当时各式各样的数据库，提出网状模型，尔后于1971年4月正式通过； 1970年美国IBM公司的E.F.Codd连续发表论文，提出关系模型，奠定了关系数据库的理论基础。 数据库阶段的数据管理特点 采用数据模型表示复杂的数据结构。 有较高的数据独立性。 数据库系统为用户提供了方便的用户接口。 数据库系统提供了以下四方面的数据控制功能： 数据库的恢复：在数据库被破坏或数据不可靠时，系统有能力把数据库恢复到最近某个正确状态。 数据库的并发控制：对程序的并发操作加以控制，防止数据库被破坏，杜绝提供给用户不正确的数据。 数据的完整性：保证数据库中的数据始终是正确的。 数据安全性：保证数据的安全，防止数据丢失或被窃取、破坏。 增加了系统的灵活性：对数据的操作不一定以记录为单位，可以以数据项为单位。 高级数据库阶段的技术 20世纪80年代的分布式数据库系统。 90年代的对象数据库系统。 面向对象的概念建模 21世纪的Web数据库系统。 开放数据库互连技术 逻辑记录与物理记录，逻辑文件与物理文件的联系和区别（联系和区别想的不是很明白）逻辑记录是逻辑设计中的数据的一种描述，逻辑设计中字段的有序集合称为记录。一般，用一个记录描述一个实体，所以记录又可以定义为能完整的描述一个实体的字段集。物理记录是物理存储中数据的一种描述，又称为物理块或块，块是内存和外存交换信息的最小单位，每块的大小，通常为2^10 ~ 2^14字节。内、外存信息交换是由操作系统的文件系统管理的。 逻辑文件是同一类记录的集合。用来描述实体集。物理文件是真实存在的，是有数据的。 对于联系和区别理解的不是很好，看到网上一段这样的解释：物理文件相当于table，逻辑文件相当于view，物理文件是有数据的，而逻辑文件是没有数据的。还有，它们都是object。（摘抄自http://bbs.chinaunix.net/thread-329732-1-1.html） 数据抽象过程的步骤第1步：根据用户需求，设计数据库的概念模型，这是一个“综合”的过程。第2步：根据转换规则，把概念模型转换成数据库的逻辑模型，这是一个“转换”的过程。第3步：根据用户的业务特点，设计不同的外部模型，给程序员使用。也就是应用程序使用的是数据库的外部模型。外部模型与逻辑模型之间的对应性称为映像。第4步：数据库实现时，要根据逻辑模型设计其内部模型。内部模型与逻辑模型之间的对应性称为映像。 概念模型、逻辑模型、外部模型和内部模型各自的特点概念模型的特点： 概念模型表达了数据的整体逻辑结构，它是系统用户对整个应用项目涉及的数据的全面描述。 概念模型是从用户需求的观点出发，对数据建模。 概念模型独立于硬件和软件。硬件独立意味着概念模型不依赖于硬件设备，软件独立意味着该模型不依赖于实现时的DBMS软件。因此硬件或软件的变化都不会影响DB的概念模型设计。 概念模型是数据库设计人员与用户之间进行交流的工具。逻辑模型的特点： 逻辑模型表达了DB的整体逻辑结构，但它是设计人员对整个应用项目数据库的全面描述。 逻辑模型是从数据库实现的观点出发，对数据建模。 逻辑模型独立于硬件，但依赖于软件（DBMS）。 逻辑模型是数据库设计人员与应用程序员之间进行交流的工具。外部模型的特点： 外部模型是逻辑模型的一个逻辑子集。 外部模型独立于硬件，依赖于软件。 外部模型反映了用户使用数据库的观点。内部模型的特点： 它描述数据在磁盘或磁带上的存储方式（文件的结构）、存取社保（外存的控件分配）和存取方法（主索引和辅助索引）。层次、网状和关系三种逻辑数据模型的区别层次模型和网状模型中，记录之间通过指针来实现，查询效率较高。层次模型只能表示1：N关系，网状模型不仅能表示1：N联系，还能表示M：N联系。关系模型和层次、网状模型的最大差别是用关键码而不是用指针导航数据。外部模型使数据库系统具有的优点 简化了用户的观点。 有助于数据库的安全性保护。 外部模型是对概念模型的支持。数据独立性与数据联系这两个概念的区别数据独立性是指应用程序和数据库的数据结构之间相互独立，不受影响。数据独立性分成物理数据独立性和逻辑数据独立性两个级别。数据联系是指实体之间的相互关系。数据独立性是在结构层次，数据联系是在具体的实体之间。 用户、DB的三级模式结构、磁盘上的物理文件之间的联系和不同数据库的三层模式结构时一个理想的结构，使数据库系统达到了高度的数据独立性。用户与数据库之间的数据传输要在三层结构中来回转换。从而使用户的数据能真正的读或写入文理文件中。应用程序在系统缓冲区中的用户记录应与外模式中的外部记录在结构上是一致的。磁盘上物理文件的记录应与内模式中的内部记录在结构上也是一致的。 DBMS的工作模式和主要功能DBMS的工作模式：（1）接受应用程序的数据请求和处理请求；（2）将用户的数据请求（高级指令）转换成复杂的机器代码（低层指令）；（3）实现对数据库的操作；（4）从对数据库的操作中接受查询结果；（5）对查询结果进行处理（格式转换）；（6）将处理结果返回给用户。 主要功能： 数据库的定义功能：DBMS提供DDL定义数据库的三级结构、两级映像，定义数据的完整性约束、保密限制等约束。因此，在DBMS中应包括DDL的编译程序。 数据库的操作功能：DBMS提供DML实现对数据的操作。基本的数据操作有两类：检索（查询）和更新（包括插入、删除、更新）。因此，在DBMS中应包括DML的编译程序或解释程序。 数据库的保护功能：（1）数据库的恢复。（2）数据库的并发控制。（3）数据完整性控制。（4）数据安全性控制。DBMS的其它保护功能还有系统缓冲区的管理以及数据存储的某些自适应调节机制等。 数据库的维护功能：这一部分包括数据库的数据载入、转换、转储，数据库的改组以及性能监控等功能。 数据字典：数据库系统中存放三级结构定义的数据库称为数据字典（Data Dictionary, DD）。对数据库的操作都要通过DD才能实现。DD中还存放数据库运行时的统计信息，例如记录个数、访问次数等。管理DD的子系统统称为“DD系统”。 DB系统缓冲区及其作用DB系统缓冲区是DBMS为应用程序在内存中开辟的一个系统缓冲区，用户数据的传输和格式转换。 DBS由哪几部分组成？它有哪些系统软件？其中DD有什么作用？它是数据库、硬件、软件和数据库管理员的集合体。典型的数据库应用开发工具有Visual Basic 7.0、PowerBuilder 10.0 和 Delphi 6.0等系统。DD为DBS提供存储三级结构的描述（一般称为元数据Metadata） DBS的全局结构解释这个结构从用户、界面、DBMS和磁盘等四个层次考虑各模块功能之间的联系。 数据库用户DBA 、专业用户、应用程序员、终端用户。 DBMS的查询处理器这一部分可分为四个成分：（1）DDL解释器：解释DDL语句，并将这些定义登录到数据字典中。（2）DML编译器：对DML语句进行优化，并转成查询求值引擎能执行的低层指令。（3）嵌入式DML的预编译器：把嵌入到主语言中的DML语句处理成规范的过程调用形式。（4）查询求值引擎：执行由DML编译器产生的低层指令。 DBMS的存储管理器存储管理器提供存储在数据库中的低层数据和应用程序、查询之间的接口。存储管理器可分为四个成分：（1）权限和完整性管理器：测试应用程序对数据库的修改是否满足完整性约束，检查用户访问数据的合法性。（2）事务管理器：DBS的逻辑工作单元称为事务（Transaction），事务由对DB的操作序列组成。事务管理器用于确保DB一致性（正确性）状态，保证并发操作正确执行。（3）文件管理器：负责磁盘空间的合理分配，管理物理文件的存储结构和存取方式。（4）缓冲区管理器：为应用程序开辟DB的系统缓冲区，负责将从磁盘中读出的数据送入内存的缓冲区。 磁盘存储器中的数据结构（1）数据文件：存储数据库管理的用户数据自身。数据库在磁盘上的基本组织形式是文件，这样可以充分利用OS管理外存的功能。（2）数据字典：存储三级结构的描述（一般称为元数据Metadata）。（3）索引：为提高查询速度而设置的逻辑排序手段。（4）统计数据：存储DBS运行时统计分析的数据。查询处理器可以使用这些信息更有效地进行查询处理。（5）日志：存储DBS运行时对DB的操作情况，以备以后查阅数据库的使用情况及数据恢复时使用。 从模块结构观察，DBMS由哪些部分组成？总体上分两个模块：查询处理器 和 存储管理器。查询处理器又可分为：DDL解释器、DML编译器、嵌入式DML的预编译器和求值引擎。存储管理器又可分为：权限和完整性管理器、事务管理器、文件管理器和缓冲区管理器。]]></content>
      <categories>
        <category>计算机</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>计算机</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟内存]]></title>
    <url>%2F2019%2F06%2F09%2F%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[虚拟内存的概念、特征以及虚拟内存的实现 传统存储管理方式的特征上一节所讨论的各种内存管理策略都是为了同时将多个进程保存在内存中以便允许多道程序设计。它们都具有以下两个共同的特征： 一次性作业必须一次性全部装入内存后，方能开始运行。这会导致两种情况发生： 当作业很大，不能全部被装入内存时，将使该作业无法运行； 当大量作业要求运行时，由于内存不足以容纳所有作业，只能使少数作业先运行，导致多道程序度的下降。 驻留性作业被装入内存后，就一直驻留在内存中，其任何部分都不会被换出，直至作业运行结束。运行中的进程，会因等待I/O而被阻塞，可能处于长期等待状态。 由以上分析可知，许多在程序运行中不用或暂时不用的程序（数据）占据了大量的内存空间，而一些需要运行的作业又无法装入运行，显然浪费了宝贵的内存资源。 局部性原理要真正理解虚拟内存技术的思想，首先必须了解计算机中著名的局部性原理。著名的 Bill Joy (SUN公司CEO)说过：”在研究所的时候，我经常开玩笑地说高速缓存是计算机科学中唯一重要的思想。事实上，髙速缓存技术确实极大地影响了计算机系统的设计。“快表、 页高速缓存以及虚拟内存技术从广义上讲，都是属于高速缓存技术。这个技术所依赖的原理就是局部性原理。局部性原理既适用于程序结构，也适用于数据结构（更远地讲，Dijkstra 著名的关于“goto语句有害”的论文也是出于对程序局部性原理的深刻认识和理解）。 局部性原理表现在以下两个方面： 时间局部性：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。 空间局部性：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。 时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。虚拟内存技术实际上就是建立了 “内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存。 虚拟存储器的定义和特征基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其余部分留在外存，就可以启动程序执行。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存,然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换出到外存上，从而腾出空间存放将要调入内存的信息。这样，系统好像为用户提供了一个比实际内存大得多的存储器，称为虚拟存储器。 之所以将其称为虚拟存储器，是因为这种存储器实际上并不存在，只是由于系统提供了部分装入、请求调入和置换功能后（对用户完全透明），给用户的感觉是好像存在一个比实际物理内存大得多的存储器。虚拟存储器的大小由计算机的地址结构决定，并非是内存和外存的简单相加。虚拟存储器有以下三个主要特征： 多次性，是指无需在作业运行时一次性地全部装入内存，而是允许被分成多次调入内存运行。 对换性，是指无需在作业运行时一直常驻内存，而是允许在作业的运行过程中，进行换进和换出。 虚拟性，是指从逻辑上扩充内存的容量，使用户所看到的内存容量，远大于实际的内存容量。 虚拟内存技术的实现虚拟内存中，允许将一个作业分多次调入内存。釆用连续分配方式时，会使相当一部分内存空间都处于暂时或“永久”的空闲状态，造成内存资源的严重浪费，而且也无法从逻辑上扩大内存容量。因此，虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。虚拟内存的实现有以下三种方式： 请求分页存储管理。 请求分段存储管理。 请求段页式存储管理。 不管哪种方式，都需要有一定的硬件支持。一般需要的支持有以下几个方面： 一定容量的内存和外存。 页表机制（或段表机制），作为主要的数据结构。 中断机构，当用户程序要访问的部分尚未调入内存，则产生中断。 地址变换机构，逻辑地址到物理地址的变换。 请求分页管理方式实现虚拟内存请求分页系统建立在基本分页系统基础之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。 在请求分页系统中，只要求将当前需要的一部分页面装入内存，便可以启动作业运行。在作业执行过程中，当所要访问的页面不在内存时，再通过调页功能将其调入，同时还可以通过置换功能将暂时不用的页面换出到外存上，以便腾出内存空间。 为了实现请求分页，系统必须提供一定的硬件支持。除了需要一定容量的内存及外存的计算机系统，还需要有页表机制、缺页中断机构和地址变换机构。 页表机制请求分页系统的页表机制不同于基本分页系统，请求分页系统在一个作业运行之前不要求全部一次性调入内存，因此在作业的运行过程中，必然会出现要访问的页面不在内存的情况，如何发现和处理这种情况是请求分页系统必须解决的两个基本问题。为此，在请求页表项中增加了四个字段，如下图所示。 请求分页系统中的页表项 增加的四个字段说明如下： 状态位P：用于指示该页是否已调入内存，供程序访问时参考。 访问字段A：用于记录本页在一段时间内被访问的次数，或记录本页最近己有多长时间未被访问，供置换算法换出页面时参考。 修改位M：标识该页在调入内存后是否被修改过。 外存地址：用于指出该页在外存上的地址，通常是物理块号，供调入该页时参考。 缺页中断机构在请求分页系统中，每当所要访问的页面不在内存时，便产生一个缺页中断，请求操作系统将所缺的页调入内存。此时应将缺页的进程阻塞（调页完成唤醒)，如果内存中有空闲块，则分配一个块，将要调入的页装入该块，并修改页表中相应页表项，若此时内存中没有空闲块，则要淘汰某页（若被淘汰页在内存期间被修改过，则要将其写回外存)。 缺页中断作为中断同样要经历，诸如保护CPU环境、分析中断原因、转入缺页中断处理程序、恢复CPU环境等几个步骤。但与一般的中断相比，它有以下两个明显的区别： 在指令执行期间产生和处理中断信号，而非一条指令执行完后，属于内部中断。 一条指令在执行期间，可能产生多次缺页中断。 地址变换机构请求分页系统中的地址变换机构，是在分页系统地址变换机构的基础上，为实现虚拟内存，又增加了某些功能而形成的。 请求分页中的地址变换过程 如上图所示，在进行地址变换时，先检索快表： 若找到要访问的页，便修改页表项中的访问位（写指令则还须重置修改位)，然后利用页表项中给出的物理块号和页内地址形成物理地址。 若未找到该页的页表项，应到内存中去查找页表，再对比页表项中的状态位P，看该页是否已调入内存，未调入则产生缺页中断，请求从外存把该页调入内存。 页面置换算法进程运行时，若其访问的页面不在内存而需将其调入，但内存已无空闲空间时，就需要从内存中调出一页程序或数据，送入磁盘的对换区。 选择调出页面的算法就称为页面置换算法。好的页面置换算法应有较低的页面更换频率，也就是说，应将以后不会再访问或者以后较长时间内不会再访问的页面先调出。 常见的置换算法有以下四种。 最佳置换算法(OPT)最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。 最佳置换算法可以用来评价其他算法。假定系统为某进程分配了三个物理块，并考虑有以下页面号引用串： 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1 进程运行时，先将7, 0, 1三个页面依次装入内存。进程要访问页面2时，产生缺页中断，根据最佳置换算法，选择第18次访问才需调入的页面7予以淘汰。然后，访问页面0时，因为已在内存中所以不必产生缺页中断。访问页面3时又会根据最佳置换算法将页面1淘汰……依此类推，如下图所示。从图中可以看出釆用最佳置换算法时的情况。可以看到，发生缺页中断的次数为9，页面置换的次数为6。 利用最佳置换算法时的置换图 先进先出(FIFO)页面置换算法优先淘汰最早进入内存的页面，亦即在内存中驻留时间最久的页面。该算法实现简单，只需把调入内存的页面根据先后次序链接成队列，设置一个指针总指向最早的页面。但该算法与进程实际运行时的规律不适应，因为在进程中，有的页面经常被访问。 利用FIFO置换算法时的置换图 这里仍用上面的实例，釆用FIFO算法进行页面置换。进程访问页面2时，把最早进入内存的页面7换出。然后访问页面3时，再把2, 0, 1中最先进入内存的页换出。由图 3-27可以看出，利用FIFO算法时进行了 12次页面置换，比最佳置换算法正好多一倍。 FIFO算法还会产生当所分配的物理块数增大而页故障数不减反增的异常现象，这是由 Belady于1969年发现，故称为Belady异常，如图3-28所示。只有FIFO算法可能出现Belady 异常，而LRU和OPT算法永远不会出现Belady异常。 Belady 异常 最近最久未使用(LRU)置换算法选择最近最长时间未访问过的页面予以淘汰，它认为过去一段时间内未访问过的页面，在最近的将来可能也不会被访问。该算法为每个页面设置一个访问字段，来记录页面自上次被访问以来所经历的时间，淘汰页面时选择现有页面中值最大的予以淘汰。 再对上面的实例釆用LRU算法进行页面置换，如下图所示。进程第一次对页面2访问时，将最近最久未被访问的页面7置换出去。然后访问页面3时，将最近最久未使用的页面1换出。 LRU页面置换算法时的置换图 在上图中，前5次置换的情况与最佳置换算法相同，但两种算法并无必然联系。实际上，LRU算法根据各页以前的情况，是“向前看”的，而最佳置换算法则根据各页以后的使用情况，是“向后看”的。 LRU性能较好，但需要寄存器和栈的硬件支持。LRU是堆栈类的算法。理论上可以证明，堆栈类算法不可能出现Belady异常。FIFO算法基于队列实现，不是堆栈类算法。 时钟(CLOCK)置换算法LRU算法的性能接近于OPT,但是实现起来比较困难，且开销大；FIFO算法实现简单，但性能差。所以操作系统的设计者尝试了很多算法，试图用比较小的开销接近LRU的性能，这类算法都是CLOCK算法的变体。 简单的CLOCK算法是给每一帧关联一个附加位，称为使用位。当某一页首次装入主存时，该帧的使用位设置为1;当该页随后再被访问到时，它的使用位也被置为1。对于页替换算法，用于替换的候选帧集合看做一个循环缓冲区，并且有一个指针与之相关联。当某一页被替换时，该指针被设置成指向缓冲区中的下一帧。当需要替换一页时，操作系统扫描缓冲区，以查找使用位被置为0的一帧。每当遇到一个使用位为1的帧时，操作系统就将该位重新置为0；如果在这个过程开始时，缓冲区中所有帧的使用位均为0，则选择遇到的第一个帧替换；如果所有帧的使用位均为1,则指针在缓冲区中完整地循环一周，把所有使用位都置为0，并且停留在最初的位置上，替换该帧中的页。由于该算法循环地检查各页面的情况，故称为CLOCK算法，又称为最近未用(Not Recently Used, NRU)算法。 CLOCK算法的性能比较接近LRU，而通过增加使用的位数目，可以使得CLOCK算法更加高效。在使用位的基础上再增加一个修改位，则得到改进型的CLOCK置换算法。这样，每一帧都处于以下四种情况之一： 最近未被访问，也未被修改(u=0, m=0)。 最近被访问，但未被修改(u=1, m=0)。 最近未被访问，但被修改(u=0, m=1)。 最近被访问，被修改(u=1, m=1)。 算法执行如下操作步骤： 从指针的当前位置开始，扫描帧缓冲区。在这次扫描过程中，对使用位不做任何修改。选择遇到的第一个帧(u=0, m=0)用于替换。 如果第1)步失败，则重新扫描，查找(u=0, m=1)的帧。选择遇到的第一个这样的帧用于替换。在这个扫描过程中，对每个跳过的帧，把它的使用位设置成0。 如果第2)步失败，指针将回到它的最初位置，并且集合中所有帧的使用位均为0。重复第1步，并且如果有必要，重复第2步。这样将可以找到供替换的帧。 改进型的CLOCK算法优于简单CLOCK算法之处在于替换时首选没有变化的页。由于修改过的页在被替换之前必须写回，因而这样做会节省时间。 页面分配策略：驻留集大小、调入页面的时机以及从何处调入页面驻留集大小对于分页式的虚拟内存，在准备执行时，不需要也不可能把一个进程的所有页都读取到主存，因此，操作系统必须决定读取多少页。也就是说，给特定的进程分配多大的主存空间，这需要考虑以下几点： 分配给一个进程的存储量越小，在任何时候驻留在主存中的进程数就越多，从而可以提高处理机的时间利用效率。 如果一个进程在主存中的页数过少，尽管有局部性原理，页错误率仍然会相对较高。 如桌页数过多，由于局部性原理，给特定的进程分配更多的主存空间对该进程的错误率没有明显的影响。 基于这些因素，现代操作系统通常釆用三种策略： 固定分配局部置换。它为每个进程分配一定数目的物理块，在整个运行期间都不改变。若进程在运行中发生缺页，则只能从该进程在内存中的页面中选出一页换出，然后再调入需要的页面。实现这种策略难以确定为每个进程应分配的物理块数目：太少会频繁出现缺页中断，太多又会使CPU和其他资源利用率下降。 可变分配全局置换。这是最易于实现的物理块分配和置换策略，为系统中的每个进程分配一定数目的物理块,操作系统自身也保持一个空闲物理块队列。当某进程发生缺页时，系统从空闲物理块队列中取出一个物理块分配给该进程，并将欲调入的页装入其中。 可变分配局部置换。它为每个进程分配一定数目的物理块，当某进程发生缺页时，只允许从该进程在内存的页面中选出一页换出，这样就不会影响其他进程的运行。如果进程在运行中频繁地缺页，系统再为该进程分配若干物理块，直至该进程缺页率趋于适当程度； 反之，若进程在运行中缺页率特别低，则可适当减少分配给该进程的物理块。 调入页面的时机为确定系统将进程运行时所缺的页面调入内存的时机，可釆取以下两种调页策略： 预调页策略。根据局部性原理，一次调入若干个相邻的页可能会比一次调入一页更高效。但如果调入的一批页面中大多数都未被访问，则又是低效的。所以就需要釆用以预测为基础的预调页策略，将预计在不久之后便会被访问的页面预先调入内存。但目前预调页的成功率仅约50%。故这种策略主要用于进程的首次调入时，由程序员指出应该先调入哪些页。 请求调页策略。进程在运行中需要访问的页面不在内存而提出请求，由系统将所需页面调入内存。由这种策略调入的页一定会被访问，且这种策略比较易于实现，故在目前的虚拟存储器中大多釆用此策略。它的缺点在于每次只调入一页，调入调出页面数多时会花费过多的I/O开销。 从何处调入页面请求分页系统中的外存分为两部分：用于存放文件的文件区和用于存放对换页面的对换区。对换区通常是釆用连续分配方式，而文件区釆用离散分配方式，故对换区的磁盘I/O速度比文件区的更快。这样从何处调入页面有三种情况： 系统拥有足够的对换区空间：可以全部从对换区调入所需页面，以提髙调页速度。为此，在进程运行前，需将与该进程有关的文件从文件区复制到对换区。 系统缺少足够的对换区空间：凡不会被修改的文件都直接从文件区调入；而当换出这些页面时，由于它们未被修改而不必再将它们换出。但对于那些可能被修改的部分，在将它们换出时须调到对换区，以后需要时再从对换区调入。 UNIX方式：与进程有关的文件都放在文件区，故未运行过的页面，都应从文件区调入。曾经运行过但又被换出的页面，由于是被放在对换区，因此下次调入时应从对换区调入。进程请求的共享页面若被其他进程调入内存，则无需再从对换区调入。 页面抖动(颠簸)和工作集(驻留集)页面抖动（颠簸）在页面置换过程中的一种最糟糕的情形是，刚刚换出的页面马上又要换入主存，刚刚换入的页面马上就要换出主存，这种频繁的页面调度行为称为抖动，或颠簸。如果一个进程在换页上用的时间多于执行时间，那么这个进程就在颠簸。 频繁的发生缺页中断（抖动），其主要原因是某个进程频繁访问的页面数目高于可用的物理页帧数目。虚拟内存技术可以在内存中保留更多的进程以提髙系统效率。在稳定状态，几乎主存的所有空间都被进程块占据，处理机和操作系统可以直接访问到尽可能多的进程。但如果管理不当，处理机的大部分时间都将用于交换块，即请求调入页面的操作，而不是执行进程的指令，这就会大大降低系统效率。 工作集（驻留集）工作集（或驻留集）是指在某段时间间隔内，进程要访问的页面集合。经常被使用的页面需要在工作集中，而长期不被使用的页面要从工作集中被丢弃。为了防止系统出现抖动现象，需要选择合适的工作集大小。 工作集模型的原理是：让操作系统跟踪每个进程的工作集，并为进程分配大于其工作集的物理块。如果还有空闲物理块，则可以再调一个进程到内存以增加多道程序数。如果所有工作集之和增加以至于超过了可用物理块的总数，那么操作系统会暂停一个进程，将其页面调出并且将其物理块分配给其他进程，防止出现抖动现象。 正确选择工作集的大小，对存储器的利用率和系统吞吐量的提嵩，都将产生重要影响。 内存管理知识点总结分页管理方式和分段管理方式在很多地方相似，比如内存中都是不连续的、都有地址变 换机构来进行地址映射等。但两者也存在着许多区别，下表（分页管理方式和分段管理方式的比较）列出了分页管理方式和分段管理方式在各个方面的对比。]]></content>
      <categories>
        <category>计算机</category>
        <category>操作系统</category>
        <category>内存管理</category>
      </categories>
      <tags>
        <tag>计算机</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[主存储器]]></title>
    <url>%2F2019%2F06%2F08%2F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[内存管理包括内存管理和虚拟内存管理。 内存管理包括:内存管理概念、交换与覆盖、连续分配管理方式和非连续分配管理方式（分页管理方式、分段管理方式、段页式管理方式）。虚拟内存管理包括:虚拟内存概念、请求分页管理方式、页面置换算法、页面分配策略、工作集和抖动。 内存管理的概念内存管理(Memory Management)是操作系统设计中最重要和最复杂的内容之一。虽然计算机硬件一直在飞速发展，内存容量也在不断增长，但是仍然不可能将所有用户进程和系统所需要的全部程序和数据放入主存中，所以操作系统必须将内存空间进行合理地划分和有效地动态分配。操作系统对内存的划分和动态分配，就是内存管理的概念。 有效的内存管理在多道程序设计中非常重要，不仅方便用户使用存储器、提高内存利用率，还可以通过虚拟技术从逻辑上扩充存储器。 内存管理的功能有： 内存空间的分配与回收：由操作系统完成主存储器空间的分配和管理，使程序员摆脱存储分配的麻烦，提高编程效率。 地址转换：在多道程序环境下，程序中的逻辑地址与内存中的物理地址不可能一致，因此存储管理必须提供地址变换功能，把逻辑地址转换成相应的物理地址。 内存空间的扩充：利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存。 存储保护：保证各道作业在各自的存储空间内运行，.互不干扰。 在进行具体的内存管理之前，需要了解进程运行的基本原理和要求。 程序装入和链接创建进程首先要将程序和数据装入内存。将用户源程序变为可在内存中执行的程序，通常需要以下几个步骤： 编译：由编译程序将用户源代码编译成若干个目标模块。 链接：由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完整的装入模块。 装入：由装入程序将装入模块装入内存运行。 对用户程序的处理步骤 程序的链接有以下三种方式： 静态链接：在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的可执行程序，以后不再拆开。 装入时动态链接：将用户源程序编译后所得到的一组目标模块，在装入内存时，釆用边装入边链接的链接方式。 运行时动态链接：对某些目标模块的链接，是在程序执行中需要该目标模块时，才对它进行的链接。其优点是便于修改和更新，便于实现对目标模块的共享。 内存的装入模块在装入内存时，同样有以下三种方式： 1.绝对装入。在编译时，如果知道程序将驻留在内存的某个位置，编译程序将产生绝对地址的目标代码。绝对装入程序按照装入模块中的地址，将程序和数据装入内存。由于程序中的逻辑地址与实际内存地址完全相同，故不需对程序和数据的地址进行修改。 绝对装入方式只适用于单道程序环境。另外，程序中所使用的绝对地址,可在编译或汇编时给出，也可由程序员直接赋予。而通常情况下在程序中釆用的是符号地址，编译或汇编时再转换为绝对地址。 2.可重定位装入。在多道程序环境下，多个目标模块的起始地址通常都是从0开始，程序中的其他地址都是相对于起始地址的,此时应釆用可重定位装入方式。根据内存的当前情况，将装入模块装入到内存的适当位置。装入时对目标程序中指令和数据的修改过程称为重定位，地址变换通常是在装入时一次完成的，所以又称为静态重定位 静态重定位的特点是在一个作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，就不能装入该作业。此外，作业一旦进入内存后，在整个运行期间不能在内存中移动，也不能再申请内存空间。 3.动态运行时装入，也称为动态重定位，程序在内存中如果发生移动，就需要釆用动态的装入方式。装入程序在把装入模块装入内存后，并不立即把装入模块中的相对地址转换为绝对地址，而是把这种地址转换推迟到程序真正要执行时才进行。因此，装入内存后的所有地址均为相对地址。这种方式需要一个重定位寄存器的支持 动态重定位的特点是可以将程序分配到不连续的存储区中；在程序运行之前可以只装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存；便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间。重定向类型 逻辑地址空间与物理地址空间编译后，每个目标模块都是从0号单元开始编址，称为该目标模块的相对地址（或逻辑地址)。当链接程序将各个模块链接成一个完整的可执行目标程序时，链接程序顺序依次按各个模块的相对地址构成统一的从0号单元开始编址的逻辑地址空间。用户程序和程序员只需知道逻辑地址，而内存管理的具体机制则是完全透明的，它们只有系统编程人员才会涉及。不同进程可以有相同的逻辑地址，因为这些相同的逻辑地址可以映射到主存的不同位置。 物理地址空间是指内存中物理单元的集合，它是地址转换的最终地址，进程在运行时执行指令和访问数据最后都要通过物理地址从主存中存取。当装入程序将可执行代码装入内存时，必须通过地址转换将逻辑地址转换成物理地址，这个过程称为地址重定位。 内存保护内存分配前，需要保护操作系统不受用户进程的影响，同时保护用户进程不受其他用户进程的影响。通过釆用重定位寄存器和界地址寄存器来实现这种保护。重定位寄存器含最小的物理地址值，界地址寄存器含逻辑地址值。每个逻辑地址值必须小于界地址寄存器；内存管理机构动态地将逻辑地址与界地址寄存器进行比较，如果未发生地址越界，则加上重定位寄存器的值后映射成物理地址，再送交内存单元，如图3-3所示。 当CPU调度程序选择进程执行时，派遣程序会初始化重定位寄存器和界地址寄存器。每一个逻辑地址都需要与这两个寄存器进行核对，以保证操作系统和其他用户程序及数据不被该进程的运行所影响。 内存覆盖与内存交换覆盖与交换技术是在多道程序环境下用来扩充内存的两种方法。 内存覆盖早期的计算机系统中，主存容量很小，虽然主存中仅存放一道用户程序，但是存储空间放不下用户进程的现象也经常发生，这一矛盾可以用覆盖技术来解决。 覆盖的基本思想是：由于程序运行时并非任何时候都要访问程序及数据的各个部分（尤其是大程序），因此可以把用户空间分成一个固定区和若干个覆盖区。将经常活跃的部分放在固定区，其余部分按调用关系分段。首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统再将其调入覆盖区，替换覆盖区中原有的段。 覆盖技术的特点是打破了必须将一个进程的全部信息装入主存后才能运行的限制，但当同时运行程序的代码量大于主存时仍不能运行。 内存交换交换（对换）的基本思想是，把处于等待状态（或在CPU调度原则下被剥夺运行权利）的程序从内存移到辅存，把内存空间腾出来，这一过程又叫换出；把准备好竞争CPU运行的程序从辅存移到内存，这一过程又称为换入。中级调度就是釆用交换技术。 例如，有一个CPU釆用时间片轮转调度算法的多道程序环境。时间片到，内存管理器将刚刚执行过的进程换出，将另一进程换入到刚刚释放的内存空间中。同时，CPU调度器可以将时间片分配给其他已在内存中的进程。每个进程用完时间片都与另一进程交换。理想情况下，内存管理器的交换过程速度足够快，总有进程在内存中可以执行。 有关交换需要注意以下几个问题： 交换需要备份存储，通常是快速磁盘。它必须足够大，并且提供对这些内存映像的直接访问。 为了有效使用CPU，需要每个进程的执行时间比交换时间长，而影响交换时间的主要是转移时间。转移时间与所交换的内存空间成正比。 如果换出进程，必须确保该进程是完全处于空闲状态。 交换空间通常作为磁盘的一整块，且独立于文件系统，因此使用就可能很快。 交换通常在有许多进程运行且内存空间吃紧时开始启动，而系统负荷降低就暂停。 普通的交换使用不多，但交换策略的某些变种在许多系统中（如UNIX系统）仍发挥作用。 交换技术主要是在不同进程（或作业）之间进行，而覆盖则用于同一个程序或进程中。由于覆盖技术要求给出程序段之间的覆盖结构，使得其对用户和程序员不透明，所以对于主存无法存放用户程序的矛盾，现代操作系统是通过虚拟内存技术来解决的，覆盖技术则已成为历史；而交换技术在现代操作系统中仍具有较强的生命力。 内存连续分配管理方式连续分配方式，是指为一个用户程序分配一个连续的内存空间。它主要包括单一连续分配、固定分区分配和动态分区分配。 单一连续分配内存在此方式下分为系统区和用户区，系统区仅提供给操作系统使用，通常在低地址部分；用户区是为用户提供的、除系统区之外的内存空间。这种方式无需进行内存保护。 这种方式的优点是简单、无外部碎片，可以釆用覆盖技术，不需要额外的技术支持。缺点是只能用于单用户、单任务的操作系统中，有内部碎片，存储器的利用率极低。 固定分区分配固定分区分配是最简单的一种多道程序存储管理方式，它将用户内存空间划分为若干个固定大小的区域，每个分区只装入一道作业。当有空闲分区时，便可以再从外存的后备作业队列中,选择适当大小的作业装入该分区，如此循环。 固定分区分配在划分分区时，有两种不同的方法 分区大小相等：用于利用一台计算机去控制多个相同对象的场合，缺乏灵活性。 分区大小不等：划分为含有多个较小的分区、适量的中等分区及少量的大分区。 为便于内存分配，通常将分区按大小排队，并为之建立一张分区说明表，其中各表项包括每个分区的起始地址、大小及状态（是否已分配）。当有用户程序要装入时，便检索该表，以找到合适的分区给予分配并将其状态置为”已分配”；未找到合适分区则拒绝为该用户程序分配内存。 这种分区方式存在两个问题：一是程序可能太大而放不进任何一个分区中，这时用户不得不使用覆盖技术来使用内存空间；二是主存利用率低，当程序小于固定分区大小时，也占用了一个完整的内存分区空间，这样分区内部有空间浪费，这种现象称为内部碎片。 固定分区是可用于多道程序设计最简单的存储分配，无外部碎片，但不能实现多进程共享一个主存区，所以存储空间利用率低。固定分区分配很少用于现在通用的操作系统中，但在某些用于控制多个相同对象的控制系统中仍发挥着一定的作用。 动态分区分配动态分区分配又称为可变分区分配，是一种动态划分内存的分区方法。这种分区方法不预先将内存划分，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。因此系统中分区的大小和数目是可变的。 动态分区在开始分配时是很好的，但是之后会导致内存中出现许多小的内存块。随着时间的推移，内存中会产生越来越多的碎片，内存的利用率随之下降。这些小的内存块称为外部碎片，指在所有分区外的存储空间会变成越来越多的碎片，这与固定分区中的内部碎片正好相对。克服外部碎片可以通过紧凑（Compaction)技术来解决，就是操作系统不时地对进程进行移动和整理。但是这需要动态重定位寄存器的支持，且相对费时。紧凑的过程实际上类似于Windows系统中的磁盘整理程序，只不过后者是对外存空间的紧凑。 在进程装入或换入主存时，如果内存中有多个足够大的空闲块，操作系统必须确定分配哪个内存块给进程使用，这就是动态分区的分配策略，考虑以下几种算法： 首次适应(First Fit)算法：空闲分区以地址递增的次序链接。分配内存时顺序查找，找到大小能满足要求的第一个空闲分区。 最佳适应(Best Fit)算法：空闲分区按容量递增形成分区链，找到第一个能满足要求的空闲分区。 最坏适应(Worst Fit)算法：又称最大适应(Largest Fit)算法，空闲分区以容量递减的次序链接。找到第一个能满足要求的空闲分区，也就是挑选出最大的分区。 邻近适应(Next Fit)算法：又称循环首次适应算法，由首次适应算法演变而成。不同之处是分配内存时从上次查找结束的位置开始继续查找。 在这几种方法中，首次适应算法不仅是最简单的，而且通常也是最好和最快的。在UNIX 系统的最初版本中，就是使用首次适应算法为进程分配内存空间，其中使用数组的数据结构 (而非链表）来实现。不过，首次适应算法会使得内存的低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。邻近适应算法试图解决这个问题，但实际上，它常常会导致在内存的末尾分配空间（因为在一遍扫描中，内存前面部分使用后再释放时，不会参与分配)，分裂成小碎片。它通常比首次适应算法的结果要差。最佳适应算法虽然称为“最佳”，但是性能通常很差，因为每次最佳的分配会留下很小的难以利用的内存块，它会产生最多的外部碎片。最坏适应算法与最佳适应算法相反，选择最大的可用块，这看起来最不容易产生碎片，但是却把最大的连续内存划分开，会很快导致没有可用的大的内存块，因此性能也非常差。 Kunth和Shore分别就前三种方法对内存空间的利用情况做了模拟实验，结果表明：首次适应算法可能比最佳适应法效果好，而它们两者一定比最大适应法效果好。另外注意,在算法实现时,分配操作中最佳适应法和最大适应法需要对可用块进行排序或遍历查找，而首次适应法和邻近适应法只需要简单查找；回收操作中，当回收的块与原来的空闲块相邻时（有三种相邻的情况，比较复杂)，需要将这些块合并。在算法实现时，使用数组或链表进行管理。除了内存的利用率，这里的算法开销也是操作系统设计需要考虑的一个因素。 内存非连续分配管理方式非连续分配允许一个程序分散地装入到不相邻的内存分区中，根据分区的大小是否固定分为分页存储管理方式和分段存储管理方式。 分页存储管理方式中，又根据运行作业时是否要把作业的所有页面都装入内存才能运行分为基本分页存储管理方式和请求分页存储管理方式。下面介绍基本分页存储管理方式。 基本分页存储管理方式固定分区会产生内部碎片，动态分区会产生外部碎片，这两种技术对内存的利用率都比较低。我们希望内存的使用能尽量避免碎片的产生，这就引入了分页的思想：把主存空间划分为大小相等且固定的块，块相对较小，作为主存的基本单位。每个进程也以块为单位进行划分，进程在执行时，以块为单位逐个申请主存中的块空间。 分页的方法从形式上看，像分区相等的固定分区技术，分页管理不会产生外部碎片。但它又有本质的不同点：块的大小相对分区要小很多，而且进程也按照块进行划分，进程运行时按块申请主存可用空间并执行。这样，进程只会在为最后一个不完整的块申请一个主存块空间时，才产生主存碎片，所以尽管会产生内部碎片，但是这种碎片相对于进程来说也是很小的，每个进程平均只产生半个块大小的内部碎片（也称页内碎片）。 分页存储的几个基本概念页面和页面大小进程中的块称为页(Page)，内存中的块称为页框（Page Frame，或页帧）。外存也以同样的单位进行划分，直接称为块(Block)。进程在执行时需要申请主存空间，就是要为每个页面分配主存中的可用页框，这就产生了页和页框的一一对应。为方便地址转换，页面大小应是2的整数幂。同时页面大小应该适中，如果页面太小，会使进程的页面数过多，这样页表就过长，占用大量内存，而且也会增加硬件地址转换的开销，降低页面换入/换出的效率；页面过大又会使页内碎片增大，降低内存的利用率。所以页面的大小应该适中，考虑到耷间效率和时间效率的权衡。 地址结构分页存储管理的地址结构地址结构包含两部分：前一部分为页号P，后一部分为页内偏移量W。地址长度为32位，其中0~11位为页内地址，即每页大小为4KB；12~31位为页号，地址空间最多允许有2^20页。 页表为了便于在内存中找到进程的每个页面所对应的物理块，系统为每个进程建立一张页表，记录页面在内存中对应的物理块号，页表一般存放在内存中。 在配置了页表后，进程执行时，通过查找该表，即可找到每页在内存中的物理块号。可见，页表的作用是实现从页号到物理块号的地址映射。 页表的作用 基本地址变换机构地址变换机构的任务是将逻辑地址转换为内存中物理地址，地址变换是借助于页表实现的。 在系统中通常设置一个页表寄存器(PTR)，存放页表在内存的始址F和页表长度M。进程未执行时，页表的始址和长度存放在进程控制块中，当进程执行时，才将页表始址和长度存入页表寄存器。设页面大小为L，逻辑地址A到物理地址E的变换过程如下：1.计算页号P(P=A/L)和页内偏移量W(W=A%L)。2.比较页号P和页表长度M，若P&gt;=M，则产生越界中断，否则继续执行。3.页表中页号P对应的页表项地址=页表起始地址F+页号P*页表项长度，取出该页表项内容b，即为物理块号。计算E=b*L+W，用得到的物理地址E去访问内存。 以上整个地址变换过程均是由硬件自动完成的。 如，若页面大小L为1K字节，页号2对应的物理块为b=8，计算逻辑地址A=2500 的物理地址E的过程如下：P=2500/1K=2，W=2500%1K=452，查找得到页号2对应的物理块的块号为 8，E=8*1024+452=8644。 分页存储管理的地址变换机构 下面讨论分页管理方式存在的两个主要问题： 每次访存操作都需要进行逻辑地址到物理地址的转换，地址转换过程必须足够快，否则访存速度会降低； 每个进程引入了页表，用于存储映射机制，页表不能太大，否则内存利用率会降低。 具有快表的地址变换机构由上面介绍的地址变换过程可知，若页表全部放在内存中，则存取一个数据或一条指令至少要访问两次内存：一次是访问页表，确定所存取的数据或指令的物理地址，第二次才根据该地址存取数据或指令。显然，这种方法比通常执行指令的速度慢了一半。 为此，在地址变换机构中增设了一个具有并行查找能力的高速缓冲存储器——快表，又称联想寄存器(TLB)，用来存放当前访问的若干页表项，以加速地址变换的过程。与此对应，主存中的页表也常称为慢表。具有快表的地址变换机构 在具有快表的分页机制中，地址的变换过程： CPU给出逻辑地址后，由硬件进行地址转换并将页号送入高速缓存寄存器，并将此页号与快表中的所有页号进行比较。 如果找到匹配的页号，说明所要访问的页表项在快表中，则直接从中取出该页对应的页框号，与页内偏移量拼接形成物理地址。这样，存取数据仅一次访存便可实现。 如果没有找到，则需要访问主存中的页表，在读出页表项后，应同时将其存入快表，以便后面可能的再次访问。但若快表已满，则必须按照一定的算法对旧的页表项进行替换。 注意：有些处理机设计为快表和慢表同时查找，如果在快表中查找成功则终止慢表的查找。 一般快表的命中率可以达到90%以上，这样，分页带来的速度损失就降低到10%以下。快表的有效性是基于著名的局部性原理，这在后面的虚拟内存中将会具体讨论。 两级页表第二个问题：由于引入了分页管理，进程在执行时不需要将所有页调入内存页框中，而只要将保存有映射关系的页表调入内存中即可。但是我们仍然需要考虑页表的大小。以32 位逻辑地址空间、页面大小4KB、页表项大小4B为例，若要实现进程对全部逻辑地址空间的映射，则每个进程需要2^20，约100万个页表项。也就是说，每个进程仅页表这一项就需要4MB主存空间，这显然是不切实际的。而即便不考虑对全部逻辑地址空间进行映射的情况，一个逻辑地址空间稍大的进程，其页表大小也可能是过大的。以一个40MB的进程为例，页表项共40KB,如果将所有页表项内容保存在内存中，那么需要10个内存页框来保存整个页表。整个进程大小约为1万个页面，而实际执行时只需要几十个页面进入内存页框就可以运行，但如果要求10个页面大小的页表必须全部进入内存，这相对实际执行时的几十个进程页面的大小来说，肯定是降低了内存利用率的；从另一方面来说，这10页的页表项也并不需要同时保存在内存中，因为大多数情况下，映射所需要的页表项都在页表的同一个页面中。 将页表映射的思想进一步延伸，就可以得到二级分页：将页表的10页空间也进行地址映射，建立上一级页表，用于存储页表的映射关系。这里对页表的10个页面进行映射只需要10个页表项，所以上一级页表只需要1页就足够（可以存储2^10=1024个页表项）。在进程执行时，只需要将这1页的上一级页表调入内存即可，进程的页表和进程本身的页面，可以在后面的执行中再i周入内存。如下图所示，这是Intel处理器80x86系列的硬件分页的地址转换过程。在32位系统中，全部32位逻辑地址空间可以分为2^20 (4GB/4KB)个页面。这些页面可以再进一步建立顶级页表，需要2^10个顶级页表项进行索引，这正好是一页的大小，所以建立二级页表即可。硬件分页地址转换 举例，32位系统中进程分页的工作过程：假定内核已经给一个正在运行的进程分配的逻辑地址空间是0x20000000到0x2003FFFF，这个空间由64个页面组成。在进程运行时，我们不需要知道全部这些页的页框的物理地址，很可能其中很多页还不在主存中。这里我们只注意在进程运行到某一页时，硬件是如何计算得到这一页的页框的物理地址即可。现在进程需要读逻辑地址0x20021406中的字节内容，这个逻辑地址按如下进行处理： 逻辑地址： 0x20021406 (0010 0000 0000 0010 0001 0100 0000 0110 B) 顶级页表字段：0x80 (00 1000 0000 B) 二级页表字段：0x21 (00 0010 0001B) 页内偏移量字段：0x406 (0100 0000 0110 B) 顶级页表字段的0x80用于选择顶级页表的第0x80表项，此表项指向和该进程的页相关的二级页表；二级页表字段0x21用于选择二级页表的第0x21表项，此表项指向包含所需页的页框；最后的页内偏移量字段0x406用于在目标页框中读取偏移量为0x406中的字节。 这是32位系统下比较实际的一个例子。看似较为复杂的例子，有助于比较深入地理解，希望读者能自己动手计算一遍转换过程。 建立多级页表的目的在于建立索引，这样不用浪费主存空间去存储无用的页表项，也不用盲目地顺序式查找页表项，而建立索引的要求是最高一级页表项不超过一页的大小。在 64位操作系统中，页表的划分则需要重新考虑，这是很多教材和辅导书中的常见题目，但是很多都给出了错误的分析，需要注意。 我们假设仍然釆用4KB页面大小。偏移量字段12位，假设页表项大小为8B。这样，其上一级分页时，每个页框只能存储29(4KB/8B)个页表项，而不再是210个，所以上一级页表字段为9位。后面同理继续分页。64=12+9+9+9+9+9+7，所以需6级分页才能实现索引。很多书中仍然按4B页表项分析，虽然同样得出6级分页的结果，但显然是错误的。这里给出两个实际的64位操作系统的分页级别（注意：里面没有使用全部64位寻址，不过由于地址字节对齐的设计考虑，仍然使用8B大小的页表项），理解了表3-2中的分级方式，相信对多级分页就非常清楚了。 基本分段存储管理方式分页管理方式是从计算机的角度考虑设计的，以提高内存的利用率，提升计算机的性能, 且分页通过硬件机制实现，对用户完全透明；而分段管理方式的提出则是考虑了用户和程序员，以满足方便编程、信息保护和共享、动态增长及动态链接等多方面的需要。 分段。段式管理方式按照用户进程中的自然段划分逻辑空间。例如，用户进程由主程序、两个子程序、栈和一段数据组成，于是可以把这个用户进程划分为5个段，每段从0 开始编址，并分配一段连续的地址空间（段内要求连续，段间不要求连续，因此整个作业的地址空间是二维的）。其逻辑地址由段号S与段内偏移量W两部分组成。 在页式系统中，逻辑地址的页号和页内偏移量对用户是透明的，但在段式系统中，段号和段内偏移量必须由用户显示提供，在髙级程序设计语言中，这个工作由编译程序完成。 段表。每个进程都有一张逻辑空间与内存空间映射的段表，其中每一个段表项对应进程的一个段，段表项记录该段在内存中的起始地址和段的长度。段表项在配置了段表后，执行中的进程可通过查找段表，找到每个段所对应的内存区。可见，段表用于实现从逻辑段到物理内存区的映射。 地址变换机构。为了实现进程从逻辑地址到物理地址的变换功能，在系统中设置了段表寄存器，用于存放段表始址F和段表长度M。其从逻辑地址A到物理地址E之间的地址变换过程如下： 从逻辑地址A中取出前几位为段号S，后几位为段内偏移量W。 比较段号S和段表长度M，若S多M，则产生越界中断，否则继续执行。 段表中段号S对应的段表项地址=段表起始地址F+段号S*段表项长度，取出该段表项的前几位得到段长C。若段内偏移量&gt;=C，则产生越界中断，否则继续执行。 取出段表项中该段的起始地址b，计算E=b+W，用得到的物理地址E去访问内存。 段的共享与保护。在分段系统中，段的共享是通过两个作业的段表中相应表项指向被共享的段的同一个物理副本来实现的。当一个作业正从共享段中读取数据时，必须防止另一个作业修改此共享段中的数据。不能修改的代码称为纯代码或可重入代码（它不属于临界资源)，这样的代码和不能修改的数据是可以共享的，而可修改的代码和数据则不能共享。 与分页管理类似，分段管理的保护方法主要有两种：一种是存取控制保护，另一种是地址越界保护。地址越界保护是利用段表寄存器中的段表长度与逻辑地址中的段号比较，若段号大于段表长度则产生越界中断；再利用段表项中的段长和逻辑地址中的段内位移进行比较，若段内位移大于段长，也会产生越界中断。 段页式管理方式页式存储管理能有效地提高内存利用率，而分段存储管理能反映程序的逻辑结构并有利于段的共享。如果将这两种存储管理方法结合起来，就形成了段页式存储管理方式。 在段页式系统中，作业的地址空间首先被分成若干个逻辑段，每段都有自己的段号，然后再将每一段分成若干个大小固定的页。对内存空间的管理仍然和分页存储管理一样，将其分成若干个和页面大小相同的存储块，对内存的分配以存储块为单位。段页式管理方式在段页式系统中，作业的逻辑地址分为三部分：段号、页号和页内偏移量。 为了实现地址变换，系统为每个进程建立一张段表，而每个分段有一张页表。段表表项中至少包括段号、页表长度和页表起始地址，页表表项中至少包括页号和块号。此外，系统中还应有一个段表寄存器，指出作业的段表起始地址和段表长度。 注意：在一个进程中，段表只有一个，而页表可能有多个。 在进行地址变换时，首先通过段表查到页表起始地址，然后通过页表找到页帧号，最后形成物理地址。如下图所示，进行一次访问实际需要三次访问主存，这里同样可以使用快表以加快查找速度，其关键字由段号、页号组成，值是对应的页帧号和保护码。段页式系统的地址变换机构]]></content>
      <categories>
        <category>计算机</category>
        <category>操作系统</category>
        <category>内存管理</category>
      </categories>
      <tags>
        <tag>计算机</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[死锁]]></title>
    <url>%2F2019%2F06%2F06%2F%E6%AD%BB%E9%94%81%2F</url>
    <content type="text"><![CDATA[死锁的定义在多道程序系统中，由于多个进程的并发执行，改善了系统资源的利用率并提高了系统的处理能力。然而，多个进程的并发执行也带来了新的问题——死锁。所谓死锁是指多个进程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都将无法向前推进。 先看生活中的一个实例，在一条河上有一座桥，桥面很窄，只能容纳一辆汽车通行。如果有两辆汽车分别从桥的左右两端驶上该桥，则会出现下述的冲突情况。此时，左边的汽车占有了桥面左边的一段，要想过桥还需等待右边的汽车让出桥面右边的一段；右边的汽车占有了桥面右边的一段，要想过桥还需等待左边的汽车让出桥面左边的一段。此时，若左右两边的汽车都只能向前行驶，则两辆汽车都无法过桥。在计算机系统中也存在类似的情况。例如，某计算机系统中只有一台打印机和一台输入设备，进程P1正占用输入设备，同时又提出使用打印机的请求，但此时打印机正被进程P2 所占用，而P2在未释放打印机之前，又提出请求使用正被P1占用着的输入设备。这样两个进程相互无休止地等待下去，均无法继续执行，此时两个进程陷入死锁状态。 产生死锁的四大必要条件①资源互斥/资源不共享每个资源要么已经分配给了一个进程，要么是可用的，只有这两种状态，资源不可以被共享使用，所以所谓的互斥是指：资源不共享，如果被使用，只能被一个进程使用。 ②占有和等待/请求并保持已经得到资源的进程还能继续请求新的资源，所以个人觉得叫占有并请求也许更好理解。 ③资源不可剥夺当一个资源分配给了一个进程后，其它需要该资源的进程不能强制性获得该资源，除非该资源的当前占有者显示地释放该资源。 ④环路等待死锁发生时，系统中一定有由两个或两个以上的进程组成的一条环路，环路上的每个进程都在等待下一个进程所占有的资源。 解决死锁的方法 预防死锁（破坏产生死锁的条件） 避免死锁（银行家算法） 检测死锁（资源分配图） 解除死锁 第三条与第四条一般联合使用 防止死锁的方法 ①防止死锁的发生只需破坏死锁产生的四个必要条件之一即可。②下面的方法开销非常之大，目前没有一个操作系统可以实现。③因此，目前使用的方法是避免死锁，而不是防止死锁。④这部分的内容大致浏览简单了解一遍即可，只要能在某些选择题中判断出选项对应的是下面四个方法中的哪个就可以了。 破坏互斥条件方法：如果允许系统资源都能共享使用，则系统不会进入死锁状态。缺点：有些资源根本不能同时访问，如打印机等临界资源只能互斥使用。所以，破坏互斥条件而预防死锁的方法不太可行，而且在有的场合应该保护这种互斥性。 破坏请求并保持条件方法：釆用预先静态分配方法，即进程在运行前一次申请完它所需要的全部资源，在它的资源未满足前，不把它投入运行。一旦投入运行后，这些资源就一直归它所有，也不再提出其他资源请求，这样就可以保证系统不会发生死锁。缺点：系统资源被严重浪费，其中有些资源可能仅在运行初期或运行快结束时才使用，甚至根本不使用。而且还会导致“饥饿”现象，当由于个别资源长期被其他进程占用时，将致使等待该资源的进程迟迟不能开始运行。 破坏不可剥夺条件方法：当一个已保持了某些不可剥夺资源的进程，请求新的资源而得不到满足时，它必须释放已经保持的所有资源，待以后需要时再重新申请。这意味着，一个进程已占有的资源会被暂时释放，或者说是被剥夺了，或从而破坏了不可剥夺条件。缺点：该策略实现起来比较复杂，释放已获得的资源可能造成前一阶段工作的失效，反复地申请和释放资源会增加系统开销，降低系统吞吐量。这种方法常用于状态易于保存和恢复的资源，如CPU的寄存器及内存资源，一般不能用于打印机之类的资源。 破坏循环等待条件方法：为了破坏循环等待条件，可釆用顺序资源分配法。首先给系统中的资源编号，规定每个进程，必须按编号递增的顺序请求资源，同类资源一次申请完。也就是说，只要进程提出申请分配资源Ri，则该进程在以后的资源申请中，只能申请编号大于Ri的资源。缺点：这种方法存在的问题是，编号必须相对稳定，这就限制了新类型设备的增加；尽管在为资源编号时已考虑到大多数作业实际使用这些资源的顺序，但也经常会发生作业使用资源的顺序与系统规定顺序不同的情况，造成资源的浪费；此外，这种按规定次序申请资源的方法，也必然会给用户的编程带来麻烦。 避免死锁的算法判断“系统安全状态”法在进行系统资源分配之前，先计算此次资源分配的安全性。若此次分配不会导致系统进入不安全状态，则将资源分配给进程； 否则，让进程等待。 银行家算法1、申请的贷款额度不能超过银行现有的资金总额2、分批次向银行提款，但是贷款额度不能超过一开始最大需求量的总额3、暂时不能满足客户申请的资金额度时，在有限时间内给予贷款4、客户要在规定的时间内还款 死锁的检测 该部分讲述如何判断是否产生死锁 画出资源分配图系统死锁，可利用资源分配图来描述。如下图所示，用长方形代表一个进程，用框代表一类资源。由于一种类型的资源可能有多个，用框中的一个点代表一类资源中的一个资源。从进程到资源的有向边叫请求边，表示该进程申请一个单位的该类资源；从资源到进程的边叫分配边，表示该类资源已经有一个资源被分配给了该进程。 简化资源分配图第一步：先看A资源，它有三个箭头是向外的，因此它一共给进程分配了3个资源，此时，A没有空闲的资源剩余。第二步：再看B资源，它有一个箭头是向外的，因此它一共给进程分配了1个资源，此时，B还剩余一个空闲的资源没分配。第三步：看完资源，再来看进程，先看进程P2，它只申请一个A资源，但此时A资源已经用光了，所以，进程P2进入阻塞状态，因此，进程P2暂时不能化成孤立的点。第四步：再看进程P1，它只申请一个B资源，此时，系统还剩余一个B资源没分配，因此，可以满足P1的申请。这样，进程P1便得到了它的全部所需资源，所以它不会进入阻塞状态，可以一直运行，等它运行完后，我们再把它的所有的资源释放。相当于：可以把P1的所有的边去掉，变成一个孤立的点，如下图所示：第五步：进程P1运行完后，释放其所占有的资源（2个A资源和1个B资源），系统回收这些资源后，空闲的资源便变成2个A资源和1个B资源，由于进程P2一直在申请一个A资源，所以此时，系统能满足它的申请。这样，进程P2便得到了它的全部所需资源，所以它不会进入阻塞状态，可以一直运行，等它运行完后，我们再把它的所有的资源释放。相当于：可以把P2的所有的边都去掉，化成一个孤立的点，变成下图： 若能消去图中所有的边，则称该图是可完全简化的，如上图 使用死锁定理判断死锁定理：①如果资源分配图中没有环路，则系统没有死锁；②如果资源分配图中出现了环路，则系统可能有死锁。或者说：当且仅当S状态的资源分配图是不可完全简化的时候，系统状态则是死锁状态 死锁的解除1、资源剥夺法挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程。但应防止被挂起的进程长时间得不到资源，而处于资源匮乏的状态。 2、撤销进程法强制撤销部分、甚至全部死锁进程并剥夺这些进程的资源。撤销的原则可以按进程优先级和撤销进程代价的高低进行。 3、进程回退法让一（多）个进程回退到足以回避死锁的地步，进程回退时自愿释放资源而不是被剥夺。要求系统保持进程的历史信息，设置还原点。]]></content>
      <categories>
        <category>计算机</category>
        <category>操作系统</category>
        <category>进程管理</category>
      </categories>
      <tags>
        <tag>计算机</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程同步]]></title>
    <url>%2F2019%2F06%2F06%2F%E8%BF%9B%E7%A8%8B%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[进程同步的一些概念 互斥与同步临界资源（临界区）：指一次只能允许一个进程使用的共享资源称为临界资源； 同步：指为完成某种任务而建立的两个和多个进程，这些进程在合作的过程中需要协调工作次序进行有序的访问而出现等待所产生的制约关系。互斥：指两个或多个进程访问临界资源时只能一个进程访问，其他进程等待的一种相互制约的关系。 信号量与互斥量信号量：本身是一个计数器，使用P，V两个操作来实现计数的减与加，当计数不大于0时，则进程进入睡眠状态，它用于为多个进程提供共享数据对象的访问。互斥量：如果信号量只存在两个状态，那就不需要计数了，可以简化为加锁与解锁两个功能，这就是互斥量。 进程同步的四种方法临界区（Critical Section）通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。 优点：保证在某一时刻只有一个线程能访问数据的简便办法缺点：虽然临界区同步速度很快，但却只能用来同步本进程内的线程，而不可用来同步多个进程中的线程。 互斥量（Mutex）为协调共同对一个共享资源的单独访问而设计的。 互斥量跟临界区很相似，比临界区复杂，互斥对象只有一个，只有拥有互斥对象的线程才具有访问资源的权限。 优点：使用互斥不仅仅能够在同一应用程序不同线程中实现资源的安全共享，而且可以在不同应用程序的线程之间实现对资源的安全共享。缺点： ①互斥量是可以命名的，也就是说它可以跨越进程使用，所以创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用量。因为互斥量是跨进程的互斥量一旦被创建，就可以通过名字打开它。②通过互斥量可以指定资源被独占的方式使用，但如果有下面一种情况通过互斥量就无法处理，比如现在一位用户购买了一份三个并发访问许可的数据库系统，可以根据用户购买的访问许可数量来决定有多少个线程/进程能同时进行数据库操作，这时候如果利用互斥量就没有办法完成这个要求，信号量对象可以说是一种资源计数器。 信号量（Semaphore）为控制一个具有有限数量用户资源而设计。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。互斥量是信号量的一种特殊情况，当信号量的最大资源数=1就是互斥量了。 优点：适用于对Socket（套接字）程序中线程的同步。（例如，网络上的HTTP服务器要对同一时间内访问同一页面的用户数加以限制，只有不大于设定的最大用户数目的线程能够进行访问，而其他的访问企图则被挂起，只有在有用户退出对此页面的访问后才有可能进入。）缺点： ①信号量机制必须有公共内存，不能用于分布式操作系统，这是它最大的弱点；②信号量机制功能强大，但使用时对信号量的操作分散， 而且难以控制，读写和维护都很困难，加重了程序员的编码负担；③核心操作P-V分散在各用户程序的代码中，不易控制和管理，一旦错误，后果严重，且不易发现和纠正。 事件（Event）用来通知线程有一些事件已发生，从而启动后继任务的开始。 优点：事件对象通过通知操作的方式来保持线程的同步，并且可以实现不同进程中的线程同步操作。缺点： 总结①临界区不是内核对象，只能用于进程内部的线程同步，是用户方式的同步。互斥、信号量是内核对象可以用于不同进程之间的线程同步（跨进程同步）。②互斥其实是信号量的一种特殊形式。互斥可以保证在某一时刻只有一个线程可以拥有临界资源。信号量可以保证在某一时刻有指定数目的线程可以拥有临界资源。]]></content>
      <categories>
        <category>计算机</category>
        <category>操作系统</category>
        <category>进程管理</category>
      </categories>
      <tags>
        <tag>计算机</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CPU调度]]></title>
    <url>%2F2019%2F06%2F04%2FCPU%E8%B0%83%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[CPU调度即按一定的调度算法从就绪队列中选择一个进程，把CPU的使用权交给被选中的进程，如果没有就绪进程，系统会安排一个系统空闲进程或idle进程。 CPU调度时机发生在内核对中断/异常/系统调用处理后返回到用户态时，具体来说有以下情况： 进程正常终止 或 由于某种错误而终止； 新进程创建 或 一个等待进程变成就绪； 当一个进程从运行态进入阻塞态； 当一个进程从运行态变为就绪态。 进程切换是指一个进程让出处理器，由另一个进程占用处理器的过程，包括以下两部分工作： 切换全局页目录以加载一个新的地址空间； 切换内核栈和硬件上下文，其中硬件上下文包括了内核执行新进程需要的全部信息，如CPU相关寄存器。 CPU调度算法衡量指标 吞吐量 （Throughput）： 每单位时间完成的进程数目； 周转时间TT (Turnaround Time)：每个进程从提出请求到运行完成的时间； 响应时间RT(Response Time)：从提出请求到第一次回应的时间； CPU利用率(CPU Utilization)：CPU做有效工作的时间比例； 等待时间(Waiting time)：每个进程在就绪队列(ready queue)中等待的时间； …… 批处理系统中采用的调度算法 衡量指标：吞吐量，周转时间，CPU利用率，公平平衡 先来先服务算法（FCFS——First Come First Serve）：按照进程就绪的先后顺序使用CPU。特点：非抢占，公平，实现简单，长进程后面的短进程需要等很长时间，不利于用户体验。 最短作业优先（SJF——Shortest Job First）：具有最短完成时间的进程优先执行，非抢占。最短剩余时间优先（SRTN——Shortest Remaining Time Next）：SJF抢占式版本，即当一个新就绪的进程比当前运行进程具有更短完成时间时，系统抢占当前进程，选择新就绪的进程执行。特点：有最短的平均周转时间，但不公平，源源不断的短任务到来，可能使长的任务长时间得不到运行，从而产生 “饥饿”现象 (starvation)。 最高响应比优先算法（HRRN——Highest Response Ratio Next）：是一个综合算法，调度时，首先计算每个进程的响应比R，之后总是选择R最高的进程执行。{响应比R = 周转时间 / 处理时间 =（处理时间 + 等待时间）/ 处理时间 = 1 +（等待时间 / 处理时间）}特点：折中权衡 交互式系统采用的调度算法 衡量指标：响应时间，公平平衡。 时间片轮转调度算法（Round Robin——RR）： 每个进程被分配一个时间片，允许该进程在该时间段运行，如果在时间片结束时该进程还在运行，则剥夺CPU并分配给另一个进程，如果该进程在时间片结RR束前阻塞或结束，则CPU立即进行切换。特点：公平；有利于交互式计算，响应时间快；由于进程切换，时间片轮转算法要花费较高的开销；对进程表中不同进程的大小差异较大的有利，而对进程都是相同大小的不利。 虚拟轮转法（Virtual RR）：主要基于时间片轮转法进行改进，解决在CPU调度中对于I/O密集型进程的不友好。其设置了一个辅助队列，对于I/O型进程执行完一个时间片之后，则进入辅助队列，CPU调度时总是先检查辅助队列是否为空，如果不为空总是优先调度辅助队列里的进程，直到为空，才调度就绪队列的进程。优先级调度算法（Priority Scheduling Algorithm——PSA）即给每个作业一个优先级，优先级越高越紧迫，应该先执行。通常：系统进程优先级高于用户进程；前台进程优先级高于后台进程；操作系统更偏好 I/O型进程。特点：实现简单，但不公平，可能导致优先级低的进程产生饥饿现象；可能产生优先级反转问题（基于优先级的抢占式算法），即一个低优先级进程持有一个高优先级进程所需要的资源，使得高优先级进程等待低优先级进程运行。 多级反馈队列调度算法（Multilevel Feedback）：设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，依次递减优先级。对于各个队列进程执行时间片的大小也不同，优先级越高的队列，分配到的时间片越少。当第一级队列为空时，再第二级队列进行调度，依次类推，各级队列按照时间片轮转方式进行调度。当一个新进程创建后，首先把它放入第一队列的末尾。按照FCFS原则排队等待调度。当轮到该进程执行时，如它在该时间片完成，便可准备撤离系统，如果它在一个时间片结束时尚未完成，则调度程序便将该进程转入第二队列的末尾，再同样地按照FCFS原则等待调度执行。依次类推。特点：更偏好I/O型进程，对CPU型进程不太友好。各种调度算法总结比较：]]></content>
      <categories>
        <category>计算机</category>
        <category>操作系统</category>
        <category>进程管理</category>
      </categories>
      <tags>
        <tag>计算机</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程]]></title>
    <url>%2F2019%2F06%2F03%2F%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[进程和线程的粗略对比线程，程序执行流的最小执行单位，是行程中的实际运作单位，经常容易和进程这个概念混淆。那么，线程和进程究竟有什么区别呢？首先，进程是一个动态的过程，是一个活动的实体。简单来说，一个应用程序的运行就可以被看做是一个进程，而线程，是运行中的实际的任务执行者。可以说，进程中包含了多个可以同时运行的线程。 引入多线程技术的动机在传统的操作系统中，进程是系统进行资源分配的基本单位，按进程为单位分给存放其映象所需要的虚地址空间、执行所需要的主存空间、完成任务需要的其他各类外围设备资源和文件。同时，进程也是处理器调度的基本单位，进程在任一时刻只有一个执行控制流，通常将这种结构的进程称单线程（结构）进程（single threaded process）。首先来考察一个文件服务器的例子，当它接受一个文件服务请求后，由于等待磁盘传输而经常被阻塞，假如不阻塞可继续接受新的文件服务请求并进行处理，则文件服务器的性能和效率便可以提高，由于处理这些请求时要共享一个磁盘缓冲区，程序和数据，要在同一个地址空间中操作。这一类应用非常多。 例如，航空售票系统需要处理多个购票和查询请求，这些信息都与同一个数据库相关；而操作系统在同时处理许多用户进程的查询请求时，都要去访问数据库所在的同一个磁盘。 对于上述这类基于同数据区的同时多请求应用，用单线程结构的进程难以达到这一目标，即使能解决问题代价也非常高，需要寻求新概念、提出新机制。随着并行技术、网络技术和软件设计技术的发展，给并发程序设计效率带来了一系列新的问题，主要表现在： 进程时空的开销大，频繁的进程调度将耗费大量处理器时间，要为每个进程分配存储空间限制了操作系统中进程的总数。 进程通信的代价大，每次通信均要涉及通信进程之间或通信进程与操作系统之间的信息传递。进程之间的并发性粒度较粗，并发度不高，过多的进程切换和通信延迟使得细粒度的并发得不偿失。 不适合并行计算和分布并行计算的要求，对于多处理器和分布式的计算环境来说，进程之间大量频繁的通信和切换，会大大降低并行度。 不适合客户/服务器计算的要求。对于 C/S 结构来说，那些需要频繁输入输出并同时大量计算的服务器进程（如数据库服务器、事务监督程序）很难体现效率。 这就迫切要求操作系统改进进程结构，提供新的机制，使得应用能够按照需求在同一进程中设计出多条控制流，多控制流之间可以并行执行，多控制流切换不需通过进程调度；多控制流之间还可以通过内存区直接通信，降低通信开销。这就是近年来流行的多线程（结构）进程（multiple threaded process） 。如果说操作系统中引入进程的目的是为了使多个程序能并发执行，以改善资源使用率和提高系统效率，那么，在操作系统中再引入线程，则是为了减少程序并发执行时所付出的时空开销，使得并发粒度更细、并发性更好。这里解决问题的基本思路是：把进程的两项功能－－“独立分配资源”与“被调度分派执行”分离开来，前一项任务仍由进程完成，它作为系统资源分配和保护的独立单位，不需要频繁地切换；后一项任务交给称作线程的实体来完成，它作为系统调度和分派的基本单位，会被频繁地调度和换，在这种指导思想下，产生了线程的概念。 进程和线程的本质对比进程是系统进行资源调度和分配的基本单位；线程是CPU调度的基本单位。 进程 = 资源 （包括寄存器值，PCB，内存映射表）+ TCB（栈结构）线程 = TCB（栈结构） 线程 的资源是共享的进程 间的资源是分隔独立的，内存映射表不同，占用物理内存地址是分隔的 线程 的切换只是切换PC，切换了TCB（栈结构）进程 的切换不仅要切换PC，还包括切换资源，即切换内存映射表 线程中的基本概念，线程的生命周期线程的生命周期，线程的生命周期可以利用以下的图解来更好的理解：先是用new Thread()的方法新建一个线程，在线程创建完成之后，线程就进入了就绪（Runnable）状态，此时创建出来的线程进入抢占CPU资源的状态，当线程抢到了CPU的执行权之后，线程就进入了运行状态（Running），当该线程的任务执行完成之后或者是非常态的调用的stop（）方法之后，线程就进入了死亡状态。而我们在图解中可以看出，线程还具有一个阻塞的过程，这是怎么回事呢？当面对以下几种情况的时候，容易造成线程阻塞，第一种，当线程主动调用了sleep（）方法时，线程会进入则阻塞状态，除此之外，当线程中主动调用了阻塞时的IO方法时，这个方法有一个返回参数，当参数返回之前，线程也会进入阻塞状态，还有一种情况，当线程进入正在等待某个通知时，会进入阻塞状态。那么，为什么会有阻塞状态出现呢？我们都知道,CPU的资源是十分宝贵的，所以，当线程正在进行某种不确定时长的任务时，Java就会收回CPU的执行权，从而合理应用CPU的资源。我们根据图可以看出，线程在阻塞过程结束之后，会重新进入就绪状态，重新抢夺CPU资源。这时候，我们可能会产生一个疑问，如何跳出阻塞过程呢?又以上几种可能造成线程阻塞的情况来看，都是存在一个时间限制的，当sleep()方法的睡眠时长过去后，线程就自动跳出了阻塞状态，第二种则是在返回了一个参数之后，在获取到了等待的通知时，就自动跳出了线程的阻塞过程 单线程和多线程单线程，顾名思义即是只有一条线程在执行任务，这种情况在我们日常的工作学习中很少遇到，所以我们只是简单做一下了解 多线程，创建多条线程同时执行任务，这种方式在我们的日常生活中比较常见。但是，在多线程的使用过程中，还有许多需要我们了解的概念。比如，在理解上并行和并发的区别，以及在实际应用的过程中多线程的安全问题，对此，我们需要进行详细的了解。 并发和并行：在我们看来，都是可以同时执行多种任务，那么，到底他们二者有什么区别呢？ 并发，从宏观方面来说，并行就是同时进行多种时间，实际上，这几种时间，并不是同时进行的，而是交替进行的，而由于CPU的运算速度非常的快，会造成我们的一种错觉，就是在同一时间内进行了多种事情 而并行，则是真正意义上的同时进行多种事情。这种只可以在多核CPU的基础下完成。 还有就是多线程的安全问题？为什么会造成多线程的安全问题呢？我们可以想象一下，如果多个线程同时执行一个任务，name意味着他们共享同一种资源，由于线程CPU的资源不一定可以被谁抢占到，这是，第一条线程先抢占到CPU资源，他刚刚进行了第一次操作，而此时第二条线程抢占到了CPU的资源，name，共享资源还来不及发生变化，就同时有两条数据使用了同一条资源，具体请参考多线程买票问题。这个问题我们应该如何解决那？ 由造成问题的原因我们可以看出，这个问题主要的矛盾在于，CPU的使用权抢占和资源的共享发生了冲突，解决时，我们只需要让一条线程战歌了CPU的资源时，阻止第二条线程同时抢占CPU的执行权，在代码中，我们只需要在方法中使用同步代码块即可。在这里，同步代码块不多进行赘述，可以自行了解。 线程池又以上介绍我们可以看出，在一个应用程序中，我们需要多次使用线程，也就意味着，我们需要多次创建并销毁线程。而创建并销毁线程的过程势必会消耗内存。而在Java中，内存资源是及其宝贵的，所以，我们就提出了线程池的概念。 线程池：Java中开辟出了一种管理线程的概念，这个概念叫做线程池，从概念以及应用场景中，我们可以看出，线程池的好处，就是可以方便的管理线程，也可以减少内存的消耗。 那么，我们应该如何创建一个线程池那?Java中已经提供了创建线程池的一个类：Executor 而我们创建时，一般使用它的子类：ThreadPoolExecutor. 1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 这是其中最重要的一个构造方法，这个方法决定了创建出来的线程池的各种属性，下面依靠一张图来更好的理解线程池和这几个参数：上图中，我们可以看出，线程池中的corePoolSize就是线程池中的核心线程数量，这几个核心线程，只是在没有用的时候，也不会被回收，maximumPoolSize就是线程池中可以容纳的最大线程的数量，而keepAliveTime，就是线程池中除了核心线程之外的其他的最长可以保留的时间，因为在线程池中，除了核心线程即使在无任务的情况下也不能被清除，其余的都是有存活时间的，意思就是非核心线程可以保留的最长的空闲时间，而util，就是计算这个时间的一个单位，workQueue，就是等待队列，任务可以储存在任务队列中等待被执行，执行的是FIFIO原则（先进先出）。threadFactory，就是创建线程的线程工厂，最后一个handler,是一种拒绝策略，我们可以在任务满了知乎，拒绝执行某些任务。 线程池的执行流程又是怎样的呢？有图我们可以看出，任务进来时，首先执行判断，判断核心线程是否处于空闲状态，如果不是，核心线程就先就执行任务，如果核心线程已满，则判断任务队列是否有地方存放该任务，若果有，就将任务保存在任务队列中，等待执行，如果满了，在判断最大可容纳的线程数，如果没有超出这个数量，就开创非核心线程执行任务，如果超出了，就调用handler实现拒绝策略。 handler的拒绝策略： 有四种：第一种AbortPolicy:不执行新任务，直接抛出异常，提示线程池已满第二种DisCardPolicy:不执行新任务，也不抛出异常第三种DisCardOldSetPolicy:将消息队列中的第一个任务替换为当前新进来的任务执行第四种CallerRunsPolicy:直接调用execute来执行当前任务 四种常见的线程池：CachedThreadPool:可缓存的线程池，该线程池中没有核心线程，非核心线程的数量为Integer.max_value，就是无限大，当有需要时创建线程来执行任务，没有需要时回收线程，适用于耗时少，任务量大的情况。 SecudleThreadPool:周期性执行任务的线程池，按照某种特定的计划执行线程中的任务，有核心线程，但也有非核心线程，非核心线程的大小也为无限大。适用于执行周期性的任务。 SingleThreadPool:只有一条线程来执行任务，适用于有顺序的任务的应用场景。 FixedThreadPool:定长的线程池，有核心线程，核心线程的即为最大的线程数量，没有非核心线程]]></content>
      <categories>
        <category>计算机</category>
        <category>操作系统</category>
        <category>进程管理</category>
      </categories>
      <tags>
        <tag>计算机</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对进程的补充——内核]]></title>
    <url>%2F2019%2F06%2F03%2F%E5%AF%B9%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%A1%A5%E5%85%85%E2%80%94%E2%80%94%E5%86%85%E6%A0%B8%2F</url>
    <content type="text"><![CDATA[内核是操作系统的内部核心程序，它向外部提供了对计算机设备的核心管理调用。我们将操作系统的代码分成两部分。内核所在的地址空间称作内核空间。而在内核以外的统称为外部管理程序，它们大部分是对外围设备的管理和界面操作。外部管理程序与用户进程所占据的地址空间称为外部空间。通常，一个程序会跨越两个空间。当执行到内核空间的一段代码时，我们称程序处于内核态，而当程序执行到外部空间代码时，我们称程序处于用户态。 Linux内核的核心功能如下图所示，Linux内核只是Linux操作系统一部分。对下，它管理系统的所有硬件设备；对上，它通过系统调用，向Library Routine（例如C库）或者其它应用程序提供接口。 因此，其核心功能就是：管理硬件设备，供应用程序使用。而现代计算机（无论是PC还是嵌入式系统）的标准组成，就是CPU、Memory（内存和外存）、输入输出设备、网络设备和其它的外围设备。所以为了管理这些设备，Linux内核提出了如下的架构。 Linux内核的整体架构和子系统划分 上图说明了Linux内核的整体架构。根据内核的核心功能，Linux内核提出了5个子系统，分别负责如下的功能： Process Scheduler也称作进程管理、进程调度。负责管理CPU资源，以便让各个进程可以以尽量公平的方式访问CPU。 Memory Manager内存管理。负责管理Memory（内存）资源，以便让各个进程可以安全地共享机器的内存资源。另外，内存管理会提供虚拟内存的机制，该机制可以让进程使用多于系统可用Memory的内存，不用的内存会通过文件系统保存在外部非易失存储器中，需要使用的时候，再取回到内存中。 VFS（Virtual File System）虚拟文件系统。Linux内核将不同功能的外部设备，例如Disk设备（硬盘、磁盘、NAND Flash、Nor Flash等）、输入输出设备、显示设备等等，抽象为可以通过统一的文件操作接口（open、close、read、write等）来访问。这就是Linux系统“一切皆是文件”的体现（其实Linux做的并不彻底，因为CPU、内存、网络等还不是文件，如果真的需要一切皆是文件，还得看贝尔实验室正在开发的”Plan 9”的）。 Network网络子系统。负责管理系统的网络设备，并实现多种多样的网络标准。 IPC（Inter-Process Communication）进程间通信。IPC不管理任何的硬件，它主要负责Linux系统中进程之间的通信。]]></content>
      <categories>
        <category>计算机</category>
        <category>操作系统</category>
        <category>进程管理</category>
      </categories>
      <tags>
        <tag>计算机</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对进程的补充——PCB]]></title>
    <url>%2F2019%2F06%2F03%2F%E5%AF%B9%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%A1%A5%E5%85%85%E2%80%94%E2%80%94PCB%2F</url>
    <content type="text"><![CDATA[进程控制块（PCB）在Linux中task_struct结构体即是PCB。PCB是进程的唯一标识，PCB由链表实现（为了动态插入和删除）。进程创建时，为该进程生成一个PCB；进程终止时，回收PCB。PCB包含信息：1、进程状态（state）；2、进程标识信息（uid、gid）；3、定时器（time）；4、用户可见寄存器、控制状态寄存器、栈指针等（tss） 每个进程都有一个非负的唯一进程ID（PID）。虽然是唯一的，但是PID可以重用，当一个进程终止后，其他进程就可以使用它的PID了。PID为0的进程为调度进程，该进程是内核的一部分，也称为系统进程；PID为1的进程为init进程，它是一个普通的用户进程，但是以超级用户特权运行；PID为2的进程是页守护进程，负责支持虚拟存储系统的分页操作。除了PID，每个进程还有一些其他的标识符： 每个进程的task_struct和系统空间堆栈(系统表格区)存放位置如下：两个连续的物理页【《Linux内核源代码情景分析》271页】系统堆栈空间不能动态扩展，在设计内核、驱动程序时要避免函数嵌套太深，同时不宜使用太大太多的局部变量，因为局部变量都是存在堆栈中的。 进程的创建新进程的创建，首先在内存中为新进程创建一个task_struct结构，然后将父进程的task_struct内容复制其中，再修改部分数据。分配新的内核堆栈、新的PID、再将task_struct这个node添加到链表中。所谓创建，实际上是“复制”。 子进程刚开始，内核并没有为它分配物理内存，而是以只读的方式共享父进程内存，只有当子进程写时，才复制。即“copy-on-write”。fork都是由do_fork实现的，do_fork的简化流程如下图：fork函数fork函数时调用一次，返回两次。在父进程和子进程中各调用一次。子进程中返回值为0，父进程中返回值为子进程的PID。程序员可以根据返回值的不同让父进程和子进程执行不同的代码。一个形象的过程：运行这样一段演示程序： 123456789101112131415161718192021222324252627#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;int main()&#123; pid_t pid; char *message; int n = 0; pid = fork(); while(1)&#123; if(pid &lt; 0)&#123; perror("fork failed\n"); exit(1); &#125; else if(pid == 0)&#123; n--; printf("child's n is:%d\n",n); &#125; else&#123; n++; printf("parent's n is:%d\n",n); &#125; sleep(1); &#125; exit(0);&#125;]]></content>
      <categories>
        <category>计算机</category>
        <category>操作系统</category>
        <category>进程管理</category>
      </categories>
      <tags>
        <tag>计算机</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程]]></title>
    <url>%2F2019%2F06%2F02%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F3%2F</url>
    <content type="text"><![CDATA[计算机中，CPU是最宝贵的资源，为了提高CPU的利用率，引入了多道程序设计的概念。当内存中多个程序存在时，如果不对人们熟悉的“程序”的概念加以扩充，就无法刻画多个程序共同运行时系统呈现出的特征。 进程的引入多道程序系统中，程序具有：并行、制约以及动态的特征。 程序概念难以反映系统中的情况： 程序是一个静态的概念程序是完成某个功能的指令集和。系统实际上是出于不断变化的状态中，程序不能反映这种动态性。 程序概念不能反映系统中的并行特性例如：两个C语言源程序由一个编译程序完成编译，若用程序概念理解，内存中只有一个编译程序运行（两个源程序看作编译程序的输入数据），但是这样无法说明白内存中运行着两个任务。程序的概念不能表示这种并行情况，反映不了他们活动的规律和状态变化。就像不能用菜谱（程序）代替炒菜（程序执行的过程）一样（这句话我稍微修改了一下，感觉应该是这样表诉才对） 进程的定义进程：一个具有一定独立功能的程序关于某个数据集合的一次运行活动，是系统进行资源分配和调度运行的基本单位 进程与程序的差别进程是一个动态的概念进程是程序的一次执行过程，是动态概念程序是一组有序的指令集和，是静态概念 不同的进程可以执行同一个程序区分进程的条件：所执行的程序和数据集合。两个进程即使执行在相同的程序上，只要他们运行在不同的数据集合上，他们也是两个进程。例如：多个用户同时调用同一个编译程序编译他们编写的C语言源程序，由于编译程序运行在不同的数据集合（不同的C语言源程序）上，于是产生了一个个不同的进程 每个进程都有自己的生命周期当操作系统要完成某个任务时，它会创建一个进程。当进程完成任务之后，系统就会撤销这个进程，收回它所占用的资源。从创建到撤销的时间段就是进程的生命期 进程之间存在并发性在一个系统中，同时会存在多个进程。他们轮流占用CPU和各种资源 进程间会相互制约进程是系统中资源分配和运行调度的单位，在对资源的共享和竞争中，必然相互制约，影响各自向前推进的速度 进程可以创建子进程，程序不能创建子程序从结构上讲每个进程都由程序、数据和一个进程控制块（Process Control Block, PCB）组成 进程的重要特征动态特征：进程对应于程序的运行，动态产生、消亡，在其生命周期中进程也是动态的 并发特征：任何进程都可以同其他进程一起向前推进 独立特征：进程是相对完整的调度单位，可以获得CPU，参与并发执行 交往特征：一个进程在执行过程中可与其他进程产生直接或间接关系 异步特征：每个进程都以相对独立、不可预知的速度向前推进 结构特征：每个进程都有一个PCB作为他的数据结构 进程最基本的特征是并发和共享特征 进程的状态与转换进程的三种基本状态a.运行状态：获得CPU的进程处于此状态，对应的程序在CPU上运行着b.阻塞状态：为了等待某个外部事件的发生（如等待I/O操作的完成，等待另一个进程发来消息），暂时无法运行。也成为等待状态c.就绪状态：具备了一切运行需要的条件，由于其他进程占用CPU而暂时无法运行 进程状态转换a.运行状态 ===&gt; 阻塞状态：例如正在运行的进程提出I/O请求，由运行状态转化为阻塞状态b.阻塞状态 ===&gt; 就绪状态：例如I/O操作完成之后，由阻塞状态转化为就绪状态c.就绪状态 ===&gt; 运行状态：例如就绪状态的进程被进程调度程序选中，分配到CPU中运行，由就绪状态转化为运行状态d.运行状态 ===&gt; 就绪状态：处于运行状态的进程的时间片用完，不得不让出uCPU，由运行状态转化为就绪状态 进程的类型a.系统进程：操作系统用来管理资源的进程，当系统进程处于运行态时，CPU处于管态，系统之间的关系由操作系统负责b.用户进程：操作系统可以独立执行的的用户程序段，当用户进程处于运行态时，CPU处于目态，用户进程之间的关系由用户负责 进程控制块进程的三个组成部分a. 程序b. 数据c. 进程控制块（PCB）：为了管理和控制进程，系统在创建每个进程时，都为其开辟一个专用的存储区，用以记录它在系统中的动态特性。系统根据存储区的信息对进程实施控制管理。进程任务完成后，系统收回该存储区，进程随之消亡，这一存储区就是进程控制块 PCB随着进程的创建而建立，撤销而消亡。系统根据PCB感知一个进程的存在，PCB是进程存在的唯一物理标识（这一点可以类比作业控制块JCB） 进程控制块的内容PCB在不同的语言中，可能用不同的数据结构表示。为了系统管理和控制进程方便，系统常常将所有进程的PCB存放在内存中系统表格区(系统空间堆栈)（这是什么区？不懂，待我仔细查查），并按照进程内部标号由小到大顺序存放。 整个系统中各进程的的PCB集合可用数组表示。这时进程内部标号可以与数组元素下标联系。 各系统预留的PCB空间往往是固定的，如UNIX系统中规定进程数量不超过50个（这一点我有点怀疑） 操作系统不同，PCB的格式、大小及内容也不尽相同。一般的，应该包含如下四个信息 a. 标识信息：进程名（uid、gid）b. 说明信息：进程状态（state）、程序存放位置c. 现场信息：通用寄存器内存、控制寄存器内存、断点地址d. 管理信息：进程优先数、队列指针 进程控制块的组织系统中，有着许多不同状态的进程，处于阻塞状态的进程阻塞原因各不相同，为了便于调度和管理，常将进程控制块PCB用适当的方法组织起来 线性结构把所有不同状态的进程的PCB组织在一个表格中。最简单，适用于进程数目不多的操作系统，如UNIX系统，缺点是调用时，往往需要查询整个PCB表，时间复杂度略高 索引结构分别把具有不同状态的进程PCB组织在同一个表中，于是有就绪进程表、运行进程表（多机系统中，还有现在的多核系统应该也有吧）以及各种等待事件的阻塞进程表 系统中的一些固定单元分别指出各表的起始地址 链式结构采用队列形式时，每个进程的PCB中要增加一个链指针表项，指向队列的下一个PCB起始地址。为了对这些队列进行管理，操作系统要做三件事： a. 把处于同一状态的进程的PCB通过各自队列的指针链接在一起，形成队列b. 为每一个队列设立一个对头指针，总是指向队首的PCBc. 排在队尾的PCB的队列指针项内容应该是“-1”或者一个特殊符号，表示这是队尾PCB 在单CPU系统中，任何时刻都只有一个处于运行态的进程 所有处于阻塞队列中的PCB应该根据产生阻塞的原因今进行排队，每一个都称为阻塞队列，比如等待磁盘I/O的阻塞队列，等待打印机输出的阻塞队列 进程控制原语要对进程进行控制，系统中必须设置一个机构，它具有创建进程、撤销进程、进程通信和资源管理等功能，这样的结构称为操作系统的内核（kernel）内核本身不是一个进程，而是硬件的首次延伸，它是加在硬件上的第一层软件。内核是通过执行各种原语操作来完成各种控制和管理功能的原语（primitive）是机器指令的延伸，用若干条机器指令构成，用以完成特定功能的一段程序。为保证操作的正确性，原语在执行期间是不可分割的（这点可以类比数据库中的事务）用于进程控制的原语有：创建进程原语、撤销进程原语、阻塞进程原语、唤醒进程原语、调度进程原语、改变优先级原语等 创建进程原语一个进程如果需要时，可以创建一个新的进程。被建立的进程称为子进程，建立者进程称为父进程所有的进程都只能通过父进程建立，不能自生自灭。 创建进程原语供进程调用，用以建立子进程。该原语的主要工作：为被建立的进程简历一个进程控制块，填入相应的初始值。主要操作过程是先向系统的PCB空间申请分配一个空闲的PCB，然后根据父进程所提供的参数，将子进程的PCB表目初始化，最后返回一个子进程内部名。 撤销进程原语由父进程撤销子进程的PCB，注意，这里会撤销一个以该子进程为根的进程子树，并回收占用的全部资源 阻塞原语在阻塞原语的作用下，进程由运行状态转化为阻塞状态 唤醒原语在唤醒原语的作用下，进程由阻塞状态转化为就绪状态 改变进程优先级原语进程的优先级是表示进程的重要性以及运行的优先性，拱进程调度程序调度进程运行时使用为了防止一些进程因优先级较低，而长期得不到运行，许多系统采用动态优先级，进程的优先级按照一些原则变化通常，进程优先级和以下因素有关系： a. 作业开始时的静态优先数：作业的优先数取决于作业的重要程度、用户为作业运行时所付出的价格和费用大小、作业的类型等因素b. 进程的类型：一般系统进程的优先数大于用户进程的优先数；I/O型进程的优先数大于CPU型进程的优先数。这些都是为了充分发挥系统I/O设备的效能c. 进程所使用的资源量：使用CPU的时间越多，优先级越低。对其他资源使用的情况也类似的考虑d. 进程在系统中的等待时间：等待时间越长，进程优先级越高 各系统处于不同的考虑，有不同的优先数计算公式。这些公式主要来自于时间经验]]></content>
      <categories>
        <category>计算机</category>
        <category>操作系统</category>
        <category>进程管理</category>
      </categories>
      <tags>
        <tag>计算机</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统后期发展]]></title>
    <url>%2F2019%2F05%2F29%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F2%2F</url>
    <content type="text"><![CDATA[通用操作系统 操作系统的三种基本类型：多道批处理系统、分时系统、实时系统。 通用操作系统：具有多种类型操作特征的操作系统。可以同时兼有多道批处理、分时、实时处理的功能，或其中两种以上的功能。 例如：实时处理+批处理=实时批处理系统。首先保证优先处理实时任务，插空进行批处理作业。常把实时任务称为前台作业，批作业称为后台作业。再如：分时处理+批处理=分时批处理系统。即：时间要求不强的作业放入“后台”（批处理）处理，需频繁交互的作业在“前台”（分时）处理，处理机优先运行“前台”作业。 从上世纪60年代中期，国际上开始研制一些大型的通用操作系统。这些系统试图达到功能齐全、可适应各种应用范围和操作方式变化多端的环境的目标。但是，这些系统过于复杂和庞大，不仅付出了巨大的代价，且在解决其可靠性、可维护性和可理解性方面都遇到很大的困难。相比之下，UNIX操作系统却是一个例外。这是一个通用的多用户分时交互型的操作系统。它首先建立的是一个精干的核心，而其功能却足以与许多大型的操作系统相媲美，在核心层以外，可以支持庞大的软件系统。它很快得到应用和推广，并不断完善，对现代操作系统有着重大的影响。至此，操作系统的基本概念、功能、基本结构和组成都已形成并渐趋完善。 操作系统的进一步发展进入20世纪80年代，大规模集成电路工艺技术的飞跃发展，微处理机的出现和发展，掀起了计算机大发展大普及的浪潮。一方面迎来了个人计算机的时代，同时又向计算机网络、分布式处理、巨型计算机和智能化方向发展。于是，操作系统有了进一步的发展，如：个人计算机操作系统、网络操作系统、分布式操作系统等。 个人计算机操作系统个人计算机上的操作系统是联机交互的单用户操作系统，它提供的联机交互功能与通用分时系统提供的功能很相似。由于是个人专用，因此一些功能会简单得多。然而，由于个人计算机的应用普及，对于提供更方便友好的用户接口和丰富功能的文件系统的要求会愈来愈迫切。 网络操作系统计算机网络：通过通信设施，将地理上分散的、具有自治功能的多个计算机系统互连起来，实现信息交换、资源共享、互操作和协作处理的系统。网络操作系统：在原来各自计算机操作系统上，按照网络体系结构的各个协议标准增加网络管理模块，其中包括：通信、资源共享、系统安全和各种网络应用服务。 分布式操作系统表面上看，分布式系统与计算机网络系统没有多大区别。分布式操作系统也是通过通信网络，将地理上分散的具有自治功能的数据处理系统或计算机系统互连起来，实现信息交换和资源共享，协作完成任务。——硬件连接相同。但有如下一些明显的区别：（1）分布式系统要求一个统一的操作系统，实现系统操作的统一性。（2）分布式操作系统管理分布式系统中的所有资源，它负责全系统的资源分配和调度、任务划分、信息传输和控制协调工作，并为用户提供一个统一的界面。（3）用户通过这一界面，实现所需要的操作和使用系统资源，至于操作定在哪一台计算机上执行，或使用哪台计算机的资源，则是操作系统完成的，用户不必知道，此谓：系统的透明性。（4）分布式系统更强调分布式计算和处理，因此对于多机合作和系统重构、坚强性和容错能力有更高的要求，希望系统有：更短的响应时间、高吞吐量和高可靠性。 操作系统的作用现代的计算机系统主要是由一个或者多个处理器，主存，硬盘，键盘，鼠标，显示器，打印机，网络接口及其他输入输出设备组成。一般而言，现代计算机系统是一个复杂的系统。其一：如果每位应用程序员都必须掌握该系统所有的细节，那就不可能再编写代码了（严重影响了程序员的开发效率：全部掌握这些细节可能需要一万年….）其二：并且管理这些部件并加以优化使用，是一件极富挑战性的工作，于是，计算安装了一层软件（系统软件），称为操作系统。它的任务就是为用户程序提供一个更好、更简单、更清晰的计算机模型，并管理刚才提到的所有设备。 总结程序员无法把所有的硬件操作细节都了解到，管理这些硬件并且加以优化使用是非常繁琐的工作，这个繁琐的工作就是操作系统来干的，有了他，程序员就从这些繁琐的工作中解脱了出来，只需要考虑自己的应用软件的编写就可以了，应用软件直接使用操作系统提供的功能来间接使用硬件。 精简的说操作系统就是一个协调、管理和控制计算机硬件资源和软件资源的控制程序。操作系统所处的位置如图 细说的说操作系统应该分成两部分功能：一：隐藏了丑陋的硬件调用接口，为应用程序员提供调用硬件资源的更好，更简单，更清晰的模型（系统调用接口）。应用程序员有了这些接口后，就不用再考虑操作硬件的细节，专心开发自己的应用程序即可。例如：操作系统提供了文件这个抽象概念，对文件的操作就是对磁盘的操作，有了文件我们无需再去考虑关于磁盘的读写控制（比如控制磁盘转动，移动磁头读写数据等细节），二：将应用程序对硬件资源的竞态请求变得有序化例如：很多应用软件其实是共享一套计算机硬件，比方说有可能有三个应用程序同时需要申请打印机来输出内容，那么a程序竞争到了打印机资源就打印，然后可能是b竞争到打印机资源，也可能是c，这就导致了无序，打印机可能打印一段a的内容然后又去打印c…,操作系统的一个功能就是将这种无序变得有序。]]></content>
      <categories>
        <category>计算机</category>
        <category>历史</category>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>计算机</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统初期发展]]></title>
    <url>%2F2019%2F05%2F21%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F1%2F</url>
    <content type="text"><![CDATA[无操作系统的计算机系统:人工操作方式：用户采用人工操作方式直接使用计算机硬件系统，将已经穿孔的纸带装入纸带输入机，在启动它将程序和数据输入计算机，然后计算机运行。 在人工方式下，其最大的缺点：用户独占全机，CPU等待人工操作（计算机资源利用率很低）；直到出现脱机输入/输出方式。 由于程序和数据都在外围机的控制下完成，或者说，他们在脱离主机的情况下进行的，故此称为脱机输入/输出 ,反之，在主机的直接控制下进行的输入/输出的方式称为联机输入/输出方式。 优点：减少了CPU的空闲时间，提高了I/O速度。 脱机处理时，外部设备上的数据需要一个相当长的等待时间后才被进行处理。当外部设备上有数据输入时，主机并不予处理，只是将外部设备的数据存放到缓冲区中。一旦缓冲区满了，或是等待的时间到了，主机才进行加工处理。对输出的操作也是这样，一旦计算机要把处理结果输出，它只是把输出结果送入缓冲区中，然后向外部设备慢慢地进行输出，而主机又去进行其它的加工处理，当缓冲区中的数据全部输出完毕，主机再把下一批的数据存入缓冲区中。 手工操作(穿孔卡片)1946年第一台计算机诞生–20世纪50年代中期，计算机工作还在采用手工操作方式。此时还没有操作系统的概念。程序员将对应于程序和数据的已穿孔的纸带（或卡片）装入输入机，然后启动输入机把程序和数据输入计算机内存，接着通过控制台开关启动程序针对数据运行；计算完毕，打印机输出计算结果；用户取走结果并卸下纸带（或卡片）后，才让下一个用户上机。 手工操作方式两个特点：1.用户独占全机。不会出现因资源已被其他用户占用而等待的现象，但资源的利用率低。2.CPU 等待手工操作。CPU的利用不充分。 20世纪50年代后期，出现人机矛盾：手工操作的慢速度和计算机的高速度之间形成了尖锐矛盾，手工操作方式已严重损害了系统资源的利用率（使资源利用率降为百分之几，甚至更低），不能容忍。唯一的解决办法：只有摆脱人的手工操作，实现作业的自动过渡。这样就出现了成批处理。 批处理系统(磁带存储)诞生时间：20世纪50年代。 实时操作系统的起源为了提高单一操作员单一控制终端的操作系统SOSC的效率，人们提出了批处理操作系统。SOSC效率低下是因为计算机总是在等待人的下一步动作，而人的动作总是很慢。因此，人们觉得，如果去掉等待人的时间，即让所有的人先想好自己要运行的命令，列成一个清单，打印在纸带上，然后交给一个工作人员来一批一批的处理，效率不就提高了吗？这样就形成了批处理操作系统。 批处理系统的定义批处理系统就是成批处理一些程序的系统。批处理分为联机批处理和脱机批处理两种。 联机批处理在联机批处理中，编制了一个常驻内存的监督程序，用来控制用户作业的运行。其处理过程为：用户将所需解决的问题组成作业，交给操作员，操作员有选择地把若干作业合成一批，并把一批作业装到输入设备上，然后由监督程序控制送到辅存，再从辅村中将一个一个作业调入内存运行，直到全部作业处理完毕。 脱机批处理脱机批处理系统由主机和卫星机组成。卫星机又称外围计算机，它不与主机直接连接，只与外部设备打交道。作业通过卫星机输入到磁带上，当主机需要输入作业时，就把输入带从卫星机的磁带机上取下，并装入到主机的磁带机上。于是，主机可以连续的处理由输入带输入的许多用户作业，并把这些作业的运行结果不断地输出到输出带上。最后，多个用户作业的输出结果再通过卫星机连接的打印机打印出来。 脱机批处理产生的目的：缓解主机与外设的矛盾提高CPU的利用率。 多道批处理系统诞生时间：20世纪60年代 多道程序系统多道程序系统是控制多道程序同时运行的程序系统，由它决定在某一个时刻运行哪一个作业，或者说，是在计算机内存中同时存放几道互相独立的程序，使他们在管理程序控制之下，相互穿插地运行，即使多道程序在系统内并行工作。 主要特征：1.多道，即计算机内存中同时存放几道相互独立的程序。2.宏观上并行，同时进入系统的几道程序都处于运行过程中，即他们先后开始了各自的运行，但都未运行完毕。3.微观上串行，内存中的多道程序轮流地或分时地占有CPU，交替执行 多道程序系统的出现，标志着操作系统渐趋成熟的阶段，先后出现了作业调度管理、处理机管理、存储器管理、外部设备管理、文件系统管理等功能。由于多个程序同时在计算机中运行，开始有了空间隔离的概念，只有内存空间的隔离，才能让数据更加安全、稳定。出了空间隔离之外，多道技术还第一次体现了时空复用的特点，遇到IO操作就切换程序，使得cpu的利用率提高了，计算机的工作效率也随之提高。 多道批处理系统多道批处理系统有两个含义：一是多道，二是批处理。多道是在计算机内存中同时存放多个作业，它们在操作系统的控制下并发执行，而且在外存中还存放有大量的作业，并组成一个后备作业队列，系统按一定的调度原则每次从后备作业队列中选取一个或多个作业调入内存运行。 分时系统 分时系统的起源背景：在多道批处理系统的时代，人们主要提高对系统资源的利用率和系统的吞吐量。但是由于时代的发展，人们又提出了另一个问题，在人们将制作在卡片上的程序交由计算机执行时，用户无法即时获得程序运行的结果。这一问题很有可能导致很严重的后果发生。基于这个问题，人们考虑能否让人回到计算机前来，每个人即时管理自己的程序，但又由于20世纪60年代计算机还十分昂贵，所以一台计算机要同时供多个用户共享使用，每个用户在共享一台计算机时都希望能像独占时一样，不仅可以随时与计算机进行交互，而且还不会感觉到其他用户的存在。于是分时系统就在这样情况下诞生。 分时系统的介绍分时系统是允许多个联机用户同时使用一台计算机进行处理的系统。系统将CPU在时间上分割成很小的时间段，每个时间段称为一个时间片。每个联机用户通过终端以交互方式控制程序的运行，系统把CPU时间轮流分配给个联机作业，每个作业只运行极短的时间片，从而使每个用户都有一种“独占计算机”的感觉。 分时系统实现的关键问题人—机交互问题1.及时接收2.及时处理 共享主机问题分时系统的主要目标为了方便用户使用计算机系统，并在尽可能的情况下，提高系统资源的利用率。 分时系统的主要特征1.多路性是指系统允许将多台终端同时连接到主机上，并按分时原则为每个用户服务。多路性允许多个用户共享一台主机，显著提高资源利用率，降低使用费用，促进计算机更广泛的应用。2.独立性是指系统提供了这样的用机环境，即每个用户在各自的终端上进行操作，彼此之间互不干扰，给用户的感觉就像是一个人在使用主机。3.交互性是指用户可通过终端与系统进行广泛的人人机对话。其广泛性表现在：用户可以请求系统提供多方面的服务，如进行文件编辑和数据处理，访问系统中的文件和数据库，请求提供打印服务等。4.及时性是指用户的请求能在很短的时间内获得响应。这一时间间隔是根据人们所能接受的等待时间确定的，通常仅为1~3秒钟。 分时系统的优点1.自然操作方式该系统使用户能在较短的时间内采用交互式会话工作方式，及时输入、调度、修改和运行自己的程序，因而加快了解题周期。2.扩大了应用范围无论是本地用户，还是运地用户，只要与计算机连在一台终端设备，就可以随时随地使用计算机。3.便于共享和交换信息远近终端用户均通过系统中的文件系统彼此交流信息和共享各种文件。4.经济实惠用户只须有系统配备的终端，即可完成各种处理任务，可共享大型的具有丰富资源的计算机系统。 分时系统实例解析若选择时间片为100ms，系统中有20个用户分享CPU，并忽略用户程序间的切换时间开销，则每个用户的平均响应时间为：100ms*20=2秒。在假设CPU运行速度为200万次/秒，则对每个用户程序来说，等价的CPU速度为：200/20=10万次/秒。 注意：分时系统的分时间片工作，在没有遇到IO操作的时候就用完了自己的时间片被切走了，这样的切换工作其实并没有提高cpu的效率，反而使得计算机的效率降低了。但是我们牺牲了一点效率，却实现了多个程序共同执行的效果，这样你就可以在计算机上一边听音乐一边聊qq了。 实时操作系统 实时操作系统的起源1980年，加拿大两个大学生Gordon Bell和Dan Dodge，在学习操作系统设计课程期间，萌发了设计“实时操作系统（RTOS）”的念头，并且动手干了起来，最终做出了一个实时操作系统的微内核。 实时操作系统的定义实时操作系统是保证在一定时间限制内完成特定功能的操作系统。实时操作系统有软实时系统和硬实时系统之分。软实时系统在规定时间得不到响应所产生的后果是可以承受的，如流水装配线。即使装配线瘫痪，也只是损失了资金；而硬实时系统在得不到实时响应后则可能产生不能承受的灾难，如导弹防卫系统。如果反应迟钝，结果就可能是严重损失。 实时操作系统的分类计算机应用到实时控制中，配置实时操作系统，就可组成各种各样的实时系统。目前，在计算机应用中，过程控制和信息处理都有一定的实时要求，据此，把实时系统分为实时过程控制系统和实时信息处理系统两大类。 实时过程控制它又可分为两类：一类是以计算机位控制中枢的生产过程自动化系统，如冶炼、发电、炼油、化工、机械加工等的自动控制。在这类系统中，要求计算机及时采集和处理现场信息，控制有关的执行装置，使得某些参数，如温度、压力、流量、液位等按一定规律变化，从而达到实现生产过程自动化的目的。另一类是飞行物体的自动控制，如飞机、导弹、人造卫星的制导等。这类系统要求反应速度快，可靠性高。通常要求系统的响应时间在毫秒甚至微秒级内。 实时信息处理它通常配有大型文件系统或数据，事先存有经过合理组织的大量数据，它能及时响应来自终端用户的服务请求，如进行信息的检索、存储、修改、更新、加工、删除、传递等，并能在短时间内对用户作出正确的回答。如情报检索、机票预定、银行业务、电话交换等都属此类系统。这类系统除要求响应时间及时外，并要求有较高的可靠性、安全性和保密措施等。 实时操作系统的特点 对外部进入系统的信号或信息应能做到实时响应。 实时系统较一般的通用系统有规律，有许多操作具有一定的可预计性。 实时系统的终端一般作为执行和询问使用，不具有分时系统那样有较强的会话能力。 实时系统对可靠性和安全性要求较高，常采用双工工作方式。 实时系统的代表——VxWorksVxWorks 操作系统是美国WindRiver公司于1983年设计开发的一种嵌入式实时操作系统，是嵌入式开发环境的关键组成部分。良好的持续发展能力、高性能的内核以及友好的用户开发环境，在嵌入式实时操作系统领域占据一席之地。它以其良好的可靠性和卓越的实时性被广泛地应用在通信、军事、航空、航天等高精尖技术及实时性要求极高的领域中，如卫星通讯、军事演习、弹道制导、飞机导航等。在美国的 F-16、FA-18战斗机、B-2 隐形轰炸机和爱国者导弹上，甚至连1997年4月在火星表面登陆的火星探测器、2008年5月登陆的凤凰号，和2012年8月登陆的好奇号也都使用到了VxWorks上。]]></content>
      <categories>
        <category>计算机</category>
        <category>历史</category>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>计算机</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统年表]]></title>
    <url>%2F2019%2F05%2F20%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F0%2F</url>
    <content type="text"><![CDATA[1950年代1956年 GM-NAA I/O 1959年 SHARE Operating System 1960年代1960年 IBSYS 1961年 CTSSMCP (Burroughs Large Systems) 1962年 GCOS 1964年 EXEC 8OS/360（宣称）TOPS-10 1965年 Multics（宣称）OS/360（上市）Tape Operating System（TOS） 1966年 DOS/360（IBM）MS/8 1967年 ACP（IBM）CP/CMSITSWAITS 1969年 TENEXUnix 1970年代1970年 DOS/BATCH 11（PDP-11） 1971年 OS/8 1972年 MFT (operating system)MVTRDOSSVSVM/CMS 1973年 Alto OSRSX-11DRT-11VME 1974年 MVS（MVS/XA） 1975年 BS2000 1976年 CP/MTOPS-20 1978年 Apple DOS 3.1（苹果公司第一个操作系统）TripOSVMSLisp Machine（CADR） 1979年 POSNLTSS 1980年代1980年 OS-9QDOSSOSXDE (Tajo)Xenix 1981年 MS-DOS 1982年 Commodore DOSSunOS(1.0)Ultrix 1983年 Lisa OSCoherentNovell NetWareProDOS 1984年 Macintosh OS（系统 1.0）MSX-DOSQNXUniCOS 1985年 AmigaOSAtari TOSMIPS OSOberon operating systemMicrosoft Windows 1.0（Windows第一版） 1986年 AIXGS-OSHP-UX 1987年 ArthurIRIX（SGI推出的第一个版本号是3.0）MinixOS/2（1.0）Microsoft Windows 2.0 1988年 A/UX（苹果电脑）LynxOSMVS/ESAOS/400 1989年 NeXTSTEP（1.0）RISC OSSCO Unix（第三版） 1990年代1990年 Amiga OS2.0BeOS（v1）OSF/1Microsoft Windows 3.0 1991年 Linux 1992年 386BSD0.1Amiga OS3.0Solaris2.0 （SunOS 4.x的继承者，以SVR4为基础，而非BSD）Microsoft Windows 3.1 1993年 九号项目（第一版）FreeBSDNetBSDMicrosoft Windows NT 3.1（第一版NT） 1995年 Digital UNIX（akaTru64）OpenBSDOS/390Microsoft Windows 95 1996年 Windows NT 4.0Linux2.0 1997年 InfernoMac OS 7.6（第一版官方正式命名为Mac OS）SkyOS 1998年 Solaris7 （第一款64位Solaris版本，是2.7舍弃主版本号的称谓）Microsoft Windows 98 1999年 AROSMac OS 8Microsoft Windows 98 Second Edition 2000年代2000年 AtheOSMac OS 9MorphOSWindows 2000Microsoft Windows Me 2001年 Amiga OS4.0 （2001年5月）Mac OS X 10.1Windows XPz/OS 2002年 Windows XP 64-bit EditionSyllableMac OS X 10.2 2003年 Windows Server 2003（2003年3月28日）Windows XP 64-bit Edition- 以Microsoft Windows Server 2003为基础，同一天发布。Mac OS X 10.3 2004年 Windows XP Media Center Edition 2005年 Windows XP Professional x64 EditionMac OS X 10.4 2006年 MicrosoftWindows Vista 2007年 Mac OS X 10.5 2009年 Mac OS X 10.6MicrosoftWindows 7]]></content>
      <categories>
        <category>计算机</category>
        <category>历史</category>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>计算机</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机历史——软件的发展]]></title>
    <url>%2F2019%2F05%2F19%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%86%E5%8F%B20%2F</url>
    <content type="text"><![CDATA[软件从未变得如此重要。当年赴摩尔学院听计算机讲座的先驱们万万没有想到，他们所学的知识竟然催生了一个新的行业，一个由计算机指令支撑起来的虚拟行业。软件分为多个层次，涉及到微代码、机器代码、汇编语言、高级语言的转换。数据库、软件开发过程，乃至整个企业结构都与之息息相关。计算机无所不在，它们的思想统领着整个世界。软件的重要性已变得无以复加，无怪乎世界上财力最雄厚的富豪当中，有好几个人是靠经营软件公司而积累了大笔的财富。 “优化软件就相当于优化一切。” 数据库随着编程语言的功能日渐强大，计算机的速度日益加快，容量日益扩大，可靠性日益增强。很快，计算机科学家就意识到，除了计算方程式的结果，计算机还可以在更广阔的领域大有可为。它们可以快速存储和处理大量的数据。如果只是单纯存储一系列数字，那倒不是什么难事，但是，如果存储的是病历记录或者财会记录，那么情况就会复杂许多。这就要求计算机必须能在短时间内迅速找到特定的信息条目——比如某一份病例中记述的病因，或者某一天产生的支付记录。怎样编排数据才能帮助我们轻松地找到所需信息呢？这些都不是什么新的问题——自从第一部词典问世以来，人们就面临着快速查找词条的问题。其解决办法，就是按照字母表的顺序编排词语。以某个单词为参照，词典中的其他词语中要么在它之前，要么在它之后。因此，我们在查找单词时，可以翻开词典的任何一页，然后根据上面的词语决定应该往前翻还是往后翻，直到将我们想查的单词查找出来。 第一代第一代数据库都是按照非常类似的原则编排的，它们于20世纪60年代问世，被称为导航式数据库管理系统（navigational database management system）。数据库第一次打开时，就会自动出现一个指针，指向第一条存储记录（好比翻开词典正文的第一页，就会看到第一个词条是以a开头的单词）。这些存储记录按照链表或网状结构编排，每一条记录当中都存有一个指针，指向相邻的记录。为了检索信息，计算机需要访问每一条记录，并通过其中的链接跳转到下一个记录，以此类推，直到找到用户所需的信息。如果用户想从一个庞大的数据库中检索出所有心脏病患者的病例，那么计算机就需要把每一条记录都访问一遍，才能将心脏病患者的病例筛选出来。这显然是一个非常缓慢而低效的信息检索方式，而且在那个年代，计算机和存储设备的运转速度都慢得可怜，要执行这样的检索是难以想象的。或许这种事情在今天的人看来有些匪夷所思，不过第一代数据库的确是不能用来查找信息。随着计算机和存储器的性能日渐提升，导航式数据库的局限性也愈发凸显。20世纪70年代，IBM的一名英国研究人员埃德加·弗兰克·科德（Edgar Frank “Ted” Codd）认为，数据库的模型亟待改进。科德与开发硬盘存储系统的IBM员工一道，设计了一个新的数据库模型，科德称之为关系模型。这种数据库结构比较智能化。数据的编排方式并不是像词典那样列出一长串条目，而是采用一系列数据库表，不同的数据库表通过关系键联系起来。为了便于大家理解关系数据库，我们用词典来打个比方。关系数据库就好比一系列分类词典，比如动词词典、名词词典、副词词典等等。如果你想查找某个单词——比如动词“bow”，那就只需要翻阅动词词典。如果你想找“bow”的名词词义，那就只需要翻阅名词词典。这比从头到尾地翻阅一本超厚的大词典要高效多了。关系数据库也是同样的道理，它采用关系键，将不同的记录联系起来。比方说，一个员工信息数据库可能会以员工编号作为关系键。知道了工号，你就可以在各个数据库表（好比各个分类词典）中分别查询员工的工资信息、家庭住址、计算机登录情况等等。每个数据库表中的值都可以作为关系键，用于在其他数据库表中查找相应的信息。也就是说，员工的职位描述也可作为关系键，用来查询员工是否具备参与机密工作的资格。 SEQUEL的出现20世纪70年代末出现了一种特殊的编程语言，用户可以通过它查询数据库中的复杂信息。这种语言脱胎于关系代数和微积分，全称为结构化英语查询语言（SEQUEL，即Structured English Query Language），后来又很快简称为结构化查询语言（SQL）。SQL支持查询、表达式、从句等多种编程元素。有了它，用户就可以在数据库中查询高度复杂的信息。数据库管理系统负责接收和翻译SQL表达式，并尽快返回结果（如果情况理想的话）。SQL中包含好几种语言，其中数据操纵语言（data manipulation language，简称DML）和数据定义语言（data definition language，简称DDL）能让用户运用简单易用的表达式在数据库中修改或添加数据。此后，数据库在原有的基础上继续改进，开始向面向对象的趋势发展，并进一步得到优化。索引的概念得到引进，经常查询的信息存储在高速的临时数据库中，临时数据库则与主数据库相连。正如图书目录一样，索引可以使用户查找所需信息的速度大幅加快。如今，数据库的设计特点表现为高度模块化，可访问性强。可扩展标记语言（Extensible Markup Language，简称XML）、超级文本预处理语言（Hypertext Preprocessor，简称PHP）等基于网页的语言可以使用SQL，连接在线数据库。（有了网页服务器，当你浏览的网页中包含这些高级语言写成的命令时，网页浏览器就会对它们进行翻译。）可以想见，未来数据库的分布将日趋广泛，可访问性日益增强，访问速度日益加快。 我们已经对数据库领域的巨大飞跃感同身受。就在几年前，家家户户的抽屉里还塞满了老照片，书架上堆满了书本、文件、录像带和CD，但是如今，我们查找、创建、购买的所有信息都是以数字形式保存下来的。大多数照片都已实现数字化，电子书正日渐占据图书市场的主流。大多数公司都喜欢给客户邮寄电子账单，而非纸质账单。视频和音乐已大多实现数字化。多年来，我们的财富不过是存储在银行计算机中的数字。政府以数字化的形式发布信息；医院在计算机上保存病例。越来越多的商店开始实行网上交易。我们只需要轻轻点击几次鼠标，就可以购买食品、汽车乃至任何种类的商品。所有这些海量的数据都存储在数据库中。它们的界面可以是一个赏心悦目的网页，供人随意浏览各种美观的照片；可以是一家网上商店，供人随心挑选品类丰富的商品；可以是一款功能强大的音乐播放程序，能让人徜徉于音乐的海洋；甚至可以是一款会计应用程序，能让人随时监测开支情况。但是，在多姿多彩的界面背后，让这一切成为可能的，便是精巧的数据库技术。 软件危机如今，软件业可谓风生水起，蔚为大观，仿佛这个行业的发展向来一帆风顺，毫无波澜。但是，正如电子业历经了“数字暴政”的阵痛，才有了集成电路的诞生，新生的软件业也经历了危机的考验，这场危机还推动了一门全新学科的诞生。 编写大型程序的巨大困难程序员遇到的问题从一开始就很明晰。虽然有了新的高级编程语言的帮助，开发人员在编写代码的过程中可谓得心应手，但是，前所未有的重大问题依然在不断涌现。20世纪60年代，随着集成电路的发明和摩尔定律的问世，计算机的性能每年都在突飞猛进。与此同时，软件应用也在以类似的速度不断飞跃。然而，就在这个过程中，程序员日益强烈地意识到，他们的程序正变得越来越难以掌控。程序当中的错误太多，软件并没有发挥应有的效果，而且开发系统的过程似乎正变得意料之外地漫长。 这些问题在1968年达到了顶点。在有史以来的第一次软件工程大会上，世界各地的计算机科学家齐聚一堂，共同讨论他们关切的问题。他们忧心忡忡，这一点从会上的讨论中就可以看出来： 麻省理工学院的罗伯特·格雷厄姆（Robert Graham）表示：“我们投入了长年累月的研究，耗费了巨大的投资，到头来却发现，我们从一开始就没有把系统研究透彻，软件根本没有取得预期的效果。我们就像莱特兄弟制造飞机一样，辛辛苦苦地把飞机造好，将它推下悬崖，任凭它轻而易举地坠毁，然后再从头开始。”密歇根大学计算中心（University of Michigan Computing Center）的伯纳德·加勒（Bernard Galler）表示：“我想举几个在IBM碰到的不好的例子。有一次，用户提出，希望能够增强PL/1语言可扩展性。对此，IBM经过一周的内部讨论，最终下结论称，这种事情不可能做到。因为语言设计师不打算告诉用户怎样实现所需的扩展。还有一个例子：OS/360操作系统的作业控制语言（job control language，简称JCL）开发出来以后，用户在设计阶段根本无法事先看到任何选项。为什么会出现这种情况呢？”丹麦第一家计算机公司A/S Regnecentralen的员工彼得·诺尔（Peter Naur）表示：“……软件设计师的角色类似于建筑师和土木工程师，尤其是规划城市、工厂等复杂建筑的设计师。因此我们应该学会从这些领域吸取灵感，攻克我们遇到的设计问题。” 此次大会落幕后，另一场大会很快召开，其宗旨是讨论技术和管理思想。从这一刻开始，软件工程学作为一门新的学科登上了历史的舞台。伊恩·萨默维尔是现代软件工程师、英国圣安德鲁斯大学（St. Andrews University）教授，他撰写了很多业内的权威教科书。他表示，新学科的命名颇有内涵，意在表明，人们从此将采取系统的、有组织的方式来编写软件。不过，大会的主办方给出了不同的说法，“他们声称之所以发明这个术语，只是出于调侃的心态，没想到这种叫法就传播开了”。当然，这样命名是为了“故意制造煽动的效果”，以激发研究人员行动起来。还别说，这样做真的起到了效果。没过多久，许多关键性的技术革新开始涌现，它们专门针对的是软件工程学领域，旨在辅助程序开发人员提高编程能力，写出高效的软件。在这一理念的指导下，新的编程语言得到开发。戴维·帕纳斯（David Parnas）等研究人员提出了信息隐藏的概念，这一概念在模块化编程和面向对象的编程领域举足轻重，它可以确保数据及相关函数封装在对象内，与其他的数据和函数分隔开来。这就好比采用标准化模块制造汽车——车载收音机等部件的更换不会影响到其他部件。同理，如果你设计好程序之后，突然想对某个地方进行改写（比方说将某个函数或数据结构更换），那么程序中的其他函数和数据完全不会受到影响。集成开发环境（Integrated development environment，简称IDE）的发明，就是为了让编程变得更加轻松。它们的作用就好比文字处理器——程序开发人员可以在不同的窗口编写代码，并对其进行编译和调试。正如文字处理器可以检查拼写和语法错误，集成开发环境也可以帮助编程人员找出程序中的错误，并提供大量实用的工具进行除错。现代的集成开发环境通常包括一系列工具，比如：手持设备模拟器；用于设计图形用户界面（Graphical User Interface，简称GUI）的工具；全方位的帮助系统，用于辅助编程人员从已有的库——即程序编程接口（application programming interface，简称API）中寻找合适的函数。 如何面向用户除了发明实用的编程工具，研究人员很快意识到，还有更好的软件设计方法亟待开发。这就好比汽车制造商不能把仅仅把目光放在硬件上，还应着眼于汽车的用途、目标客户的定位、成本开销的大小，从而将生产问题化整为零，分解成一个个具体的问题，比如：应该采用什么样的发动机、传动部件、转向系统、制动系统、车轮系统和座椅系统？车内需要容纳多少人？生产一台汽车需要多少时间？编写软件也是同样的道理。一个大型软件项目可能会比制造汽车复杂得多，怎样设计才能确保项目的高效运转？研究人员很快意识到，要做到这一点，必须确立一个明确的软件生命周期。首先，你必须合理定位产品和项目需求。接下来要做的，就是设计、运行和测试软件，并将其运行情况清晰地记录下来。最后要做的，就是发布软件，或许在这个阶段，你还需要指导用户如何高效地使用软件、如何进行必要的维护工作。 这些事情说起来容易，做起来难。产品或项目的需求并不好确定，因为顾客往往并不知道自己真正的需求到底是什么，因此可能会举棋不定、自相矛盾，甚至改变主意。他们往往不具备编程人员的思维方式，因此不知道如何从软件开发的角度表达自己的需求。换句话说，对于哪些事情在技术上可行，而哪些不可行，他们基本上没什么概念。有的时候，编程人员连目标用户是哪些人都无法确定，因此，真正应该提要求的人反而没有这个机会。 如何规划大型项目除此之外，不同的设计阶段应该如何开展，这也是摆在编程人员面前的一大难题。项目的开发架构是应该采用“瀑布模型”（waterfall model）——像流水下坡一样顺次开展每个阶段，还是应该采用“螺旋模型”（spiral model）——反复开展每个阶段，开发一系列原型软件，以最大限度地降低风险？软件的开发是应该遵循迭代式和增量式的过程，还是应该采用“灵活性强”的方式，以迅速适应可能发生的变化？就算你知道了开发软件的最佳顺序，怎样才能把每一个阶段的工作都做到最好？应该采用哪些设计方法和工具？怎样测试软件，才能确保万无一失？怎样维护软件，才能使之适应未来的变化？ 正因为软件工程学专家孜孜不倦地攻克上述难题，软件项目的发展才得以适应硬件的发展需求和用户复杂的使用需求。软件工程学着眼于软件开发的方方面面，比如对软件体系结构进行建模，采用可视化程序设计，使用形式化方法测试软件、提高其性能的可靠性。伊恩·萨默维尔认为，软件工程学领域已经取得了许多重大的进步，这些进步给软件开发带来了实实在在的影响。“开发不同类型的软件，需要采用不同类型的软件技术和方法，”他表示，“配置管理（Configuration Management，简称CM）就是一个非常重要的项目管理方法，它支持并行开发。信息隐藏的概念是由帕纳斯在1972年提出的，它在抽象数据类型（Abstruct Data Type，简称ADT）领域得到了进一步发展，并影响了大多数现代编程语言。在关键任务系统领域，我们不仅可以采用安全分析和可靠性分析的方法，还可以运用容错技术，为航空器、化工厂等重要设施建立安全可靠的系统。统一建模语言（Unified Modelling Language，简称UML）将多种建模概念融合在一起，如今已成为软件系统建模的标准方式。编程环境的思想于20世纪70年代问世，在20世纪80年代得到进一步发展，如今已在软件工程学界得到广泛采纳。”安东尼·芬克尔斯坦是软件工程学教授，在伦敦大学学院担任工程学系系主任。他认为，正因为有了软件工程学的帮助，程序员才得以高效利用时间。“如果没有软件工程学，我认为硬件与软件之间的性能差距会进一步扩大。制约软件开发的主要因素就是缺少训练有素的人才，现在也是如此。如果当初没有足够的人才投身于软件工程行业，我们就无法取得今天的成就了。” 软件膨胀不过，尽管为数众多的软件工程师竭尽全力地投身于技术攻坚，但是依然无法解决所有的问题。我们每次使用计算机时，都会对软件工程领域的一大问题感同身受：由于某种原因，软件每次升完级以后，其运转速度似乎都会变慢。计算机科学家（及众多编程语言的发明者）尼古拉斯·维尔特（Niklaus Wirth）观察到了这一现象，人们将其称为维尔特定律（Wirth’s Law）。维尔特定律的内容是：软件变慢的速度永远快过硬件变快的速度。其他科学家也发表过类似的观点。曾在英特尔担任研究人员的兰德尔·肯尼迪（Randall Kennedy）就是其中一人。他曾写道：“虽然与几年前的Office 2000相比，Vista系统上的微软的Office 2007 虽然处理能力提高了将近两倍，但是占用空间却多出了11倍以上。”造成这一现象的罪魁祸首是软件膨胀（software bloat）——新版本的软件往往只是在原版本的基础上叠加了新的代码，而并没有经过重新编写。 维尔特定律表明，纵使计算机的运行速度快得惊人，新一代的软件的运 行速度也比不上十年前的老版本。目前，计算机科学家正在费尽心思解决这个问题。不过萨默维尔深知，这并不是软件工程学领域的唯一挑战。“软件项目面临的主要挑战在于，开发环境正变得越来越复杂。这是因为，我们在建立新系统的过程中，将不同的供应商提供的各种系统和服务整合了起来。原本，在软件工程学领域，很多理论之所以能够成立，往往是基于这样的前提，那就是，系统完全处在软件开发人员的掌控之下，软件开发人员可以做出明智的决定来开发和改变系统。当这样的前提不再成立时，软件测试等方法必须做出相应的调整，以适应新的情况。”这一观点引起了一些计算机科学家的高度重视。伦敦大学学院教授马克·哈曼围绕搜索问题对软件工程学进行了研究。他按照遗传算法——也就是由“优胜劣汰”的生物进化规律演化而来的随机化搜索方法，利用计算机来寻找特定软件的最优测试方法。“软件测试是衡量软件质量、寻找优化方法的关键手段之一。测试的内容之一，就是寻找特定的输入，使程序执行特定的代码片段，”哈曼表示，“人工完成这样的工作需要花费很大的心血。这就好比你得从厚厚的地址簿里大海捞针，将一个人的电话和住址找出来。但是，如果计算机能够对测试用例进行评定，我们可以轻而易举地将这个过程自动化。” 其他危机不过，仅仅有个聪明的测试方法是不够的。我们所说的危机与20世纪60年代末的软件危机已经无法同日而语，但是从某种程度上讲，软件业依然面临着定位问题。大型软件开发项目依然经常失败，尽管软件工程师尽了最大的努力。有时候，问题只是出现在成本和时间上——我们并不擅长估算软件开发产生的耗费。“我们的软件估算水平很差，”芬克尔斯坦表示，“如果你让我‘开发一个售卖二手教科书的网页前端，’我可能一时半会儿没法告诉你需要多少时间。运气好的话，我可能之前就做过一次这样的项目，但是我在这方面的经验也就仅限于此了。’”不过，重大的失败也有可能是由更微妙的原因造成的（而且这样的事情不在少数，造成的损失也极为惨重）。芬克尔斯坦认为，问题的症结并不在于分析师和开发者经验不足。“个人认为，这些系统之所以失败，都是一些人们很熟悉的问题造成的：比如在项目设计和开展阶段犯了低级错误，”他表示，“你必须问自己，既然人们对这些问题都很熟悉，为什么还要一次又一次地犯同样的错误？他们是傻子吗？他们没看过萨默维尔的书吗？这些问题前十页就讲了，哪怕稍微翻翻也好啊，又不一定要全读完！我觉得，问题的症结是，企业结构、管理决策结构与开发软件的技术过程存在不协调。因此，这些系统之所以会失败，问题出在管理上，而不是工程上。”软件工程领域的挑战还表现在，怎样满足客户的信息安全需求，怎样设计软件才能使之适应互联网时代的潮流。此外，一些所谓的“非功能性需求”也越来越值得重视，比如电源或电池寿命。在这个问题上，哈曼的想法比较现实：“如果我在乘坐越洋航班时，笔记本的电量在半路上就耗光了，那么就算里面的软件再好，对我来说一点用也没有。我宁愿软件耗电量低点，让续航时间久点，就算软件里头到处都是漏洞也没有关系。”芬克尔斯坦也这么认为：“在软件工程领域，我们一直致力于开发新特性，从来没有想过省电的问题——一般都不会有人往这方面想，除非你要设计航天器。但是现在，这个问题已经变得很关键。有很多之前没有考虑过的新特性一下子变得非常重要。” 还记得以前我们讲到的编写并行软件吗？那是帕特森给整个行业的科学家提出的挑战。芬克尔斯坦确信，它会给软件工程领域带来重大的变革。“软件工程领域面临的另一大挑战就是多核技术。如果软件无法充分发挥多核技术的优势，那么一台计算机就算内核再多也于事无补。要是采用一个内核就足以运行所有软件，那么剩下15个内核留着干嘛呢？总不可能都用来运行杀毒软件吧。我们所需要的，不仅仅是编程技术的一个突破，而是整个软件工程领域的革新。这肯定会改变我们当前的游戏规则。”]]></content>
      <categories>
        <category>计算机</category>
        <category>历史</category>
        <category>软件</category>
      </categories>
      <tags>
        <tag>计算机</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机先驱——莫里斯·威尔克斯]]></title>
    <url>%2F2019%2F05%2F19%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%85%88%E9%A9%B14%2F</url>
    <content type="text"><![CDATA[Sir Maurice Vincent Wilkes，1913年6月23日－2010年11月29日1931年他进入剑桥的圣约翰学院，之后进入剑桥著名的卡文迪什实验室工作。于1938年10月取得剑桥大学博士学位，而他的硕士学位是在当年年初才取得的。英国计算机科学家。设计和制造了世界上第一台存储程序式电子计算机EDSAC，在“工程和软件等计算机领域都有许多开创性成果”。 开端这是1946年的一个温暖和煦的仲夏日，时值星期一早晨。回想起三年前与图灵在下午茶时间的热烈讨论，克劳德·香农觉得恍如隔世。此时此刻，他正在宾夕法尼亚大学的摩尔电气工程学院学习一门为期八周的课程，这门课目前已经上到了第三周。能够受邀来此听课，对看他来说已是一大荣幸，毕竟，这是少数人才有的殊荣。课程采用讲座的形式，主题是电子数字计算机的设计。这是世界上第一门关于计算机科学的课程，香农发现，课上所学的许多思想在他的头脑里擦出了灵感的火花。他最近从莫奇利那里学到了一个新词——“编程”。它通常作为动词使用。给电子计算机编程是一个让人耳目一新的概念。香农还听到了一些关于办公室政治的八卦：给他们开课的两位讲师——莫奇利及其同事埃克特四个月前刚从宾夕法尼亚大学辞职，原因似乎是围绕“埃德瓦克”产生的专利纠纷。另一名讲师戈德斯坦近期就要去高等研究院（IAS）入职了，届时他将与香农的老同事约翰·冯·诺依曼共事。冯·诺依曼本来也要到这里来开设两个星期的讲座，但是他好像不会来了，因为临时有事。 在一篇机密级的论文中，香农发布了他最近在贝尔实验室开展密码学研究的部分成果。这些研究成果与他当年攻读理科硕士期间提出的思想一脉相承，只不过二者的着眼点不同。香农当年着眼的是开关电路，现在着眼的则是密码学背后的数学原理。他开始意识到，破译扰频加密的信息，其实大体上就相当于给正常传输的信息纠错。举个例子，如果一段编码中出现了重复信息——比方说它的内容中包含许多常见的词语如“这个”、“一个”、“和”，那么这段编码破译起来就会轻松许多。因为我们知道，“这个”、“一个”、“和”这类简短的词语是句中常见的语法成分，就算把它们的每个字都改头换面，也不难根据它们在句中出现的位置来判断其成分。只要破译了高频词，那么整条加密信息指的是什么内容，或许就能猜出个大概了。因此，要想增加破译难度，必须尽量减少冗余信息。但是，如果你想尽可能多地保留原始信息，而记忆存储系统又很容易出错，那就最好少删除一些冗余信息。检验信息是否出错的方法之一，就是设置奇偶校验位（parity）。至于奇偶校验位是指什么，还得从比特的概念说起。比特（bit）是内存中的最小单位，也称作“位”、它只有两个状态，分别以1和0表示。我们将8个连续的比特叫做一个字节（byte），比如（1、0、0、1、1、1、1、0）就是一个典型的字节。如果其中某一位存储了错误的值，那就会导致信息出错。为了检测信息是否出错，我们在每一个字节（8位）后面又额外增加了一位，称为奇偶校验位。这样一来，原来的8位字节就变成了新的9位字节。奇偶校验位也只有1和0两种值。如果原字节中1的个数为奇数，那么奇偶校验位就设为1，这样一来，新字节中1的个数就变为偶数；反之，如果原字节中1的个数为偶数，那么奇偶校验位就设为0，这样一来，新字节中1的个数依然为偶数。也就是说，凡是带有奇偶校验位的字节当中，1的个数始终应该为偶数，如果你发现某个字节不是这样，那就说明它有错误，这段字节包含的信息就需要重新读取。（这个方法在20世纪50年代早期开始在计算机领域广泛采用，后来，人们很快就开发出了更多高级的方法。） 言归正传，香农在摩尔学院听讲座的过程中，了解了二进制对于计算机的重要价值：二进制数不仅是计算机内各个部件交换信息的重要载体，还是确保信息存储和检索过程不出差错的重要工具。后来，香农发明了术语“比特”来指代二进制数位（binary digit），同时阐述了如何利用比特来衡量信息量，并对信息进行传输、加密、压缩、纠错。在当年赴摩尔学院听讲座的人当中，香农并不是唯一一个计算机领域的先驱。莫里斯·威尔克斯也去了摩尔学院，只不过他差点就错过了这门课程。香农在台下听莫奇利讲解二进制与十进制数的那一天，威尔克斯还在英国。1945年，莫里斯·威尔克斯在剑桥大学听说了埃克特和莫奇利在美国研制埃尼阿克的工作，于是在1946年2月给学院提交了一份报告。他在报告中写道：“这是一个大有可为的研究领域，电子应用技术首当其冲。它在战时取得了迅猛的发展。 美国人在这门学科上已经领先了一步，我觉得剑桥也应该迎头赶上。”三个月后，机械计算机专家莱斯利·科姆里（Leslie Comri）来访剑桥。他从美国带来了一份手稿副本——即约翰·冯·诺依曼所写的《关于埃德瓦克的报告初稿》。威尔克斯只有一个晚上的时间阅读报告，当时还没有影印机，他只能边读边作笔记。威尔克斯很快就被报告的内容吸引住了。“我很快就意识到这个研究成果非同小可，”他表示，“从那以后，我对计算机的发展前景一直没有怀疑过。”就在威尔克斯依然对报告的内容记忆犹新之时，他突然接到了摩尔学院院长哈罗德·彭德（Harold Pender）发来的电报，邀请他去参加一门新开的电子计算机课程。威尔克斯的越洋航程并不顺利。尽管伙食条件一流，但是住宿条件太差，35个人挤在一艘只能容纳20个人的小货船里。更糟糕的是，发动机在中途抛锚了好几次。就这样，威尔克斯一路历经磨难，终于在8月15日抵达了纽约，上岸后又马不停蹄地赶路，总算在8月18日赶到了费城。这时候，他已经错过了三分之二的课程，好在前面的课程大多都是些入门性质的讲座。到了8月19日，也就是星期一，威尔克斯抵达摩尔学院，正好赶上当天下半节课。这堂课讲的是埃尼阿克的细节内容，讲师提供了详尽的电路图。威尔克斯回到剑桥大学，满脑子都是计算机领域的前沿思想和美国人取得的一些关键成果。威尔克斯认为，是时候研制一台实用的存储程序计算机了。幸运的是，没过多久，餐饮巨头J. Lyons &amp; Company就给他提供了科研经费和技术人员，因为该公司需要计算机进行会计核算，管理员工工资单。威尔克斯的项目进展很快，他在雷达领域积累的经验更是大大加速了这一进程。项目团队在此基础上构建了一个工作记忆系统，用于存储数字。威尔克斯在研制新机器的过程中，旁听了图灵开设的几个讲座，讲座的主题是图灵关于自动计算机的设计思想。不过，两个人的设计理念并不一致。图灵认为，计算机应该在水银延迟线存储器的基础上进行优化设计。威尔克斯的观点正好相反。“我认为，水银延迟线存储器迟早要被真正的随机存取存储器淘汰。与其把时间和精力都花在一项短命的技术上，还不如多下点功夫研究编程，毕竟，编程领域还有那么多问题值得研究。”图灵也不赞赏威尔克斯的设计理念，他在一篇备忘录中写道，威尔克斯有一些理念“比较偏向美国传统，遇到什么困难就喜欢依赖设备，而不喜欢动脑子。”但是事实证明，威尔克斯的方法更加实际。剑桥大学的电子延迟存储自动计算机（Electronic Delay Storage Automatic Calculator，简称EDSAC）于1949年5月6日投入运行，直到1958年才光荣退役。它是世界上第一台实用的存储程序计算机。 学习计算机编程剑桥大学的EDSAC计算机并不只是一台前沿尖端的机器，它还开创了计算机领域的先河。此前的计算机每次执行新的运算，都需要插入不同的线路进行重新装配，而EDSAC则通过存储器中的软件实现各种不同的运算操作，这就对编程提出了很高的要求。为了写出功能强大的软件，威尔克斯和戴维·惠勒（David Wheeler）等研究人员提出并改进了许多新的思想，时至今日，这些思想在计算机编程领域已占据主流地位。不过编程在当时并不是一件容易的事情。所有的早期计算机先驱很快就意识到，一旦设计出存储程序计算机，就必须拼了老命地编写计算机能够运行的程序。如果任何程序都无外乎是一组能够触发数学或逻辑学电路的二进制数，那么编写软件就会变成一场噩梦——而事实也的确如此。1949年6月，惠勒第一次意识到了编程的艰难。他后来回忆起了当时的情形：“那时候，我正试着让自己编写的第一个真正意义上的程序运转起来。有一次，我像往常一样从EDSAC机房出来，准备去操作打孔机，突然站在楼梯转角处犹豫了，心里意识到，单是给自己的程序除错，可能就要花掉我大半辈子的时间。”显然，当时的科学家需要一些新的思想，来简化编程过程，提高编程能力。对此，威尔克斯（在几年后）提出了一个方法，称为微程序设计。当时，麻省理工学院正在研制的旋风计算机（Whirlwind）给了他部分灵感，让他意识到，并不是每一条低级指令——比如除法——都需要电子电路来执行。复杂的指令完全可以分解成一系列简单的指令，而微代码编写出来的微程序可以作为二进制机器代码和硬件之间的桥梁。事实证明，这一方法实用性很强，时至今日，复杂指令集计算机（Complex Instruction Set Computer，简称CISC）处理器依然采用了这一思想原理，以执行高度复杂的操作。而精简指令集计算机（Reduced instruction set computer，简称RISC）处理器则不使用微编程。但是即便是使用微代码，计算机编程人员依然需要编写一长串的数字，即机器代码指令。而且，早期的编程人员还因为机器的内存容量极其有限而备受掣肘。EDSAC的内存只有两千字节左右（放到今天，一部手机的内存都比它大几百万倍）。为了解决这些问题，威尔克斯的团队又想出了一个妙招——编写子程序。研究人员意识到，许多程序在运行的过程中，都需要重复执行某个操作——比如在某个复杂的数字运算中，需要多次进行开平方操作。如果每次开平方都得把平方根代码写上，那么程序当中就会出现许多重复代码，占用不必要的空间，使程序变得庞大而低效。这就好比你在写一个句子时，不仅构造了完整的语法结构，还将句中每个词语的定义也写了下来。为了简化编程过程，威尔克斯的方法是建立子程序库，也就是将常见的函数单独列出，集中起来，就像把常见的词语及其释义收录在词典中一样。一旦程序在运行的过程中需要使用到某个常见函数，计算机就会在子程序库中“查找定义”，执行相应的子程序代码，根据输入值进行运算，再将运算结果返回。在这一方面，威尔克斯的理念已经领先于同时代的大多数人。冯· 诺依曼有一次突然造访，与威尔克斯进行了讨论。两个人的观点产生了分歧。威尔克斯回忆道：“他觉得应该把开平方运算嵌入到计算机的指令集中……我自己的立场则有所不同，我已经把子程序看做是对基本指令集的扩展，所以觉得没有必要再在指令集中嵌入一个特殊的函数。”由于威尔克斯领导的剑桥大学研究团队很早就开始在编程领域开疆拓土，他们对编程的艺术也颇有心得。普林斯顿高等研究院的冯·诺依曼喜欢绘制“程序框图”，来展示程序应该如何运作。所谓程序框图，大体上就是一系列带箭头的步骤，可以展示控制流。不过，威尔克斯手下最好的程序开发人员戴维·惠勒认为，要想写出出色的软件，还需要其他的方法。“我们关心的首要问题是，用户在操作过程中是否得心应手，因此在这方面也下了很大的功夫。”他表示，“模块化设计的编程风格很早就开始得到推行。这是我们开展编程教学的方式。当然，我们也知道一些其他的方法，比如冯·诺依曼的程序框图。不过这些方法一般都不用，就算用也只是拿来说明已经完成的步骤。我 们发现，只要将复杂的问题进行分解，用一个个子程序加以解决，然后将子程序置于主程序的控制之下，就可以逐步形成模块化设计的思维方式，到时候程序设计自然水到渠成，根本不需要使用到程序框图。个人认为，程序框图最容易让人写出垃圾软件。并不是说这种方法毫无价值，只不过你要是想拿它来代替思考过程，根本就不管用。”威尔克斯的团队还考虑到了程序员可能遇到的其他困难。他们从一开始就意识到，尽管计算机只能理解数字，但很少有人能够在只采用数字的情况下编写程序，了解计算机的运行过程。人的大脑习惯了阅读文字和符号，而不是处理一连串数字。惠勒认为，冯·诺依曼在高等研究院研制的计算机在这一方面做得很差，完全比不上剑桥大学的 EDSAC。“它太原始了，这让我非常震惊，”他表示，“我估计它的程序是用二进制输入的。我们剑桥大学的研究团队很早就开始采用了一种叫做‘汇编程序’的工具。”它能够转换编程语言，从十进制转为二进制，使用助记符，可引用代码，可分隔字段，可自动定位子程序，还具备其他各种功能。我们基本上从开展项目的第一天起就已经在使用汇编程序了。这极大地简化了编程过程。这样一来，程序开发人员就不需要和抽象的二进制数打交道了，他们可以采用简短的词语来编写程序，这些词语看起来有点像英文单词。与一连串抽象的二进制数字相比，即使是奇怪而又晦涩的文字无论在阅读还是理解上，都要轻松许多。它与处理器使用的低级的代码没有太大的分别：其中的每一个词语（或命令）——比如“cmpl”、“jmp”——都直接对应于机器代码中的一条指令。要将汇编语言写成的程序转换为相应的机器代码，就需要使用到另一种计算机程序，称为汇编程序。汇编程序读取的是用汇编语言书写的源程序，输出的是用机器语言表示的目标程序。汇编语言在计算机领域举足轻重，20世纪90年代的所有程序都是由汇编语言写成。几十年来，有两种常见的程序只采用汇编语言：一是计算机游戏（因为开发人员希望尽可能地提高游戏的运转速度，同时尽可能给玩家带来极致丰富的游戏体验），二是操作系统。即便是在当今时代，程序员要想编写速度超快而形式简洁的代码，都免不了要采用一些汇编语言。 攀登更高峰1951年，计算机开始搭载好几个层次的软件。第一层是微代码，它完全依赖于芯片内部的硬件连接。第二层是机器代码，它比微代码更抽象一些。第三层是汇编语言，它比机器代码可读性稍强。计算机编程，说白了其实就是告诉计算机应该使用哪种逻辑和算术电路。要想给计算机编程，程序员可以使用汇编语言来写代码，而汇编语言正如我们在上一节所看到的那样，和英文单词有些类似。这些代码随即由汇编程序转化为机器代码，机器代码定义微程序的指令，微程序则在算术和逻辑单元（ALU）的电子元件中被翻译为一系列指令的组合。 不过，汇编语言对于许多程序员来说依然难度太大。如果你想处理更复杂的思想和概念，那么，纠结于个别的跳转指令只会拖累你的步伐。 如果你希望自己的程序能够在完全不同的处理器上运行，那就需要采用高级的编程语言，也就是独立于底层硬件的计算机语言。1953年，随着电子计算机在全世界遍地开花，发明抽象编程语言的问题开始受到广泛关注。莫里斯·威尔克斯受邀主持了美国计算机协会（ACM）在麻省理工学院召开的一期研讨会，专门探讨这个问题（当时的会议主题为自动编程）。威尔克斯至今还清楚地记得当年会上的讨论情况。“与会者的意见分歧相当尖锐。有些人认为，凡是试图绕开困难的做法都是误入歧途。程序员只有老老实实地恪守本分，编程领域才会取得更大的发展。另一方面，还有一些人认为，只有新的技术才具有实实在在的实用价值。”（时至今日，计算机科学家当中依然存在这两派的纷争。）许多研究人员已经在试验新的、更简单的编程语言。早在1949年，约翰·莫奇利就发明了一种语言，称为简代码（Brief Code），后来更名为短代码（Short Code）。短代码虽然使用起来简单许多，但是需要翻译——也就是说，计算机每次运行这种语言编写的程序，都得临时将短代码翻译成机器代码。这就意味着，这种程序的运行速度比机器代码写成的程序慢54倍。与此同时，在英国曼彻斯特，一位名叫埃里克·格伦尼（Alick Glennie）的研究人员发明了另一种语言。这种语言易于使用，可通过另一种程序自动转换为机器代码，因此具备简单实用、运行速度快的双重优势。格伦尼将其称为自动代码（Autocode）。 显然，用自动代码写程序比用汇编语言要轻松许多。其中有些自动代码语句和好几条机器代码指令相对应，不过程序员不需要为此挂心。只要使用另一种称为编译器的程序，就可以将这段由自动代码编写而成的简洁英文命令翻译成机器代码。自动代码是世界上最早出现的编译型高级编程语言。自计算机协会在麻省理工学院召开研讨会，讨论自动编程问题后，越来越多的计算机科学家开始意识到，编程过程的简化势在必行。1957年，IBM的约翰·巴库斯（John Backus）发明了另一种编译型高级编程语言，称为福传（FORTRAN）。福传的全名是Formula Translation，意思是“公式翻译”。这种语言甚至比自动代码更高级，可以用来编写更加复杂的程序。它的编译器也极为智能，可以生成非常简洁高效的机器代码。没过多久，许多适用于其他计算机的福传编译器相继问世，这样一来，同一款福传程序就可以编译成不同计算机所特有的机器代码。从这一刻开始，程序员便有了一种新的工具——“便携式”代码，它可以使同一款程序在完全不同的计算机上运行。很快，其他编程语言也开始纷纷效法，比如算法语言（ALGOrithmic language，简称ALGOL）、列表处理语言（LISt Processor，简称LISP）、初学者通用符号指令码（Beginner’s All-purpose Symbolic Instruction Code，简称BASIC）。随着计算机设计师开始研制晶体管计算机，这些语言也得到了稳步改进。很快，计算机科学家便能分析编程语言，并用数学方法——包括邱奇的λ演算将其形式化。程序员也可以在代码中表达更抽象的概念，而不需要操心低层次的细节问题。各种类型的编程语言相继问世。早期语言基本上都是过程式语言（程序员告诉计算机如何执行过程步骤），后来的语言则采用了不同的编程范型。在面向对象的语言（Object-Oriented Language）中，数据及其操控方法都封装在“对象”中，以实现代码的模块化，防止数据的意外损坏（这一点也是程序的“副作用”）。函数式编程语言利用若干简单的执行单元让计算结果不断渐进，逐层推导复杂的运算，而不是像过程语言一样，设计一个复杂的执行过程。此外，还有更多适用于并行计算机的程序语言相继问世。正因为众多早期先驱的开创性工作，如今人们习以为常的一些重要编程思想才得以诞生。威尔克斯继续投入计算机语言的研究，他在改良算法语言60（ALGOL 60）的基础上发明了CPL（Combined Programming Language）编程语言。这种语言并没有受到热烈的反响，但是却奠定了BCPL（Basic Combined Programming Language）语言的基础。BCPL进一步发展演变，推动了B语言和C语言的问世。直到现在， C语言（以及在此基础上形成的诸多语言，如C++、C#、Objective C）或许是世界上应用最广泛的计算机编程语言之一。人们当前使用的许多众所周知的操作系统（比如UNIX、Linux、Mac OS X、Windows）都是用C语言写成的。如今，几乎每一台计算机上都搭载了C语言编译器，方便用户使用C语言编写代码。]]></content>
      <categories>
        <category>计算机</category>
        <category>历史</category>
        <category>先驱</category>
      </categories>
      <tags>
        <tag>计算机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机先驱——罗伯特·诺伊斯与戈登·摩尔]]></title>
    <url>%2F2019%2F05%2F18%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%85%88%E9%A9%B13%2F</url>
    <content type="text"><![CDATA[Robert Norton Noyce，1927年12月12日—1990年6月3日1953年，获麻省理工学院（MIT）博士学位；1949年，获格林尼学院文学学士学位。1968年创办英特尔公司、1957年创办仙童半导体公司。 Gordon Moore，1929年1月3日—？加州大学伯克利分校的化学学士学位，并且在加州理工学院（Caltech）获得物理化学（physical chemistry)博士学位美国科学家，企业家，英特尔公司创始人之一。 摩尔定律发明硅芯片后，罗伯特·诺伊斯继续和同事戈登·摩尔（Gordon Moore）在飞兆半导体公司（Fairchild Semiconductor Corporation）研究集成电路技术，直到1968年，两人成立了一家新公司，即著名的英特尔。他们和全世界的业内先驱一道，共同掀起了电子学领域的技术革新。早期的集成电路还只有几百个、乃至上千个晶体管，但制造工艺的稳步改进使单个芯片上可以容纳的晶体管数目越来越多。（20世纪60年代早期，集成电路技术之所以迅猛发展，很大程度上是因为美国导弹计划和阿波罗太空计划的推动。）集成电路的日益复杂使戈登·摩尔在1965年做出了一个预测。当时，他注意到，从1958年集成电路问世到1965年，单个芯片上的晶体管数量每年都翻了一倍。于是，他预测，这个趋势至少还会持续十年。后来，他修正了自己的观点，认为单个芯片上的晶体管数量每两年就会翻一倍。1970年，加州理工学院（California Institute of Technology简称 Caltech）教授卡弗·米德（Carver Mead）发明了专门的术语，将这个预测称为“摩尔定律”。令人惊叹的是，这个“定律”似乎一直都很准。单个芯片上可容纳的晶体管数量在20世纪70年代中期为一万个，在1986年达到了一百万个，在2005年则为十亿个。尽管经常有人提出，摩尔定律很快就会失效，因为晶体管的尺寸越做越小，已经快要达到物理定律的极限，不过到目前为止，这项卓越的技术依然保持着强劲的发展势头。计算机技术一向与电子学的前沿技术联系紧密，因此从20世纪60年代开始，硅芯片技术的迅猛发展也带动了计算机的更新换代。摩尔在英特尔的同事大卫·豪斯（David House）认为，从摩尔定律可以推断出，计算机的性能每隔18个月就会翻一倍。他说的基本没错——这些年来，计算机的性能大约每隔20个月就翻了一倍。摩尔后来开玩笑说：“18个 月是豪斯说的，不关我的事。” 正因为电子学正向着微型化的方向大幅迈进，我们的计算机每年都在变得更小巧、更便宜、更强大。早期的计算机都是庞然大物，很多情况下只能靠远程终端控制（一台大型计算机就需要很多个键盘和显示屏）。很快，小型计算机和个人计算机（台式机）相继问世。随着单一芯片上集成的元件继续增多，计算机的尺寸进一步缩水，由此产生了便携式个人计算机，也就是笔记本。后来又出现了更迷你的上网本、平板计算机和掌上设备，比如智能手机。计算机已变得小巧、廉价，足以在儿童玩具上实现复杂的功能，甚至在贺卡中嵌入音乐，而且由于它的更新换代速度太快，被淘汰的设备无需多想就可以直接丢弃。本已小巧玲 的计算机还会向着更小巧、更便宜的方向迈进，这种发展趋势还没有任何减缓的迹象。虽然有了摩尔定律这一强大利器，科学家并没有安于现状，不再绞尽脑汁寻找提升计算速度的新方法。事实上，计算机领域的创新远未止步。尽管所有计算机都具备冯·诺依曼当年在报告中提到的逻辑元件，但它们远非千篇一律。为了提升运算速度或效率，各种高明的优化设计方案层出不穷。举个例子，自从计算机问世以来，工程师就一直面临着两难的问题：要想扩大存储量，就必须牺牲速度。在存储量小的情况下，速度可以很快，但存储量一旦扩大，速度往往就会受到拖累。我们在日常生活中也经历过类似的事情——假如你有一张简短的历史购物单，要想在上面寻找某样东西，是一件轻而易举的事情，不需要花什么时间；但是，如果你写了二十年的日记，想在这些日记当中寻找某一天购买过的某样商品，那么寻找起来就会困难很多，花的时间也会长很多。因此，回到计算机的问题上，要想兼顾速度和存储量，可以结合采用多种不同类型的存储器。如今的计算机处理器通常有如下配置：少量超快内部存储器（称为寄存器）；一个内部高速缓冲存储器（cache，简称高速缓存）（或许还会加装一个容量稍大、但速度稍慢的高速缓存）；一个比高速缓存更慢，但却更大的外部存储器；一个比外部存储器还慢，但却大很多的硬盘；此外或许还会加装一个比硬盘还慢，但却更大的备份存储器（磁带或硬盘）。只要在时机把握得当的情况下，将数据和指令从慢速存储器转移到快速存储器，计算机就能迅速调取信息，从而运行得更快。（这就好比你在写日记的时候，将重要的信息提取出来，写在一张纸上，这样日后查找起来就会更方便。）现代计算机处理器还有一种典型的优化设计方案，称为流水线（pipelining，又称管线）。其具体执行过程非常类似于工厂中的流水线。下面我给大家具体解释一下。工厂制造一辆车可能需要一整天，但是几乎每时每刻都有新车出厂。这是因为采用了流水线操作，生产汽车的流程被分为许多道工序，所有工序并行操作，不同的车辆同时进入不 同的工序。比方说，生产汽车的部分工序依次包括：焊接门框，安装车门，安装电动车窗。第一辆车进入焊接工序的同时，第二辆车进入装门工序（比第一辆车早一道工序），第三辆车进入装窗工序（比第二辆车早一道工序）。接着，所有汽车通过运输带自动进入下一道工序：第一辆车进入装门工序，第二辆车进入装窗工序，同时，另有一辆车接替第一辆车，进入焊接工序。计算机处理器的流水线技术也是一样的道理：将一条或一组指令的执行过程拆分为多个步骤，然后通过硬件处理单元 尽可能多地并行执行这些步骤。处理器的流水线段数越多，在理论上可以并行执行的指令数也就越多。除了流水线作业以外，还有其他方法可以让计算机并行执行指令，比如采用向量处理器。向量处理器不仅可以执行向量计算（一次直接操作一维数组，而不仅仅是一个数据），还可以并行运行多个处理器。 在当今时代，就连个人计算机的处理器中，也包含人类有史以来最精巧繁复的设计作品。它们已经复杂到无以复加，以至于没有其他计算机的辅助，就不可能完成设计过程。无论是安排硅芯片上晶体管的布局架构，还是设计处理器的集成电路，这类低端的设计工作现在已经基本上没有人在做了。未来计算机的细节设计已经交给当今时代的计算机来承担。 并行化是计算机的未来计算机技术的进步看似永无止境，而且，摩尔定律可能会让人想当然地以为，处理器势必会一直朝着更小巧、更便宜、更快捷的方向发展下去。但是，任何事物都不可能永远保持飞速发展的状态。事实上，我们在前进的道路上已经遇到了一个障碍。计算机体系结构教授戴维·帕特森道出了其中的缘由：“过去十年到十五年的时间里，我们为了提升计算机的性能，不断地增加晶体管的数量。每一次增加晶体管的数量，都会使硅芯片的功耗和散热压力更大。每块芯片约100瓦的功耗已经是其散热能力的极限。我们大概在2003年达到了这个水平。要想继续利用摩尔定律提升计算机的性能，唯一的出路就是制造并行计算机。这就意味着我们必须改变编程模型， 这是六十年的计算发展史上最重大的变革。”也就是说，问题并不在于摩尔定律。因为在未来的许多年里，硅芯片上的晶体管数目似乎还会越来越多。真正的问题在于，一个体积较大、而且精密复杂的处理器会在运转的过程中发热。笔记本发烫到致人三度烧伤、处理器发烫到融化电路板，这种夸张的事情没有人愿意看到。唯一的解决办法是，制造更小、更简单的处理器，使单个处理器的功耗减小，同时在单个芯片上集成多个处理器。计算机处理器的设计理 念已然开始发生变迁。因此，现在市面上的计算机的时钟频率（clock speed）（用于衡量计算机解读新指令的速度）可能并没有快多少，但是处理器中的核数却增加了不少。不过这里面有一个问题：既然有了并行或多核处理器，就理应配备能够高效利用其性能的软件，但是编写这样的软件对于程序员来说，是一件极其困难的事情。如今，硬件条件已经齐备，但是软件设施明显跟不上前进的步伐，无法充分发挥计算机的全部运算能力。帕特森同意这一观点，他在最近发表的一篇文章中写道：“处理器的并行化和微型化是计算发展史上的一个里程碑。” 有许多计算机科学家试图尝试帕特森的方法，但是到目前为止，问题尚未解决，我们还不知道怎样编写并行软件，才能使之与新的计算机体系结构相适应。怎样才能写出并行文字处理器或并行电子邮件程序？这个问题着实令人头疼。不过，值得庆幸的是，有一些应用程序在本质上讲就已经是并行程序了。其中最明显的例子，或许莫过于我们在每一台现代计算机上都会看到的、神奇的计算机图形。计算机图形往往由成千上万个微小的多边形拼接而成，多边形的表面覆盖着照片质量的图像。打个比方，假如你想制作某件物品的三维模型，可以先用铁丝网将其形状构建出来，然后在表面覆盖图像，用以表现物品表面的图案。计算机图形也是一样的道理。无论是展示动画效果（比如游戏角色的动作、行驶在车道上的汽车），还是纯粹显示窗口和图标，计算机都在同时改变成千上万个多边形和图像的位置，而且每个多边形和图像的位置改变方式都非常相似。由此可见，计算机不费吹灰之力，就可以并行处理这些计算过程，提升运转速度。事实上，时至今日，图形的并行处理已经变得轻而易举，以至于大多数最先进的多核计算机结构都是图形处理单元（graphics processing units，简称GPU）。这些处理器已经有数百个内核，所有的内核都并行计算。因此，大多数游戏机、个人计算机、乃至小型便携式计算机都采用了并行GPU，以使图形流畅逼真。正因为GPU运算如此之快，内核如此之多，它已成为许多超级计算机的重要部件。处理器的并行化趋势并不仅仅表现在单个芯片上。云计算是最近出现的一个新概念。它提供了一个动态虚拟的架构，这个架构或许会改变我们对计算机的认识。有了它，计算机用户就可以购买处理时间，使用异地多台计算机的软件和存储器，而不需要知道提供服务的计算机位于何处、其部件究竟如何运转。从概念上讲，云计算将计算机视为一种资源——这跟水电的性质是一样的，我们在日常生活中都会用水用电，但却不需要知道自来水厂和发电站在哪里。云计算可以让用户使用最新软件，执行高强度计算，享受虚拟主机服务，而不需要参与异地物理主机的升级和维护。在线购书网站亚马逊就是云计算领域的创新先驱。该公司意识到，其庞大的数据中心通常只有10％的容量得到了有效利用，因此，在2006年，该公司开始推出亚马逊网络服务（Amazon Web Services），出售数据中心的闲置容量。其他公司可以按需购买亚马逊提供的任何计算服务、软件和存储空间，而不需要维护或升级任何计算机。这一做法已变得越来越受欢迎，很多公司将来或许会从“云端”购买 企业所需的一切计算服务，而不是大动干戈地建立和维护自己的内部计算机系统。另一方面，用户或许也可以通过为数众多的云端计算机执行并行处理，而不需要担心任务怎样拆分——只要云端软件足够智能，可以代劳就好。处理器的并行化趋势还体现在汽车上，这里的并行处理比较容易实现。一台现代汽车上可能会搭载一百多个微处理器，它们协同工作，共同确保发动机和传动装置的平稳运转，同时控制仪表板、车门锁、倒车雷达、车载收音机、GPS、车灯、后视镜、座椅调节器……事实上，大多数汽车都有自己的计算机网络，使车内不同的计算机能够高效配合。 在这一方面，读者朋友们或许已经有了亲身体验。当你踩下油门，发动机猛然加速时，车载收音机的音量也会自动变大。有些汽车甚至更加智能，可以将安全气囊加速计、停车灯、GPS导航系统、手机和车门锁进行互联，万一出了什么严重的事故，车子就会呼叫应急号码，将你的GPS坐标发送出去，同时解锁车门，打开停车灯。 超越冯·诺依曼不过，在有些人看来，如此惊人的技术进步依然远远不够。曼切斯特大学教授史蒂夫·弗伯（Steve Furber）在职业生涯的开始，曾为艾康（Acorn）计算机公司设计ARM 32位微处理器。这个设计在世界各地受到了热捧，如今，ARM内核的出货量已超过200亿个，比英特尔芯片的销量还多（ARM处理器本身也更昂贵）。多年来，全世界90％以上的手机都至少搭载了一个ARM内核。不过，弗伯虽然是正统的计算机设计师出身，但在1998年却决定改变方向。他意识到，生物大脑似乎比计算机处理器的计算和存储部件要优越许多。“最后，我一咬牙，就转方向了，”弗伯表示，“管他呢，反正我感兴趣的是神经网络。”如今，有越来越多的计算机设计师开始研究仿生计算机，弗伯就是其中的一员。他有一项雄心勃勃的设计，称为SpiNNaker。SpiNNaker是一个通用脉冲神经网络结构，其中包含成百上千个并行运转ARM微处理器。弗伯并不是唯一一个具备前沿思想的计算机科学家。如今，各种类型的仿生处理器正在紧锣密鼓的研制当中，它们的性能有的类似于大脑神经元，有的类似于免疫细胞，有的类似于细胞中的基因。有些研究人员甚至在尝试用新的材料代替硅，来制作处理信息的芯片。现在，还有诸多问题等着科学家来解答：我们能否在DNA链中存储信息，让它们跟基因一起重组？我们能否对细菌进行基因改造，从而发明新的计算机？我们能否发明量子计算机，让它根据匪夷所思的物理学量子效应来执行计算？约克大学（University of York）教授安迪·泰瑞尔是一名计算机工程师，专攻仿生计算机。他认为，在未来的一段时间里，计算机体系结构依然会采用经典的冯·诺依曼设计。“但是，你可以想象，有‘一小撮’计算机工程师已经在设计新的体系结构了（希望他们的设计不仅新奇，而且令人振奋）。研制过程中或许采取了新的材料（或材料组合），比如 分子器件、忆阻器（memresister）、生物电材料、各种化学结构（液晶已经被人试过了）。或许还有些新的材料我们根本就不知道。”泰瑞尔认为，自然界中一定隐藏着某些秘诀，能够启发我们改善计算机的性能。毕竟，自然界中存在许多复杂而又高度精巧的事物。“怎样才能在保持原有优势的基础上，将材料换成新的呢？这是一个难关。采用生物材料的系统似乎能搭载更多（也更复杂）的部件，其数量（和复杂度）可能会超乎人的想象。因此，我们面临的一大挑战或许是：怎样才能制造这样的系统？应该采用什么材料？怎样才能发挥它的性能？”]]></content>
      <categories>
        <category>计算机</category>
        <category>历史</category>
        <category>先驱</category>
      </categories>
      <tags>
        <tag>计算机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机先驱——约翰·冯·诺依曼]]></title>
    <url>%2F2019%2F05%2F18%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%85%88%E9%A9%B12%2F</url>
    <content type="text"><![CDATA[John von Neumann，1903年12月28日—1957年2月8日1921年，冯·诺依曼在布达佩斯大学注册为数学方面的学生。与此同时，冯·诺依曼进入柏林大学（1921年），1923年又进入瑞士苏黎世联邦工业大学学习化学。1926年他在苏黎世联邦工业大学获得化学方面的大学毕业学位，通过在每学期期末回到布达佩斯大学通过课程考试，他也获得了布达佩斯大学数学博士学位。先后执教于柏林大学和汉堡大学，1930年前往美国，后入美国籍。历任普林斯顿大学、普林斯顿高级研究所教授，美国原子能委员会会员。美国全国科学院院士。20世纪最重要的数学家之一，在现代计算机、博弈论、核武器和生化武器等领域内的科学全才之一，被后人称为“计算机之父”和“博弈论之父”。 制造大脑事有凑巧，1943年，当图灵回到英国后，一位名叫约翰·冯·诺依曼的数学家也从美国漂洋过海，来到了英国。冯·诺依曼当时是普林斯顿高等研究院最年轻的成员（他是最先被研究院聘为教授的五人之一，同时入院的还有爱因斯坦），他人脉很广，也认识图灵，因为在1938年，图灵博士毕业，成为研究助理后，他曾要求图灵留在普林斯顿。但图灵拒绝了这个工作机会，回到了英国剑桥。冯·诺依曼也见过香农。那是在1940年，香农还在高级研究所担任研究员。 20世纪30年代，人们越来越热衷于发明自动计算机。几个世纪以来，机械式计算机除了齿轮和螺丝钉以外，什么部件也没有。冯·诺依曼对这些设备深为着迷，他尤其痴迷于19世纪20年代查尔斯·巴贝奇（Charles Babbage）发明的一台机械式计算机，它与如今的现代计算机在设计上有许多共通之处。随着继电器这种电控开关的问世，利用电动设备进行计算已经成为了可能。不少工程师发明了早期计算机。其中最早的机型之一采用了柏林工程师康拉德·楚泽（Konrad Zuse）发明的继电器。这台巨型机器称为Z3，由于缺少条件分支，它的功能受到了一定的局限。也就是说，它不能根据不同的计算结果执行不同的操作，必须在程序中不停地执行相同的计算。它的运行速度也很慢，因为继电器采用了移动部件接通和断开电流。运行速度更快的计算机都采用了没有移动部件的电子管（真空管）。20世纪30年代，美国爱荷华州立大学（Iowa State University）的 约翰·阿塔纳索夫（John Atanasoff）花了几年的时间发明了一台电子计算机，用来解线性代数方程。这台计算机由他和学生克利福德·贝里 （Clifford Berry）共同制造，称为“阿塔纳索夫-克利福德贝里计算机”（Atanasoff-Berry Computer，简称ABC）。它体型较小，性能不甚可靠，内含大约300个电子管。与此同时，英国工程师托马斯·弗劳尔斯（Thomas Flowers）于1934年在继电器的基础上发明了独创的开关系统，并于30年代末投入使用。开关系统采用了3000多个电子管，用于英国电话交换机和简单的数据处理。 1943年，图灵回国后，鼓动马克斯·纽曼接近弗劳尔斯，请他来布莱切利公园，帮忙改进他们在继电器的基础上设计出来的破译机。1943年底，弗劳尔斯发明了巨像I（Colossus I）——一台内含1600个电子管的电子计算机。巨像I后来一共制造了十台，每一台都包含2400个电子管，但它们不是通用机器，必须插入不同的电缆重新编程。 这时候，冯·诺依曼已结束英国之行，回到了美国。由于他名气很大，美国国防部邀请他参与曼哈顿计划（Manhattan Project，美国政府制造第一颗原子弹的计划），负责设计原子弹的爆炸外护层（explosive outer jacket）。要完成这项工作，必须进行大量复杂的数学计算。冯·诺依曼意识到，他需要一台全新的计算机，其性能必须远远超越当前所有的计算机。一次偶然的相遇注定将改变一切。1944年夏，冯·诺依曼在马里兰州的火车站遇到了曾任数学教授的赫尔曼·戈德斯坦中尉（Herman Goldstine）。戈德斯坦当时是宾夕法尼亚大学（University of Pennsylvania）摩尔电气工程学院（Moore School of Electrical Engineering）的军方联络人。在摩尔电气工程学院，一台令人惊叹的全新计算机正在紧锣密鼓的研制当中。时至今日，戈德斯坦依然对当年与冯·诺依曼交谈的情形记忆犹新：“话题很快就转移到了我的工作上。我说我正在关注一项开发任务，任务的目的是制造一台每秒钟可以运算333个乘法的电子计算机。这句话才说完，整个谈话的气氛一下子就变了，原本我们还是比较轻松、随意地聊聊天、打打趣，突然变得像是在 做数学博士学位的口头答辩。”冯·诺依曼马上做出安排，拜访了项目的设计师：约翰·莫奇利（John Mauchly）和约翰·埃克特（John Presper Eckert）。他们设计的是世界上第一台通用计算机：电子数字积分计算机（The Electronic Numerical Integrator and Computer）——简称“埃尼阿克”（ENIAC）。这个庞然大物尺寸为8×3×100英寸（约合2.4米×0.9米×30米），重约三十吨，包含17,000多个电子管和1500多个继电器，运算速度比以往的任何计算机都快。冯·诺依曼很快就开始定期造访摩尔电气工程学院，并受邀参与了埃尼阿克的设计项目。埃尼阿克的研制工作进展缓慢，因此，在研制工作完成之前，军方又布置了一个任务，要求再建造一台更快的计算机。埃尼阿克的后继者称为电子离散变量自动计算机（Electronic Discrete Variable Automatic Computer）——简称“埃德瓦克”（EDVAC），约翰尼·冯·诺依曼成为了设计团队的一员。埃德瓦克的设计持续了好几个月，涉及到很多新思想和新技术。挑战主要来自两大方面，一是保存数据的存储器，需要解决的问题是，数据能否存储在某种形式的雷达甚至电视显像管里？二是指令系统，这里需要考虑的是，有哪些功能是计算机应该具备的？1945年6月，冯·诺依曼撰写了一篇文章，对摩尔学院项目团队的设计理念进行了总结。这只是一份初稿，署名作者只有他一个人，但是文章的终稿版从未出炉。戈德斯坦鼓励将初稿的内容公诸于世，因此，埃德瓦克的设计思想很快在全世界研究人员和工程师中传播开来。文章标题为“关于埃德瓦克的报告初稿”（First Draft of a Report on the EDVAC）。这是第一份系统描述计算机制造方法的公开出版物，具有划时代的革新意义。 数字大脑的解剖尽管“关于埃德瓦克的报告初稿”描述的是工程学和数学领域的研究成果，但它的遣词造句通俗而又浅显，几乎人人都能看懂。报告是冯·诺依曼1945年在火车上手写的，以下是部分摘录：我们只要分析一下这台构想中的设备应该具备哪些功能，就不难看出，该设备的核心部件应该分为几个大类。第一：由于该设备本质上是一台计算机，最起码要能够迅速地执行基本的算术运算，其中包括加法、乘法和除法。由此可见，该设备应该包含专门执行此类运算的部件……也就是说，中央算术器（central arithmetic part）或许是一个必不可缺的部件，它也构成了该设备的第一大部件，我们将其简称为CA。第二：该设备需要对不同的运算操作进行适当的排序，这一过程称 为逻辑控制。中央控制器（central control organ）可以对设备进行高效的逻辑控制……它构成了该设备的第二大部件，我们将其简称为CC。第三：任何设备要想进行长时间的复杂操作（尤其是计算操作），都需要容量相当可观的存储器（memory）……它构成了该设备的第三大部件，我们将其简称为M。……CA、CC、M这三大部件就相当于人体神经系统中的联络神经元。至于哪些部件对应于人的感觉神经元（又称传入神经元）和运动神经元（又称传出神经元），是接下来要讨论的问题。这些部件是该设备的输入装置和输出装置。值得注意的是，这个设计方案包含五大逻辑元件：第一是中央算术器，负责执行所有的运算操作；第二是中央控制器，它决定机器的下一步动作；第三是存储器，用于保存程序及程序输出的结果；第四是输入设备，比如键盘；第五是输出设备，比如打印机。 算术逻辑单元（arithmetic and logic unit，简称ALU）和寄存器（register），用冯·诺依曼的说法就是中央算术器。这个电子装置接收外界输入的电信号，并据此输出各种各样的电信号（即运算结果）。ALU的运作模式固定不变，受到布尔逻辑电路的支配。它设有临时存储区域，称为寄存器，寄存器的运作方式和存储器一样（但是访问速度要快很多），用于保存ALU和存储器输出的结果。存储器。信息以二进制编码1和0的形式存储下来，二进制编码1和0则分别由“高”、“低”两种电压转换而来。在现代计算机中，这种类型的存储器通常被称为随机存取存储器（random access memory，简称RAM）。RAM这个缩写虽然看似神秘，但它的作用其实很简单。用通俗的话来讲，它可以帮助我们直接调取任何零散的信息，不需要像磁带或纸带那样，在庞杂的信息当中大海捞针。冯·诺依曼有很多设计理念（比如采用中央存储器，以保存数据和指令）明显受到了图灵机的影响。冯·诺依曼的同事、洛斯阿拉莫斯国家实验室（Los Alamos National Laboratory）的物理学家斯坦利·弗兰克尔（Stanley Frankel）深知图灵的工作在当时的重要性。“我知道，大约在1943-1944年这段时间，冯·诺依曼非常重视图灵在1936年写的论文……他让我看看这篇论文，于是我好好研究了一下。”冯·诺依曼也很重视香农的布尔逻辑，深知这一理论的重要价值。 他在报告中写道：这台机器的一大重要方面在于，它依据的不是算术原理，而是逻辑原理。非真即假的逻辑系统从本质上讲就是一个二进制的系统。 猝不及防的结束直到1951年，埃德瓦克才被制造出来。尽管它比埃尼阿克要小，但还是安装了6000个电子管（真空管），功率高达56千瓦，需要工业空调才能保持降温。没有人赶在战争结束之前成功造出可以使用的通用计算机。事实上，冯·诺依曼和最初的设计师莫奇利和埃克特之间发生了些许不快，因为莫奇利和埃克特对他们的理念不受重视而忿忿不平，他们想将自己的设计方案申请专利，投入商业使用。冯·诺依曼放弃了埃德瓦克，转而决定在高等研究院制造一台截然不同的计算机。受到此项工作的激发，很多其他计算机被相继设计出来。约翰·冯·诺依曼在高等研 究院开展的电子计算机项目（electronic computer project，简称ECP）比此前所有的项目都更加完善，整个系统运转速度极快，可以在不出现任何错误的情况下，长时间运行数据输入量和输出量都相当可观的程序（比如氢弹试验数据计算、天气预报、人工生命模拟）。ECP的成果和设计方案得到了广泛共享。IBM当年之所以能推出商业计算机（700系列），就是因为在合作参与ECP的过程中学到了关键技术。我们现在生活在冯·诺依曼构建的世界。现代的计算机系统虽然日新月异，但万变不离其宗，大框架都是冯·诺依曼1952年在普林斯顿构建起来的。 冯·诺依曼写下关于埃德瓦克的报告后，才过两年，贝尔实验室就发明了晶体管。从理论层面讲，晶体管能做到的事情和电子管完全相同，但从实际角度讲，晶体管具有无可比拟的优越性，不仅速度快了好几倍，而且耗电量和体积也小了很多。1953年，世界上第一台晶体管计算机由曼切斯特大学研究生迪克· 格里姆斯戴尔（Dick Grimsdale）制造完成。一石激起千层浪，此后15年里，世界各地涌现了一百多台晶体管计算机。但是，第一台晶体管计算机才问世五年，电子工程师就已经面临一个严峻的问题——“数字的暴政”（tyranny of numbers）：为了提高运算能力，就必须安装更多的晶体管，但是一旦安装更多的晶体管，制造和维护成本就会增大，因为每个部件都需要手工焊接到电路板上。这个问题并没有让电子工程师困扰多久。1958年，德州仪器（Texas Instruments）公司的新职员杰克·基尔比（Jack Kilby）产生了一个革命性的想法：为什么不同时制造所有的元件呢？只要蚀刻锗晶片，就可以将电路中所有的元件都集成到一小块芯片上。几个月后，到了1959年，另一位研究人员——罗伯特·诺伊斯（Robert Noyce）也独自想出了同样的主意，只不过他使用的不是锗晶片，而是硅晶片。集成电路（integrated circuit，简称IC），也就是硅芯片就此诞生。1957年，约翰·冯·诺依曼去世，时值图灵去世三年后，硅芯片问世两年前。]]></content>
      <categories>
        <category>计算机</category>
        <category>历史</category>
        <category>先驱</category>
      </categories>
      <tags>
        <tag>计算机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机先驱——克劳德·艾尔伍德·香农]]></title>
    <url>%2F2019%2F05%2F18%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%85%88%E9%A9%B11%2F</url>
    <content type="text"><![CDATA[Claude Elwood Shannon，1916年4月30日—2001年2月24日1936年获得密歇根大学学士学位。1940年在麻省理工学院获得硕士和博士学位，1941年进入贝尔实验室工作。美国数学家、信息论的创始人。 时值1943年初，图灵正在访问他赴美之行的最后一站——贝尔实验室。他之所以来到这里，就是为了协助大西洋通信的语音加密工作（说白了就是给大西洋两岸传输的通话内容加密，这样敌人就无法监听）。不过，这次访问很快就因为另一个原因而变得收获颇丰。每天下午茶时间，图灵都会和实验室里的一位研究人员在食堂里长谈，这位研究人员名叫克劳德·香农（Claude Shannon）。两个人似乎都对计算机的问题非常热衷。图灵看问题主要从数学的视角出发，而香农的视角则完全不同。 逻辑思维香农进入贝尔电话实验室实习，学习操作自动电话交换机。实习期间，他意识到了一件重要的事情。年轻的香农发现，有两个看似截然不同的事物其实具有共同的本质。克劳德·香农回到麻省理工学院，发展他的理论新思想。那时候，他还没有和图灵见过面，图灵当时还是邱奇的学生，正在250英里（约合402公里）以外的普林斯顿大学攻读博士。两人共进午餐是六年以后的事情。 香农已经知道，数学上有一种逻辑代数系统，叫做布尔逻辑，它得名于英国数学家乔治·布尔（George Boole）。在布尔逻辑中，任何逻辑 表达式的计算结果都不是数值，而是“真”、“假”这两种真值。你只需要使用逻辑运算符“与”、“或”、“非”，就可以表达任何你想表达的逻辑语句。这个逻辑语句可以是一个英文句子，比如“在下雨且阴天或无 风的时候，我会带伞。”布尔逻辑可以让我们描述和操纵逻辑表达式，这就和我们通过数学函数来操纵数字是一样的道理（正如上一章所讲的那样，所有的数学问题都可以归结为逻辑问题）。香农取得的突破在于，他注意到，逻辑和开关电路具有共同的本质。他借鉴了布尔逻辑，并运用它来定义带有机电式继电器（电气开关）的电路。香农的理论表明，整个电路都可以用布尔逻辑表述出来，只要巧妙地运用逻辑表达式，就可以简化和改善电路设计。 也就是在这个时候，人们开始着手制造世界上第一台电子计算机。由此可见，只要能够运用逻辑数学表达式设计出简洁而高效的电路，就能创造巨大的实用价值。由于所有的数学问题都可以归结为逻辑问题，而逻辑问题又可以通过电气开关表现出来，香农的理论表明，人们可以设计专门的电机，用来计算任何可计算的数学函数。 香农决定将他的思想写成研究报告发表出来，研究报告的题目是“继电器和开关电路的符号分析”（A Symbolic Analysis of Relay and Switching Circuits）。这项成果给计算机科学领域带来了重大突破。香农很快以此为基础，完成了他在麻省理工学院的硕士论文。这篇论文受到了广泛的赞誉，人们说它“或许是本世纪最重要、也最有名的硕士论文”。24岁时，香农写了一篇博士论文，从代数学的角度描述遗传学和进化论。毕业后，他作为国家研究员（National Research Fellow），在声名远播的普林斯顿高等研究院（Institute for Advanced Study，简称IAS）工作了一年。在那里，他接触到了一些世界上最顶尖的人才，其中包括赫尔曼·外尔（Hermann Weyl）、阿尔伯特·爱因斯坦、库尔特·哥德尔和约翰·冯·诺依曼（John von Neumann）。1941年，香农进入贝尔电话实验室，继续扩充自己的理论思想。两年后，在贝尔实验室的食堂，图灵在与香农交谈的过程中大为振奋——他的声音不由自主地越来越大，引起周围的人纷纷侧目。香农的话让他看到了希望曙光——图灵机或许真的可以变成现实！临走前，图灵买了一本电路入门书，把它带到回国的船上，在危险四伏的海上航程中如饥似渴地阅读起来。 其他贡献香农理论的重要特征是熵（entropy）的概念，他证明熵与信息内容的不确定程度有等价关系。熵曾经是波尔兹曼在热力学第二定律引入的概念，我们可以把它理解为分子运动的混乱度。信息熵也有类似意义，例如在中文信息处理时，汉字的静态平均信息熵比较大，中文是9.65比特，英文是4.03比特。这表明中文的复杂程度高于英文，反映了中文词义丰富、行文简练，但处理难度也大。信息熵大，意味着不确定性也大。 众所周知，质量、能量和信息量是三个非常重要的量。 人们很早就知道用秤或者天平计量物质的质量，而热量和功的关系则是到了19世纪中叶，随着热功当量的明确和能量守恒定律的建立才逐渐清楚。能量一词就是它们的总称，而能量的计量则通过“卡、焦耳”等新单位的出现而得到解决。然而，关于文字、数字、图画、声音的知识已有几千年历史了。但是它们的总称是什么，它们如何统一地计量，直到19世纪末还没有被正确地提出来，更谈不上如何去解决了。20世纪初期，随着电报、电话、照片、电视、无线电、雷达等的发展，如何计量信号中信息量的问题被隐约地提上日程。 1928年哈特利（R.V. H. Harley）考虑到从D个彼此不同的符号中取出N个符号并且组成一个“词”的问题。如果各个符号出现的概率相同，而且是完全随机选取的，就可以得到D^N个不同的词。从这些词里取了特定的一个就对应一个信息量I。哈特利建议用NlogD这个量表示信息量，即I=NlogD。这里的log表示以10为底的对数。后来，1949年控制论的创始人维纳也研究了度量信息的问题，还把它引向热力学第二定律。但是就信息传输给出基本数学模型的核心人物还是香农。1948年香农长达数十页的论文“通信的数学理论”成了信息论正式诞生的里程碑。在他的通信数学模型中，清楚地提出信息的度量问题，他把哈特利的公式扩大到概率Pi不同的情况，得到了著名的计算信息熵H的公式： H=-&sum;PilogPi 如果计算中的对数log是以2为底的，那么计算出来的信息熵就以比特（bit）为单位。在计算机和通信中广泛使用的字节（Byte）、KB、MB、GB等词都是从比特演化而来。“比特”的出现标志着人类知道了如何计量信息量。香农的信息论为明确什么是信息量概念作出决定性的贡献。香农在进行信息的定量计算的时候，明确地把信息量定义为随机不定性程度的减少。这就表明了他对信息的理解：信息是用来减少随机不定性的东西。或香农逆定义：信息是确定性的增加。]]></content>
      <categories>
        <category>计算机</category>
        <category>历史</category>
        <category>先驱</category>
      </categories>
      <tags>
        <tag>计算机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机先驱——艾伦·麦席森·图灵]]></title>
    <url>%2F2019%2F05%2F17%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%85%88%E9%A9%B1%2F</url>
    <content type="text"><![CDATA[Alan Mathison Turing，1912年6月23日－1954年6月7日1931年图灵进入剑桥大学国王学院，毕业后到美国普林斯顿大学攻读博士学位英国数学家、逻辑学家，被称为计算机科学之父，人工智能之父。 谜题关于数学漏洞的问题，我给大家举个例子。剑桥有位数学家——伯特兰·罗素（Bertrand Russell）发现了一个数学漏洞。此前罗素的工作已经取得了巨大的成功——他证明了所有数学问题都可以还原为逻辑问题，也就是说，所有数学发现都可以用逻辑表达式重新写出来。 这项工作是伟大的，因为它有助于我们了解数学赖以建立的所有基本真理。但是后来，罗素发现了一个问题。他发现了一个悖论——也就是看起来既正确又不正确的论断。数学家经常寻找悖论，因为你如果觉得某件事情既正确又不正确，那么你的想法肯定有漏洞。所以，通过这种方法可以将很多想法证伪。相比之下，罗素悖论的性质要严重许多，因为它似乎预示着，整个数学体系是有漏洞的。罗素悖论给我们出的难题是： 假设有一个集合A，它的所有子集都具有一个共同的性质P——它们不包含自身。问题是：集合A是否包含自身？ 首先，若A包含自身，则A是A的子集，那么A具有性质P，由性质P知A不包含A；其次，若A不包含A，也就是说A具有性质P，而A是由所有具有性质P的集合组成的，所以A包含A。就像理发师悖论一样，唯一说得通的解法是，集合A既包含自身，又不包含自身。这在逻辑上是不可能的。罗素悖论的提出之所以让数学家如临大敌，是因为它预示着数学的理论基础存在漏洞。几个世纪以来，数学思想和证明无不建立在一系列的基本真理之上。连加法和减法的运算法则都是运用集合和逻辑学加以证明的。但是罗素悖论表明，任何数学证明都不再可信。 罗素悖论还只是这一切的开端。1931年，在图灵攻读高级课程的四年前，有位数学家一劳永逸地证明了数学体系必定是不完备的。他的名 字叫库尔特·哥德尔（Kurt Gödel）。哥德尔的第一条定理可以通过类似的方式表述出来：G＝“本命题不可以由理论T证明。”如果命题G事实上可以由理论T证明，则理论T中存在一个自相矛盾的定理G，既然有自相矛盾的地方，那么理论T就是不完备的。也就是说，T要是完备的理论，就不可以证明G，但是这样一来，T就有证明不了的命题，也称不上是完备的理论了。于是，G所指的内容就是真的：G既无法得到证明，但又是真命题。由此可见，有些事物不管能否得到证明，都可以为真。 图灵在学校也学到了一个与此相关的前沿思想。这是由德国数学家大卫·希尔伯特（DavidHilbert）在1928年提出的挑战。这项挑战称为“判定问题”（Entscheidungs problem）。希尔伯特想知道的是，一个命题的真假能否自动判定。他的问题是，对于给定的数学语言，有没有什么方法或者程序可以让机器判定某件事情的真假，并将结果显示出来。虽然这听起来颇为实用，但真正的挑战在于：这种自动化的方法或机器是否有可能存在？自动判定简单的句子似乎并不是遥不可及的事情，但如果是用复杂的数学语言写成的高难度句子，是否仍有可能加以判定？这种万能的真理说明者是否真有可能存在？ 永不停机的图灵机当时没有任何机器能做到这一点，于是图灵构想了一台能做到这一点的机器。他想象的是一台理论计算机。一台能从纸带上读取信息的机器。根据即时读取的指令，机器可以将纸带左移、右移，或在纸带上读取信息、输出结果。虽然这台奇怪的新机器终究只是纸上谈兵的假想机，但是这已经足够了，因为图灵只是想从理论上解决希尔伯特提出的问题而已。或许颇具讽刺意味的是，图灵虽然提出了关于通用计算机的思想，但却并不急着证明他的机器可以解决判定问题。相反，他想证明判定问题不可能得到解决，进而说明有些问题在数学上根本不可判定。为了做到这一点，图灵首先假想他的小计算机正在根据纸带上的信号执行一个运算，接着他提出了一个问题：有没有什么方法可以判断这 台机器究竟是会陷入死循环，不停地计算下去；还是会停止计算，给出结果呢？ 图灵认为，要想判断他的机器会不会停机，那就需要再构造一台图灵机，以对第一台机器进行检测，因为他知道，他假想的机器在理论上 可以进行任何数学运算。于是他假想出第二台图灵机，如果检测到第一台图灵机永不停机，那么第二台机器就会停机，然后输出“不停机”；如 果检测到第一台图灵机停了机，那么第二台机器就会一直运转下去。现在，脑筋急转弯的地方来了。假如第二台机器反观自身，判断自己会不会停止计算，那会发生什么情况？图灵对此进行了设想，他突然发现了一个悖论：如果机器检测到自己会永不停机，那么它就会停机，然后输出“不停机”；如果机器检测到自己停了机，那么它就会一直运转下去。这在逻辑上是不可能的，由此证明，有些图灵机是不可判定的——我们永远也无法判断它们会不会停机。 顺便说一下，图灵当时设计这个图灵机，完全只是为了辅助他证明这个问题而已，这个机器是假想的，不存在的就像画一条辅助线。可是后来他又发现，虽然这个机器不能解决所有的问题，但确实能够解决很多问题，而且真的是可以造出来的。于是…… 图灵就成为了“计算机科学之父”。 P是否等于NP？P和NP指的是两种类型的问题，它们的计算复杂度各不相同。P类问题可以通过多项式时间算法解决。换句话说，凡是可以用O（n^x）算法解决的问题都是P类问题，不管这里的x是什么。排序问题就是典型的P类问题。就算是最好的排序算法，它的时间复杂度在最坏的情况下也是O（n^2），符合多项式关系，因此排序问题属于P类问题。对于NP类问题，我们可以在多项式时间内检验候选解是否正确，但是求解所需要的时间却会漫长许多——而且往往是指数时间。在已知量较小的情况下，所有这些问题乍看之下都很好解决，但是，一旦已知量的数量级增大，比如配送车穿行的城市增加到一百个、装箱的行李数量增加到五百个、硬币的数量限制增加到一百个，那么求解所需要的时间就会呈指数式增长。因此，P是否等于NP的问题实际上是在问：难度很大的NP类问题究竟能否用多项式算法求解？我们现在采用的算法是不是太愚蠢了，就像慢速排序那样？能不能找到像快速排序这种聪明的解法，让原本很难的问题一下子迎刃而解？ 显然，NP类问题很难解决，但早在1936年，图灵对如此艰涩的难题就已经有了自己的思考方法。思考NP类问题的方法之一，就是构造一台特殊的图灵机，称为非确定型图灵机（non-deterministic Turing Machine）。如果我们可以制造出这样的机器，就可以让它在多项式时间内运行NP类问题。之所以称之为非确定型，就是因为我们无法预测它的运作方式，但它总能找到最快的方法解决问题。试想你在干草堆里寻找一根针。你立马就能分辨出自己看到的是一棵干草还是一根针，但是从哪里寻找却是一个很大的问题。你有很大的选择空间，但问题是：“怎样做出选择才能让我找到解法？”非确定型图灵机的道理与之大同小异。它的问题是：“是否存在某种特定的指令，可以使我成功求解？”如果这样的指令存在，那么它就会惊呼“太好了！”然后遵照指令，在最快的时间内找到解法。如果这样的指令不存在，那么它就会唏嘘“太可惜了”，然后停止运转。至于这类聪明的图灵机是如何判断出解题方法的，这一点在某种程度上讲还是个迷。对此，人们设想了两种情况。第一，答案已经摆在那里了。这就好比你有一块魔镜，它无所不知，每次都会告诉你：这是最好的选择。第二，可以采用某种平行或并行操作，也就是说，这类非确定型图灵机所做的，其实就是同时运行所有可能的选择。 这些奇怪的思想是由图灵等业界先驱同时提出的，它们历经发展演进，为一个新的理论研究领域提供了肥沃的土壤，这个研究领域叫做可计算性理论（有时又称为递归论）。 总结可计算性理论以及图灵机图灵先知先觉，在电子计算机远未问世之前，他已经想到所谓“可计算性”的问题。物理学家阿基米得曾宣称:“给我足够长的杠杆和一个支点，我就能撬动地球。”类似的问题是，数学上的某些计算问题，是不是只要给数学家足够长的时间，就能够通过“有限次”的简单而机械的演算步骤而得到最终答案呢？这就是所谓“可计算性”问题，一个必须在理论上做出解释的数学难题。 “图灵机”是一个虚拟的“计算机”，完全忽略硬件状态，考虑的焦点是逻辑结构。图灵在他那篇著名的文章里，还进一步设计出被人们称为“通用图灵机”的模型，它可以模拟其他任何一台解决某个特定数学问题的“图灵机”的工作状态。他甚至还想象在带子上存储数据和程序。“通用图灵机”实际上就是现代通用计算机的最原始的模型。不过图灵在提出图灵机构想之后，又发现了新问题，有些问题图灵机是无法计算的。比如定义模糊的问题，如“人生有何意义”，或者缺乏数据的问题，“明天3D中奖号是多少”，其答案当然是无法计算出来的。但也有一些定义完美的计算问题，它们亦是不可解的，这类问题称为不可计算问题。不可计算的问题在践中几乎碰不到，事实上，很难找到这样的例子，既不可计算但又有人向计算的明确定义的问题。一个罕见的问题是所谓的停机问题。 图灵机的意义图灵提出图灵机的模型并不是为了给出计算机的设计，它的意义我认为有如下几点：1.它证明了通用计算理论，肯定了计算机实现的可能性，同时它给出了计算机应有的主要架构；2.图灵机模型引入了读写与算法与程序语言的概念，极大的突破了过去的计算机器的设计理念；3.图灵机模型理论是计算学科最核心的理论，因为计算机的极限计算能力就是通用图灵机的计算能力，很多问题可以转化到图灵机这个简单的模型来考虑。对图灵机给出如此高的评价并不是高估，因为从它的设计与运行中，我们可以看到其中蕴涵的很深邃的思想。通用图灵机等于向我们展示这样一个过程：程序和其输入可以先保存到存储带上，图灵机就按程序一步一步运行直到给出结果，结果也保存在存储带上。另外，我们可以隐约看到现代计算机主要构成（其实就是冯诺依曼理论的主要构成），存储器（相当于存储带），中央处理器（控制器及其状态，并且其字母表可以仅有0和1两个符号），IO系统（相当于存储带的预先输入）；]]></content>
      <categories>
        <category>计算机</category>
        <category>历史</category>
        <category>先驱</category>
      </categories>
      <tags>
        <tag>计算机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdowm空格缩进、多层嵌套]]></title>
    <url>%2F2019%2F05%2F17%2Fmarkdowm%E7%A9%BA%E6%A0%BC%E7%BC%A9%E8%BF%9B%2F</url>
    <content type="text"><![CDATA[空格缩进 一个空格表示：&amp;ensp;或&amp;#8194; 两个空格表示：&amp;emsp;或&amp;#8195; 不换行空格：&amp;nbsp;或&amp;#160; 多层嵌套效果： 第一层 第二层 &amp;alpha; &amp;acute; 代码： 12345&gt; 第一层&gt;&gt; 第二层&gt;&gt; &gt;&gt; &amp;alpha;&gt;&gt; &amp;acute;]]></content>
      <categories>
        <category>书写方法</category>
      </categories>
      <tags>
        <tag>markdowm书写方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F05%2F14%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
