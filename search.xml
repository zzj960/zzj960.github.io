<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[计算机历史——软件的发展]]></title>
    <url>%2F2019%2F05%2F19%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%86%E5%8F%B20%2F</url>
    <content type="text"><![CDATA[软件从未变得如此重要。当年赴摩尔学院听计算机讲座的先驱们万万没有想到，他们所学的知识竟然催生了一个新的行业，一个由计算机指令支撑起来的虚拟行业。软件分为多个层次，涉及到微代码、机器代码、汇编语言、高级语言的转换。数据库、软件开发过程，乃至整个企业结构都与之息息相关。计算机无所不在，它们的思想统领着整个世界。软件的重要性已变得无以复加，无怪乎世界上财力最雄厚的富豪当中，有好几个人是靠经营软件公司而积累了大笔的财富。 “优化软件就相当于优化一切。” 数据库随着编程语言的功能日渐强大，计算机的速度日益加快，容量日益扩大，可靠性日益增强。很快，计算机科学家就意识到，除了计算方程式的结果，计算机还可以在更广阔的领域大有可为。它们可以快速存储和处理大量的数据。如果只是单纯存储一系列数字，那倒不是什么难事，但是，如果存储的是病历记录或者财会记录，那么情况就会复杂许多。这就要求计算机必须能在短时间内迅速找到特定的信息条目——比如某一份病例中记述的病因，或者某一天产生的支付记录。怎样编排数据才能帮助我们轻松地找到所需信息呢？这些都不是什么新的问题——自从第一部词典问世以来，人们就面临着快速查找词条的问题。其解决办法，就是按照字母表的顺序编排词语。以某个单词为参照，词典中的其他词语中要么在它之前，要么在它之后。因此，我们在查找单词时，可以翻开词典的任何一页，然后根据上面的词语决定应该往前翻还是往后翻，直到将我们想查的单词查找出来。 第一代第一代数据库都是按照非常类似的原则编排的，它们于20世纪60年代问世，被称为导航式数据库管理系统（navigational database management system）。数据库第一次打开时，就会自动出现一个指针，指向第一条存储记录（好比翻开词典正文的第一页，就会看到第一个词条是以a开头的单词）。这些存储记录按照链表或网状结构编排，每一条记录当中都存有一个指针，指向相邻的记录。为了检索信息，计算机需要访问每一条记录，并通过其中的链接跳转到下一个记录，以此类推，直到找到用户所需的信息。如果用户想从一个庞大的数据库中检索出所有心脏病患者的病例，那么计算机就需要把每一条记录都访问一遍，才能将心脏病患者的病例筛选出来。这显然是一个非常缓慢而低效的信息检索方式，而且在那个年代，计算机和存储设备的运转速度都慢得可怜，要执行这样的检索是难以想象的。或许这种事情在今天的人看来有些匪夷所思，不过第一代数据库的确是不能用来查找信息。随着计算机和存储器的性能日渐提升，导航式数据库的局限性也愈发凸显。20世纪70年代，IBM的一名英国研究人员埃德加·弗兰克·科德（Edgar Frank “Ted” Codd）认为，数据库的模型亟待改进。科德与开发硬盘存储系统的IBM员工一道，设计了一个新的数据库模型，科德称之为关系模型。这种数据库结构比较智能化。数据的编排方式并不是像词典那样列出一长串条目，而是采用一系列数据库表，不同的数据库表通过关系键联系起来。为了便于大家理解关系数据库，我们用词典来打个比方。关系数据库就好比一系列分类词典，比如动词词典、名词词典、副词词典等等。如果你想查找某个单词——比如动词“bow”，那就只需要翻阅动词词典。如果你想找“bow”的名词词义，那就只需要翻阅名词词典。这比从头到尾地翻阅一本超厚的大词典要高效多了。关系数据库也是同样的道理，它采用关系键，将不同的记录联系起来。比方说，一个员工信息数据库可能会以员工编号作为关系键。知道了工号，你就可以在各个数据库表（好比各个分类词典）中分别查询员工的工资信息、家庭住址、计算机登录情况等等。每个数据库表中的值都可以作为关系键，用于在其他数据库表中查找相应的信息。也就是说，员工的职位描述也可作为关系键，用来查询员工是否具备参与机密工作的资格。 SEQUEL的出现20世纪70年代末出现了一种特殊的编程语言，用户可以通过它查询数据库中的复杂信息。这种语言脱胎于关系代数和微积分，全称为结构化英语查询语言（SEQUEL，即Structured English Query Language），后来又很快简称为结构化查询语言（SQL）。SQL支持查询、表达式、从句等多种编程元素。有了它，用户就可以在数据库中查询高度复杂的信息。数据库管理系统负责接收和翻译SQL表达式，并尽快返回结果（如果情况理想的话）。SQL中包含好几种语言，其中数据操纵语言（data manipulation language，简称DML）和数据定义语言（data definition language，简称DDL）能让用户运用简单易用的表达式在数据库中修改或添加数据。此后，数据库在原有的基础上继续改进，开始向面向对象的趋势发展，并进一步得到优化。索引的概念得到引进，经常查询的信息存储在高速的临时数据库中，临时数据库则与主数据库相连。正如图书目录一样，索引可以使用户查找所需信息的速度大幅加快。如今，数据库的设计特点表现为高度模块化，可访问性强。可扩展标记语言（Extensible Markup Language，简称XML）、超级文本预处理语言（Hypertext Preprocessor，简称PHP）等基于网页的语言可以使用SQL，连接在线数据库。（有了网页服务器，当你浏览的网页中包含这些高级语言写成的命令时，网页浏览器就会对它们进行翻译。）可以想见，未来数据库的分布将日趋广泛，可访问性日益增强，访问速度日益加快。 我们已经对数据库领域的巨大飞跃感同身受。就在几年前，家家户户的抽屉里还塞满了老照片，书架上堆满了书本、文件、录像带和CD，但是如今，我们查找、创建、购买的所有信息都是以数字形式保存下来的。大多数照片都已实现数字化，电子书正日渐占据图书市场的主流。大多数公司都喜欢给客户邮寄电子账单，而非纸质账单。视频和音乐已大多实现数字化。多年来，我们的财富不过是存储在银行计算机中的数字。政府以数字化的形式发布信息；医院在计算机上保存病例。越来越多的商店开始实行网上交易。我们只需要轻轻点击几次鼠标，就可以购买食品、汽车乃至任何种类的商品。所有这些海量的数据都存储在数据库中。它们的界面可以是一个赏心悦目的网页，供人随意浏览各种美观的照片；可以是一家网上商店，供人随心挑选品类丰富的商品；可以是一款功能强大的音乐播放程序，能让人徜徉于音乐的海洋；甚至可以是一款会计应用程序，能让人随时监测开支情况。但是，在多姿多彩的界面背后，让这一切成为可能的，便是精巧的数据库技术。 软件危机如今，软件业可谓风生水起，蔚为大观，仿佛这个行业的发展向来一帆风顺，毫无波澜。但是，正如电子业历经了“数字暴政”的阵痛，才有了集成电路的诞生，新生的软件业也经历了危机的考验，这场危机还推动了一门全新学科的诞生。 编写大型程序的巨大困难程序员遇到的问题从一开始就很明晰。虽然有了新的高级编程语言的帮助，开发人员在编写代码的过程中可谓得心应手，但是，前所未有的重大问题依然在不断涌现。20世纪60年代，随着集成电路的发明和摩尔定律的问世，计算机的性能每年都在突飞猛进。与此同时，软件应用也在以类似的速度不断飞跃。然而，就在这个过程中，程序员日益强烈地意识到，他们的程序正变得越来越难以掌控。程序当中的错误太多，软件并没有发挥应有的效果，而且开发系统的过程似乎正变得意料之外地漫长。 这些问题在1968年达到了顶点。在有史以来的第一次软件工程大会上，世界各地的计算机科学家齐聚一堂，共同讨论他们关切的问题。他们忧心忡忡，这一点从会上的讨论中就可以看出来： 麻省理工学院的罗伯特·格雷厄姆（Robert Graham）表示：“我们投入了长年累月的研究，耗费了巨大的投资，到头来却发现，我们从一开始就没有把系统研究透彻，软件根本没有取得预期的效果。我们就像莱特兄弟制造飞机一样，辛辛苦苦地把飞机造好，将它推下悬崖，任凭它轻而易举地坠毁，然后再从头开始。”密歇根大学计算中心（University of Michigan Computing Center）的伯纳德·加勒（Bernard Galler）表示：“我想举几个在IBM碰到的不好的例子。有一次，用户提出，希望能够增强PL/1语言可扩展性。对此，IBM经过一周的内部讨论，最终下结论称，这种事情不可能做到。因为语言设计师不打算告诉用户怎样实现所需的扩展。还有一个例子：OS/360操作系统的作业控制语言（job control language，简称JCL）开发出来以后，用户在设计阶段根本无法事先看到任何选项。为什么会出现这种情况呢？”丹麦第一家计算机公司A/S Regnecentralen的员工彼得·诺尔（Peter Naur）表示：“……软件设计师的角色类似于建筑师和土木工程师，尤其是规划城市、工厂等复杂建筑的设计师。因此我们应该学会从这些领域吸取灵感，攻克我们遇到的设计问题。” 此次大会落幕后，另一场大会很快召开，其宗旨是讨论技术和管理思想。从这一刻开始，软件工程学作为一门新的学科登上了历史的舞台。伊恩·萨默维尔是现代软件工程师、英国圣安德鲁斯大学（St. Andrews University）教授，他撰写了很多业内的权威教科书。他表示，新学科的命名颇有内涵，意在表明，人们从此将采取系统的、有组织的方式来编写软件。不过，大会的主办方给出了不同的说法，“他们声称之所以发明这个术语，只是出于调侃的心态，没想到这种叫法就传播开了”。当然，这样命名是为了“故意制造煽动的效果”，以激发研究人员行动起来。还别说，这样做真的起到了效果。没过多久，许多关键性的技术革新开始涌现，它们专门针对的是软件工程学领域，旨在辅助程序开发人员提高编程能力，写出高效的软件。在这一理念的指导下，新的编程语言得到开发。戴维·帕纳斯（David Parnas）等研究人员提出了信息隐藏的概念，这一概念在模块化编程和面向对象的编程领域举足轻重，它可以确保数据及相关函数封装在对象内，与其他的数据和函数分隔开来。这就好比采用标准化模块制造汽车——车载收音机等部件的更换不会影响到其他部件。同理，如果你设计好程序之后，突然想对某个地方进行改写（比方说将某个函数或数据结构更换），那么程序中的其他函数和数据完全不会受到影响。集成开发环境（Integrated development environment，简称IDE）的发明，就是为了让编程变得更加轻松。它们的作用就好比文字处理器——程序开发人员可以在不同的窗口编写代码，并对其进行编译和调试。正如文字处理器可以检查拼写和语法错误，集成开发环境也可以帮助编程人员找出程序中的错误，并提供大量实用的工具进行除错。现代的集成开发环境通常包括一系列工具，比如：手持设备模拟器；用于设计图形用户界面（Graphical User Interface，简称GUI）的工具；全方位的帮助系统，用于辅助编程人员从已有的库——即程序编程接口（application programming interface，简称API）中寻找合适的函数。 如何面向用户除了发明实用的编程工具，研究人员很快意识到，还有更好的软件设计方法亟待开发。这就好比汽车制造商不能把仅仅把目光放在硬件上，还应着眼于汽车的用途、目标客户的定位、成本开销的大小，从而将生产问题化整为零，分解成一个个具体的问题，比如：应该采用什么样的发动机、传动部件、转向系统、制动系统、车轮系统和座椅系统？车内需要容纳多少人？生产一台汽车需要多少时间？编写软件也是同样的道理。一个大型软件项目可能会比制造汽车复杂得多，怎样设计才能确保项目的高效运转？研究人员很快意识到，要做到这一点，必须确立一个明确的软件生命周期。首先，你必须合理定位产品和项目需求。接下来要做的，就是设计、运行和测试软件，并将其运行情况清晰地记录下来。最后要做的，就是发布软件，或许在这个阶段，你还需要指导用户如何高效地使用软件、如何进行必要的维护工作。 这些事情说起来容易，做起来难。产品或项目的需求并不好确定，因为顾客往往并不知道自己真正的需求到底是什么，因此可能会举棋不定、自相矛盾，甚至改变主意。他们往往不具备编程人员的思维方式，因此不知道如何从软件开发的角度表达自己的需求。换句话说，对于哪些事情在技术上可行，而哪些不可行，他们基本上没什么概念。有的时候，编程人员连目标用户是哪些人都无法确定，因此，真正应该提要求的人反而没有这个机会。 如何规划大型项目除此之外，不同的设计阶段应该如何开展，这也是摆在编程人员面前的一大难题。项目的开发架构是应该采用“瀑布模型”（waterfall model）——像流水下坡一样顺次开展每个阶段，还是应该采用“螺旋模型”（spiral model）——反复开展每个阶段，开发一系列原型软件，以最大限度地降低风险？软件的开发是应该遵循迭代式和增量式的过程，还是应该采用“灵活性强”的方式，以迅速适应可能发生的变化？就算你知道了开发软件的最佳顺序，怎样才能把每一个阶段的工作都做到最好？应该采用哪些设计方法和工具？怎样测试软件，才能确保万无一失？怎样维护软件，才能使之适应未来的变化？ 正因为软件工程学专家孜孜不倦地攻克上述难题，软件项目的发展才得以适应硬件的发展需求和用户复杂的使用需求。软件工程学着眼于软件开发的方方面面，比如对软件体系结构进行建模，采用可视化程序设计，使用形式化方法测试软件、提高其性能的可靠性。伊恩·萨默维尔认为，软件工程学领域已经取得了许多重大的进步，这些进步给软件开发带来了实实在在的影响。“开发不同类型的软件，需要采用不同类型的软件技术和方法，”他表示，“配置管理（Configuration Management，简称CM）就是一个非常重要的项目管理方法，它支持并行开发。信息隐藏的概念是由帕纳斯在1972年提出的，它在抽象数据类型（Abstruct Data Type，简称ADT）领域得到了进一步发展，并影响了大多数现代编程语言。在关键任务系统领域，我们不仅可以采用安全分析和可靠性分析的方法，还可以运用容错技术，为航空器、化工厂等重要设施建立安全可靠的系统。统一建模语言（Unified Modelling Language，简称UML）将多种建模概念融合在一起，如今已成为软件系统建模的标准方式。编程环境的思想于20世纪70年代问世，在20世纪80年代得到进一步发展，如今已在软件工程学界得到广泛采纳。”安东尼·芬克尔斯坦是软件工程学教授，在伦敦大学学院担任工程学系系主任。他认为，正因为有了软件工程学的帮助，程序员才得以高效利用时间。“如果没有软件工程学，我认为硬件与软件之间的性能差距会进一步扩大。制约软件开发的主要因素就是缺少训练有素的人才，现在也是如此。如果当初没有足够的人才投身于软件工程行业，我们就无法取得今天的成就了。” 软件膨胀不过，尽管为数众多的软件工程师竭尽全力地投身于技术攻坚，但是依然无法解决所有的问题。我们每次使用计算机时，都会对软件工程领域的一大问题感同身受：由于某种原因，软件每次升完级以后，其运转速度似乎都会变慢。计算机科学家（及众多编程语言的发明者）尼古拉斯·维尔特（Niklaus Wirth）观察到了这一现象，人们将其称为维尔特定律（Wirth’s Law）。维尔特定律的内容是：软件变慢的速度永远快过硬件变快的速度。其他科学家也发表过类似的观点。曾在英特尔担任研究人员的兰德尔·肯尼迪（Randall Kennedy）就是其中一人。他曾写道：“虽然与几年前的Office 2000相比，Vista系统上的微软的Office 2007 虽然处理能力提高了将近两倍，但是占用空间却多出了11倍以上。”造成这一现象的罪魁祸首是软件膨胀（software bloat）——新版本的软件往往只是在原版本的基础上叠加了新的代码，而并没有经过重新编写。 维尔特定律表明，纵使计算机的运行速度快得惊人，新一代的软件的运 行速度也比不上十年前的老版本。目前，计算机科学家正在费尽心思解决这个问题。不过萨默维尔深知，这并不是软件工程学领域的唯一挑战。“软件项目面临的主要挑战在于，开发环境正变得越来越复杂。这是因为，我们在建立新系统的过程中，将不同的供应商提供的各种系统和服务整合了起来。原本，在软件工程学领域，很多理论之所以能够成立，往往是基于这样的前提，那就是，系统完全处在软件开发人员的掌控之下，软件开发人员可以做出明智的决定来开发和改变系统。当这样的前提不再成立时，软件测试等方法必须做出相应的调整，以适应新的情况。”这一观点引起了一些计算机科学家的高度重视。伦敦大学学院教授马克·哈曼围绕搜索问题对软件工程学进行了研究。他按照遗传算法——也就是由“优胜劣汰”的生物进化规律演化而来的随机化搜索方法，利用计算机来寻找特定软件的最优测试方法。“软件测试是衡量软件质量、寻找优化方法的关键手段之一。测试的内容之一，就是寻找特定的输入，使程序执行特定的代码片段，”哈曼表示，“人工完成这样的工作需要花费很大的心血。这就好比你得从厚厚的地址簿里大海捞针，将一个人的电话和住址找出来。但是，如果计算机能够对测试用例进行评定，我们可以轻而易举地将这个过程自动化。” 其他危机不过，仅仅有个聪明的测试方法是不够的。我们所说的危机与20世纪60年代末的软件危机已经无法同日而语，但是从某种程度上讲，软件业依然面临着定位问题。大型软件开发项目依然经常失败，尽管软件工程师尽了最大的努力。有时候，问题只是出现在成本和时间上——我们并不擅长估算软件开发产生的耗费。“我们的软件估算水平很差，”芬克尔斯坦表示，“如果你让我‘开发一个售卖二手教科书的网页前端，’我可能一时半会儿没法告诉你需要多少时间。运气好的话，我可能之前就做过一次这样的项目，但是我在这方面的经验也就仅限于此了。’”不过，重大的失败也有可能是由更微妙的原因造成的（而且这样的事情不在少数，造成的损失也极为惨重）。芬克尔斯坦认为，问题的症结并不在于分析师和开发者经验不足。“个人认为，这些系统之所以失败，都是一些人们很熟悉的问题造成的：比如在项目设计和开展阶段犯了低级错误，”他表示，“你必须问自己，既然人们对这些问题都很熟悉，为什么还要一次又一次地犯同样的错误？他们是傻子吗？他们没看过萨默维尔的书吗？这些问题前十页就讲了，哪怕稍微翻翻也好啊，又不一定要全读完！我觉得，问题的症结是，企业结构、管理决策结构与开发软件的技术过程存在不协调。因此，这些系统之所以会失败，问题出在管理上，而不是工程上。”软件工程领域的挑战还表现在，怎样满足客户的信息安全需求，怎样设计软件才能使之适应互联网时代的潮流。此外，一些所谓的“非功能性需求”也越来越值得重视，比如电源或电池寿命。在这个问题上，哈曼的想法比较现实：“如果我在乘坐越洋航班时，笔记本的电量在半路上就耗光了，那么就算里面的软件再好，对我来说一点用也没有。我宁愿软件耗电量低点，让续航时间久点，就算软件里头到处都是漏洞也没有关系。”芬克尔斯坦也这么认为：“在软件工程领域，我们一直致力于开发新特性，从来没有想过省电的问题——一般都不会有人往这方面想，除非你要设计航天器。但是现在，这个问题已经变得很关键。有很多之前没有考虑过的新特性一下子变得非常重要。” 还记得以前我们讲到的编写并行软件吗？那是帕特森给整个行业的科学家提出的挑战。芬克尔斯坦确信，它会给软件工程领域带来重大的变革。“软件工程领域面临的另一大挑战就是多核技术。如果软件无法充分发挥多核技术的优势，那么一台计算机就算内核再多也于事无补。要是采用一个内核就足以运行所有软件，那么剩下15个内核留着干嘛呢？总不可能都用来运行杀毒软件吧。我们所需要的，不仅仅是编程技术的一个突破，而是整个软件工程领域的革新。这肯定会改变我们当前的游戏规则。”]]></content>
      <categories>
        <category>计算机</category>
        <category>历史</category>
      </categories>
      <tags>
        <tag>计算机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机先驱——莫里斯·威尔克斯]]></title>
    <url>%2F2019%2F05%2F19%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%85%88%E9%A9%B14%2F</url>
    <content type="text"><![CDATA[Sir Maurice Vincent Wilkes，1913年6月23日－2010年11月29日1931年他进入剑桥的圣约翰学院，之后进入剑桥著名的卡文迪什实验室工作。于1938年10月取得剑桥大学博士学位，而他的硕士学位是在当年年初才取得的。英国计算机科学家。设计和制造了世界上第一台存储程序式电子计算机EDSAC，在“工程和软件等计算机领域都有许多开创性成果”。 开端这是1946年的一个温暖和煦的仲夏日，时值星期一早晨。回想起三年前与图灵在下午茶时间的热烈讨论，克劳德·香农觉得恍如隔世。此时此刻，他正在宾夕法尼亚大学的摩尔电气工程学院学习一门为期八周的课程，这门课目前已经上到了第三周。能够受邀来此听课，对看他来说已是一大荣幸，毕竟，这是少数人才有的殊荣。课程采用讲座的形式，主题是电子数字计算机的设计。这是世界上第一门关于计算机科学的课程，香农发现，课上所学的许多思想在他的头脑里擦出了灵感的火花。他最近从莫奇利那里学到了一个新词——“编程”。它通常作为动词使用。给电子计算机编程是一个让人耳目一新的概念。香农还听到了一些关于办公室政治的八卦：给他们开课的两位讲师——莫奇利及其同事埃克特四个月前刚从宾夕法尼亚大学辞职，原因似乎是围绕“埃德瓦克”产生的专利纠纷。另一名讲师戈德斯坦近期就要去高等研究院（IAS）入职了，届时他将与香农的老同事约翰·冯·诺依曼共事。冯·诺依曼本来也要到这里来开设两个星期的讲座，但是他好像不会来了，因为临时有事。 在一篇机密级的论文中，香农发布了他最近在贝尔实验室开展密码学研究的部分成果。这些研究成果与他当年攻读理科硕士期间提出的思想一脉相承，只不过二者的着眼点不同。香农当年着眼的是开关电路，现在着眼的则是密码学背后的数学原理。他开始意识到，破译扰频加密的信息，其实大体上就相当于给正常传输的信息纠错。举个例子，如果一段编码中出现了重复信息——比方说它的内容中包含许多常见的词语如“这个”、“一个”、“和”，那么这段编码破译起来就会轻松许多。因为我们知道，“这个”、“一个”、“和”这类简短的词语是句中常见的语法成分，就算把它们的每个字都改头换面，也不难根据它们在句中出现的位置来判断其成分。只要破译了高频词，那么整条加密信息指的是什么内容，或许就能猜出个大概了。因此，要想增加破译难度，必须尽量减少冗余信息。但是，如果你想尽可能多地保留原始信息，而记忆存储系统又很容易出错，那就最好少删除一些冗余信息。检验信息是否出错的方法之一，就是设置奇偶校验位（parity）。至于奇偶校验位是指什么，还得从比特的概念说起。比特（bit）是内存中的最小单位，也称作“位”、它只有两个状态，分别以1和0表示。我们将8个连续的比特叫做一个字节（byte），比如（1、0、0、1、1、1、1、0）就是一个典型的字节。如果其中某一位存储了错误的值，那就会导致信息出错。为了检测信息是否出错，我们在每一个字节（8位）后面又额外增加了一位，称为奇偶校验位。这样一来，原来的8位字节就变成了新的9位字节。奇偶校验位也只有1和0两种值。如果原字节中1的个数为奇数，那么奇偶校验位就设为1，这样一来，新字节中1的个数就变为偶数；反之，如果原字节中1的个数为偶数，那么奇偶校验位就设为0，这样一来，新字节中1的个数依然为偶数。也就是说，凡是带有奇偶校验位的字节当中，1的个数始终应该为偶数，如果你发现某个字节不是这样，那就说明它有错误，这段字节包含的信息就需要重新读取。（这个方法在20世纪50年代早期开始在计算机领域广泛采用，后来，人们很快就开发出了更多高级的方法。） 言归正传，香农在摩尔学院听讲座的过程中，了解了二进制对于计算机的重要价值：二进制数不仅是计算机内各个部件交换信息的重要载体，还是确保信息存储和检索过程不出差错的重要工具。后来，香农发明了术语“比特”来指代二进制数位（binary digit），同时阐述了如何利用比特来衡量信息量，并对信息进行传输、加密、压缩、纠错。在当年赴摩尔学院听讲座的人当中，香农并不是唯一一个计算机领域的先驱。莫里斯·威尔克斯也去了摩尔学院，只不过他差点就错过了这门课程。香农在台下听莫奇利讲解二进制与十进制数的那一天，威尔克斯还在英国。1945年，莫里斯·威尔克斯在剑桥大学听说了埃克特和莫奇利在美国研制埃尼阿克的工作，于是在1946年2月给学院提交了一份报告。他在报告中写道：“这是一个大有可为的研究领域，电子应用技术首当其冲。它在战时取得了迅猛的发展。 美国人在这门学科上已经领先了一步，我觉得剑桥也应该迎头赶上。”三个月后，机械计算机专家莱斯利·科姆里（Leslie Comri）来访剑桥。他从美国带来了一份手稿副本——即约翰·冯·诺依曼所写的《关于埃德瓦克的报告初稿》。威尔克斯只有一个晚上的时间阅读报告，当时还没有影印机，他只能边读边作笔记。威尔克斯很快就被报告的内容吸引住了。“我很快就意识到这个研究成果非同小可，”他表示，“从那以后，我对计算机的发展前景一直没有怀疑过。”就在威尔克斯依然对报告的内容记忆犹新之时，他突然接到了摩尔学院院长哈罗德·彭德（Harold Pender）发来的电报，邀请他去参加一门新开的电子计算机课程。威尔克斯的越洋航程并不顺利。尽管伙食条件一流，但是住宿条件太差，35个人挤在一艘只能容纳20个人的小货船里。更糟糕的是，发动机在中途抛锚了好几次。就这样，威尔克斯一路历经磨难，终于在8月15日抵达了纽约，上岸后又马不停蹄地赶路，总算在8月18日赶到了费城。这时候，他已经错过了三分之二的课程，好在前面的课程大多都是些入门性质的讲座。到了8月19日，也就是星期一，威尔克斯抵达摩尔学院，正好赶上当天下半节课。这堂课讲的是埃尼阿克的细节内容，讲师提供了详尽的电路图。威尔克斯回到剑桥大学，满脑子都是计算机领域的前沿思想和美国人取得的一些关键成果。威尔克斯认为，是时候研制一台实用的存储程序计算机了。幸运的是，没过多久，餐饮巨头J. Lyons &amp; Company就给他提供了科研经费和技术人员，因为该公司需要计算机进行会计核算，管理员工工资单。威尔克斯的项目进展很快，他在雷达领域积累的经验更是大大加速了这一进程。项目团队在此基础上构建了一个工作记忆系统，用于存储数字。威尔克斯在研制新机器的过程中，旁听了图灵开设的几个讲座，讲座的主题是图灵关于自动计算机的设计思想。不过，两个人的设计理念并不一致。图灵认为，计算机应该在水银延迟线存储器的基础上进行优化设计。威尔克斯的观点正好相反。“我认为，水银延迟线存储器迟早要被真正的随机存取存储器淘汰。与其把时间和精力都花在一项短命的技术上，还不如多下点功夫研究编程，毕竟，编程领域还有那么多问题值得研究。”图灵也不赞赏威尔克斯的设计理念，他在一篇备忘录中写道，威尔克斯有一些理念“比较偏向美国传统，遇到什么困难就喜欢依赖设备，而不喜欢动脑子。”但是事实证明，威尔克斯的方法更加实际。剑桥大学的电子延迟存储自动计算机（Electronic Delay Storage Automatic Calculator，简称EDSAC）于1949年5月6日投入运行，直到1958年才光荣退役。它是世界上第一台实用的存储程序计算机。 学习计算机编程剑桥大学的EDSAC计算机并不只是一台前沿尖端的机器，它还开创了计算机领域的先河。此前的计算机每次执行新的运算，都需要插入不同的线路进行重新装配，而EDSAC则通过存储器中的软件实现各种不同的运算操作，这就对编程提出了很高的要求。为了写出功能强大的软件，威尔克斯和戴维·惠勒（David Wheeler）等研究人员提出并改进了许多新的思想，时至今日，这些思想在计算机编程领域已占据主流地位。不过编程在当时并不是一件容易的事情。所有的早期计算机先驱很快就意识到，一旦设计出存储程序计算机，就必须拼了老命地编写计算机能够运行的程序。如果任何程序都无外乎是一组能够触发数学或逻辑学电路的二进制数，那么编写软件就会变成一场噩梦——而事实也的确如此。1949年6月，惠勒第一次意识到了编程的艰难。他后来回忆起了当时的情形：“那时候，我正试着让自己编写的第一个真正意义上的程序运转起来。有一次，我像往常一样从EDSAC机房出来，准备去操作打孔机，突然站在楼梯转角处犹豫了，心里意识到，单是给自己的程序除错，可能就要花掉我大半辈子的时间。”显然，当时的科学家需要一些新的思想，来简化编程过程，提高编程能力。对此，威尔克斯（在几年后）提出了一个方法，称为微程序设计。当时，麻省理工学院正在研制的旋风计算机（Whirlwind）给了他部分灵感，让他意识到，并不是每一条低级指令——比如除法——都需要电子电路来执行。复杂的指令完全可以分解成一系列简单的指令，而微代码编写出来的微程序可以作为二进制机器代码和硬件之间的桥梁。事实证明，这一方法实用性很强，时至今日，复杂指令集计算机（Complex Instruction Set Computer，简称CISC）处理器依然采用了这一思想原理，以执行高度复杂的操作。而精简指令集计算机（Reduced instruction set computer，简称RISC）处理器则不使用微编程。但是即便是使用微代码，计算机编程人员依然需要编写一长串的数字，即机器代码指令。而且，早期的编程人员还因为机器的内存容量极其有限而备受掣肘。EDSAC的内存只有两千字节左右（放到今天，一部手机的内存都比它大几百万倍）。为了解决这些问题，威尔克斯的团队又想出了一个妙招——编写子程序。研究人员意识到，许多程序在运行的过程中，都需要重复执行某个操作——比如在某个复杂的数字运算中，需要多次进行开平方操作。如果每次开平方都得把平方根代码写上，那么程序当中就会出现许多重复代码，占用不必要的空间，使程序变得庞大而低效。这就好比你在写一个句子时，不仅构造了完整的语法结构，还将句中每个词语的定义也写了下来。为了简化编程过程，威尔克斯的方法是建立子程序库，也就是将常见的函数单独列出，集中起来，就像把常见的词语及其释义收录在词典中一样。一旦程序在运行的过程中需要使用到某个常见函数，计算机就会在子程序库中“查找定义”，执行相应的子程序代码，根据输入值进行运算，再将运算结果返回。在这一方面，威尔克斯的理念已经领先于同时代的大多数人。冯· 诺依曼有一次突然造访，与威尔克斯进行了讨论。两个人的观点产生了分歧。威尔克斯回忆道：“他觉得应该把开平方运算嵌入到计算机的指令集中……我自己的立场则有所不同，我已经把子程序看做是对基本指令集的扩展，所以觉得没有必要再在指令集中嵌入一个特殊的函数。”由于威尔克斯领导的剑桥大学研究团队很早就开始在编程领域开疆拓土，他们对编程的艺术也颇有心得。普林斯顿高等研究院的冯·诺依曼喜欢绘制“程序框图”，来展示程序应该如何运作。所谓程序框图，大体上就是一系列带箭头的步骤，可以展示控制流。不过，威尔克斯手下最好的程序开发人员戴维·惠勒认为，要想写出出色的软件，还需要其他的方法。“我们关心的首要问题是，用户在操作过程中是否得心应手，因此在这方面也下了很大的功夫。”他表示，“模块化设计的编程风格很早就开始得到推行。这是我们开展编程教学的方式。当然，我们也知道一些其他的方法，比如冯·诺依曼的程序框图。不过这些方法一般都不用，就算用也只是拿来说明已经完成的步骤。我 们发现，只要将复杂的问题进行分解，用一个个子程序加以解决，然后将子程序置于主程序的控制之下，就可以逐步形成模块化设计的思维方式，到时候程序设计自然水到渠成，根本不需要使用到程序框图。个人认为，程序框图最容易让人写出垃圾软件。并不是说这种方法毫无价值，只不过你要是想拿它来代替思考过程，根本就不管用。”威尔克斯的团队还考虑到了程序员可能遇到的其他困难。他们从一开始就意识到，尽管计算机只能理解数字，但很少有人能够在只采用数字的情况下编写程序，了解计算机的运行过程。人的大脑习惯了阅读文字和符号，而不是处理一连串数字。惠勒认为，冯·诺依曼在高等研究院研制的计算机在这一方面做得很差，完全比不上剑桥大学的 EDSAC。“它太原始了，这让我非常震惊，”他表示，“我估计它的程序是用二进制输入的。我们剑桥大学的研究团队很早就开始采用了一种叫做‘汇编程序’的工具。”它能够转换编程语言，从十进制转为二进制，使用助记符，可引用代码，可分隔字段，可自动定位子程序，还具备其他各种功能。我们基本上从开展项目的第一天起就已经在使用汇编程序了。这极大地简化了编程过程。这样一来，程序开发人员就不需要和抽象的二进制数打交道了，他们可以采用简短的词语来编写程序，这些词语看起来有点像英文单词。与一连串抽象的二进制数字相比，即使是奇怪而又晦涩的文字无论在阅读还是理解上，都要轻松许多。它与处理器使用的低级的代码没有太大的分别：其中的每一个词语（或命令）——比如“cmpl”、“jmp”——都直接对应于机器代码中的一条指令。要将汇编语言写成的程序转换为相应的机器代码，就需要使用到另一种计算机程序，称为汇编程序。汇编程序读取的是用汇编语言书写的源程序，输出的是用机器语言表示的目标程序。汇编语言在计算机领域举足轻重，20世纪90年代的所有程序都是由汇编语言写成。几十年来，有两种常见的程序只采用汇编语言：一是计算机游戏（因为开发人员希望尽可能地提高游戏的运转速度，同时尽可能给玩家带来极致丰富的游戏体验），二是操作系统。即便是在当今时代，程序员要想编写速度超快而形式简洁的代码，都免不了要采用一些汇编语言。 攀登更高峰1951年，计算机开始搭载好几个层次的软件。第一层是微代码，它完全依赖于芯片内部的硬件连接。第二层是机器代码，它比微代码更抽象一些。第三层是汇编语言，它比机器代码可读性稍强。计算机编程，说白了其实就是告诉计算机应该使用哪种逻辑和算术电路。要想给计算机编程，程序员可以使用汇编语言来写代码，而汇编语言正如我们在上一节所看到的那样，和英文单词有些类似。这些代码随即由汇编程序转化为机器代码，机器代码定义微程序的指令，微程序则在算术和逻辑单元（ALU）的电子元件中被翻译为一系列指令的组合。不过，汇编语言对于许多程序员来说依然难度太大。如果你想处理更复杂的思想和概念，那么，纠结于个别的跳转指令只会拖累你的步伐。 如果你希望自己的程序能够在完全不同的处理器上运行，那就需要采用高级的编程语言，也就是独立于底层硬件的计算机语言。1953年，随着电子计算机在全世界遍地开花，发明抽象编程语言的问题开始受到广泛关注。莫里斯·威尔克斯受邀主持了美国计算机协会（ACM）在麻省理工学院召开的一期研讨会，专门探讨这个问题（当时的会议主题为自动编程）。威尔克斯至今还清楚地记得当年会上的讨论情况。“与会者的意见分歧相当尖锐。有些人认为，凡是试图绕开困难的做法都是误入歧途。程序员只有老老实实地恪守本分，编程领域才会取得更大的发展。另一方面，还有一些人认为，只有新的技术才具有实实在在的实用价值。”（时至今日，计算机科学家当中依然存在这两派的纷争。）许多研究人员已经在试验新的、更简单的编程语言。早在1949年，约翰·莫奇利就发明了一种语言，称为简代码（Brief Code），后来更名为短代码（Short Code）。短代码虽然使用起来简单许多，但是需要翻译——也就是说，计算机每次运行这种语言编写的程序，都得临时将短代码翻译成机器代码。这就意味着，这种程序的运行速度比机器代码写成的程序慢54倍。与此同时，在英国曼彻斯特，一位名叫埃里克·格伦尼（Alick Glennie）的研究人员发明了另一种语言。这种语言易于使用，可通过另一种程序自动转换为机器代码，因此具备简单实用、运行速度快的双重优势。格伦尼将其称为自动代码（Autocode）。显然，用自动代码写程序比用汇编语言要轻松许多。其中有些自动代码语句和好几条机器代码指令相对应，不过程序员不需要为此挂心。只要使用另一种称为编译器的程序，就可以将这段由自动代码编写而成的简洁英文命令翻译成机器代码。自动代码是世界上最早出现的编译型高级编程语言。自计算机协会在麻省理工学院召开研讨会，讨论自动编程问题后，越来越多的计算机科学家开始意识到，编程过程的简化势在必行。1957年，IBM的约翰·巴库斯（John Backus）发明了另一种编译型高级编程语言，称为福传（FORTRAN）。福传的全名是Formula Translation，意思是“公式翻译”。这种语言甚至比自动代码更高级，可以用来编写更加复杂的程序。它的编译器也极为智能，可以生成非常简洁高效的机器代码。没过多久，许多适用于其他计算机的福传编译器相继问世，这样一来，同一款福传程序就可以编译成不同计算机所特有的机器代码。从这一刻开始，程序员便有了一种新的工具——“便携式”代码，它可以使同一款程序在完全不同的计算机上运行。很快，其他编程语言也开始纷纷效法，比如算法语言（ALGOrithmic language，简称ALGOL）、列表处理语言（LISt Processor，简称LISP）、初学者通用符号指令码（Beginner’s All-purpose Symbolic Instruction Code，简称BASIC）。随着计算机设计师开始研制晶体管计算机，这些语言也得到了稳步改进。很快，计算机科学家便能分析编程语言，并用数学方法——包括邱奇的λ演算将其形式化。程序员也可以在代码中表达更抽象的概念，而不需要操心低层次的细节问题。各种类型的编程语言相继问世。早期语言基本上都是过程式语言（程序员告诉计算机如何执行过程步骤），后来的语言则采用了不同的编程范型。在面向对象的语言（Object-Oriented Language）中，数据及其操控方法都封装在“对象”中，以实现代码的模块化，防止数据的意外损坏（这一点也是程序的“副作用”）。函数式编程语言利用若干简单的执行单元让计算结果不断渐进，逐层推导复杂的运算，而不是像过程语言一样，设计一个复杂的执行过程。此外，还有更多适用于并行计算机的程序语言相继问世。正因为众多早期先驱的开创性工作，如今人们习以为常的一些重要编程思想才得以诞生。威尔克斯继续投入计算机语言的研究，他在改良算法语言60（ALGOL 60）的基础上发明了CPL（Combined Programming Language）编程语言。这种语言并没有受到热烈的反响，但是却奠定了BCPL（Basic Combined Programming Language）语言的基础。BCPL进一步发展演变，推动了B语言和C语言的问世。直到现在， C语言（以及在此基础上形成的诸多语言，如C++、C#、Objective C）或许是世界上应用最广泛的计算机编程语言之一。人们当前使用的许多众所周知的操作系统（比如UNIX、Linux、Mac OS X、Windows）都是用C语言写成的。如今，几乎每一台计算机上都搭载了C语言编译器，方便用户使用C语言编写代码。]]></content>
      <categories>
        <category>计算机</category>
        <category>历史</category>
      </categories>
      <tags>
        <tag>计算机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机先驱——罗伯特·诺伊斯与戈登·摩尔]]></title>
    <url>%2F2019%2F05%2F18%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%85%88%E9%A9%B13%2F</url>
    <content type="text"><![CDATA[Robert Norton Noyce，1927年12月12日—1990年6月3日1953年，获麻省理工学院（MIT）博士学位；1949年，获格林尼学院文学学士学位。1968年创办英特尔公司、1957年创办仙童半导体公司。 Gordon Moore，1929年1月3日—？加州大学伯克利分校的化学学士学位，并且在加州理工学院（Caltech）获得物理化学（physical chemistry)博士学位美国科学家，企业家，英特尔公司创始人之一。 摩尔定律发明硅芯片后，罗伯特·诺伊斯继续和同事戈登·摩尔（Gordon Moore）在飞兆半导体公司（Fairchild Semiconductor Corporation）研究集成电路技术，直到1968年，两人成立了一家新公司，即著名的英特尔。他们和全世界的业内先驱一道，共同掀起了电子学领域的技术革新。早期的集成电路还只有几百个、乃至上千个晶体管，但制造工艺的稳步改进使单个芯片上可以容纳的晶体管数目越来越多。（20世纪60年代早期，集成电路技术之所以迅猛发展，很大程度上是因为美国导弹计划和阿波罗太空计划的推动。）集成电路的日益复杂使戈登·摩尔在1965年做出了一个预测。当时，他注意到，从1958年集成电路问世到1965年，单个芯片上的晶体管数量每年都翻了一倍。于是，他预测，这个趋势至少还会持续十年。后来，他修正了自己的观点，认为单个芯片上的晶体管数量每两年就会翻一倍。1970年，加州理工学院（California Institute of Technology简称 Caltech）教授卡弗·米德（Carver Mead）发明了专门的术语，将这个预测称为“摩尔定律”。令人惊叹的是，这个“定律”似乎一直都很准。单个芯片上可容纳的晶体管数量在20世纪70年代中期为一万个，在1986年达到了一百万个，在2005年则为十亿个。尽管经常有人提出，摩尔定律很快就会失效，因为晶体管的尺寸越做越小，已经快要达到物理定律的极限，不过到目前为止，这项卓越的技术依然保持着强劲的发展势头。计算机技术一向与电子学的前沿技术联系紧密，因此从20世纪60年代开始，硅芯片技术的迅猛发展也带动了计算机的更新换代。摩尔在英特尔的同事大卫·豪斯（David House）认为，从摩尔定律可以推断出，计算机的性能每隔18个月就会翻一倍。他说的基本没错——这些年来，计算机的性能大约每隔20个月就翻了一倍。摩尔后来开玩笑说：“18个 月是豪斯说的，不关我的事。” 正因为电子学正向着微型化的方向大幅迈进，我们的计算机每年都在变得更小巧、更便宜、更强大。早期的计算机都是庞然大物，很多情况下只能靠远程终端控制（一台大型计算机就需要很多个键盘和显示屏）。很快，小型计算机和个人计算机（台式机）相继问世。随着单一芯片上集成的元件继续增多，计算机的尺寸进一步缩水，由此产生了便携式个人计算机，也就是笔记本。后来又出现了更迷你的上网本、平板计算机和掌上设备，比如智能手机。计算机已变得小巧、廉价，足以在儿童玩具上实现复杂的功能，甚至在贺卡中嵌入音乐，而且由于它的更新换代速度太快，被淘汰的设备无需多想就可以直接丢弃。本已小巧玲 的计算机还会向着更小巧、更便宜的方向迈进，这种发展趋势还没有任何减缓的迹象。虽然有了摩尔定律这一强大利器，科学家并没有安于现状，不再绞尽脑汁寻找提升计算速度的新方法。事实上，计算机领域的创新远未止步。尽管所有计算机都具备冯·诺依曼当年在报告中提到的逻辑元件，但它们远非千篇一律。为了提升运算速度或效率，各种高明的优化设计方案层出不穷。举个例子，自从计算机问世以来，工程师就一直面临着两难的问题：要想扩大存储量，就必须牺牲速度。在存储量小的情况下，速度可以很快，但存储量一旦扩大，速度往往就会受到拖累。我们在日常生活中也经历过类似的事情——假如你有一张简短的历史购物单，要想在上面寻找某样东西，是一件轻而易举的事情，不需要花什么时间；但是，如果你写了二十年的日记，想在这些日记当中寻找某一天购买过的某样商品，那么寻找起来就会困难很多，花的时间也会长很多。因此，回到计算机的问题上，要想兼顾速度和存储量，可以结合采用多种不同类型的存储器。如今的计算机处理器通常有如下配置：少量超快内部存储器（称为寄存器）；一个内部高速缓冲存储器（cache，简称高速缓存）（或许还会加装一个容量稍大、但速度稍慢的高速缓存）；一个比高速缓存更慢，但却更大的外部存储器；一个比外部存储器还慢，但却大很多的硬盘；此外或许还会加装一个比硬盘还慢，但却更大的备份存储器（磁带或硬盘）。只要在时机把握得当的情况下，将数据和指令从慢速存储器转移到快速存储器，计算机就能迅速调取信息，从而运行得更快。（这就好比你在写日记的时候，将重要的信息提取出来，写在一张纸上，这样日后查找起来就会更方便。）现代计算机处理器还有一种典型的优化设计方案，称为流水线（pipelining，又称管线）。其具体执行过程非常类似于工厂中的流水线。下面我给大家具体解释一下。工厂制造一辆车可能需要一整天，但是几乎每时每刻都有新车出厂。这是因为采用了流水线操作，生产汽车的流程被分为许多道工序，所有工序并行操作，不同的车辆同时进入不 同的工序。比方说，生产汽车的部分工序依次包括：焊接门框，安装车门，安装电动车窗。第一辆车进入焊接工序的同时，第二辆车进入装门工序（比第一辆车早一道工序），第三辆车进入装窗工序（比第二辆车早一道工序）。接着，所有汽车通过运输带自动进入下一道工序：第一辆车进入装门工序，第二辆车进入装窗工序，同时，另有一辆车接替第一辆车，进入焊接工序。计算机处理器的流水线技术也是一样的道理：将一条或一组指令的执行过程拆分为多个步骤，然后通过硬件处理单元 尽可能多地并行执行这些步骤。处理器的流水线段数越多，在理论上可以并行执行的指令数也就越多。除了流水线作业以外，还有其他方法可以让计算机并行执行指令，比如采用向量处理器。向量处理器不仅可以执行向量计算（一次直接操作一维数组，而不仅仅是一个数据），还可以并行运行多个处理器。 在当今时代，就连个人计算机的处理器中，也包含人类有史以来最精巧繁复的设计作品。它们已经复杂到无以复加，以至于没有其他计算机的辅助，就不可能完成设计过程。无论是安排硅芯片上晶体管的布局架构，还是设计处理器的集成电路，这类低端的设计工作现在已经基本上没有人在做了。未来计算机的细节设计已经交给当今时代的计算机来承担。 并行化是计算机的未来计算机技术的进步看似永无止境，而且，摩尔定律可能会让人想当然地以为，处理器势必会一直朝着更小巧、更便宜、更快捷的方向发展下去。但是，任何事物都不可能永远保持飞速发展的状态。事实上，我们在前进的道路上已经遇到了一个障碍。计算机体系结构教授戴维·帕特森道出了其中的缘由：“过去十年到十五年的时间里，我们为了提升计算机的性能，不断地增加晶体管的数量。每一次增加晶体管的数量，都会使硅芯片的功耗和散热压力更大。每块芯片约100瓦的功耗已经是其散热能力的极限。我们大概在2003年达到了这个水平。要想继续利用摩尔定律提升计算机的性能，唯一的出路就是制造并行计算机。这就意味着我们必须改变编程模型， 这是六十年的计算发展史上最重大的变革。”也就是说，问题并不在于摩尔定律。因为在未来的许多年里，硅芯片上的晶体管数目似乎还会越来越多。真正的问题在于，一个体积较大、而且精密复杂的处理器会在运转的过程中发热。笔记本发烫到致人三度烧伤、处理器发烫到融化电路板，这种夸张的事情没有人愿意看到。唯一的解决办法是，制造更小、更简单的处理器，使单个处理器的功耗减小，同时在单个芯片上集成多个处理器。计算机处理器的设计理 念已然开始发生变迁。因此，现在市面上的计算机的时钟频率（clock speed）（用于衡量计算机解读新指令的速度）可能并没有快多少，但是处理器中的核数却增加了不少。不过这里面有一个问题：既然有了并行或多核处理器，就理应配备能够高效利用其性能的软件，但是编写这样的软件对于程序员来说，是一件极其困难的事情。如今，硬件条件已经齐备，但是软件设施明显跟不上前进的步伐，无法充分发挥计算机的全部运算能力。帕特森同意这一观点，他在最近发表的一篇文章中写道：“处理器的并行化和微型化是计算发展史上的一个里程碑。” 有许多计算机科学家试图尝试帕特森的方法，但是到目前为止，问题尚未解决，我们还不知道怎样编写并行软件，才能使之与新的计算机体系结构相适应。怎样才能写出并行文字处理器或并行电子邮件程序？这个问题着实令人头疼。不过，值得庆幸的是，有一些应用程序在本质上讲就已经是并行程序了。其中最明显的例子，或许莫过于我们在每一台现代计算机上都会看到的、神奇的计算机图形。计算机图形往往由成千上万个微小的多边形拼接而成，多边形的表面覆盖着照片质量的图像。打个比方，假如你想制作某件物品的三维模型，可以先用铁丝网将其形状构建出来，然后在表面覆盖图像，用以表现物品表面的图案。计算机图形也是一样的道理。无论是展示动画效果（比如游戏角色的动作、行驶在车道上的汽车），还是纯粹显示窗口和图标，计算机都在同时改变成千上万个多边形和图像的位置，而且每个多边形和图像的位置改变方式都非常相似。由此可见，计算机不费吹灰之力，就可以并行处理这些计算过程，提升运转速度。事实上，时至今日，图形的并行处理已经变得轻而易举，以至于大多数最先进的多核计算机结构都是图形处理单元（graphics processing units，简称GPU）。这些处理器已经有数百个内核，所有的内核都并行计算。因此，大多数游戏机、个人计算机、乃至小型便携式计算机都采用了并行GPU，以使图形流畅逼真。正因为GPU运算如此之快，内核如此之多，它已成为许多超级计算机的重要部件。处理器的并行化趋势并不仅仅表现在单个芯片上。云计算是最近出现的一个新概念。它提供了一个动态虚拟的架构，这个架构或许会改变我们对计算机的认识。有了它，计算机用户就可以购买处理时间，使用异地多台计算机的软件和存储器，而不需要知道提供服务的计算机位于何处、其部件究竟如何运转。从概念上讲，云计算将计算机视为一种资源——这跟水电的性质是一样的，我们在日常生活中都会用水用电，但却不需要知道自来水厂和发电站在哪里。云计算可以让用户使用最新软件，执行高强度计算，享受虚拟主机服务，而不需要参与异地物理主机的升级和维护。在线购书网站亚马逊就是云计算领域的创新先驱。该公司意识到，其庞大的数据中心通常只有10％的容量得到了有效利用，因此，在2006年，该公司开始推出亚马逊网络服务（Amazon Web Services），出售数据中心的闲置容量。其他公司可以按需购买亚马逊提供的任何计算服务、软件和存储空间，而不需要维护或升级任何计算机。这一做法已变得越来越受欢迎，很多公司将来或许会从“云端”购买 企业所需的一切计算服务，而不是大动干戈地建立和维护自己的内部计算机系统。另一方面，用户或许也可以通过为数众多的云端计算机执行并行处理，而不需要担心任务怎样拆分——只要云端软件足够智能，可以代劳就好。处理器的并行化趋势还体现在汽车上，这里的并行处理比较容易实现。一台现代汽车上可能会搭载一百多个微处理器，它们协同工作，共同确保发动机和传动装置的平稳运转，同时控制仪表板、车门锁、倒车雷达、车载收音机、GPS、车灯、后视镜、座椅调节器……事实上，大多数汽车都有自己的计算机网络，使车内不同的计算机能够高效配合。 在这一方面，读者朋友们或许已经有了亲身体验。当你踩下油门，发动机猛然加速时，车载收音机的音量也会自动变大。有些汽车甚至更加智能，可以将安全气囊加速计、停车灯、GPS导航系统、手机和车门锁进行互联，万一出了什么严重的事故，车子就会呼叫应急号码，将你的GPS坐标发送出去，同时解锁车门，打开停车灯。 超越冯·诺依曼不过，在有些人看来，如此惊人的技术进步依然远远不够。曼切斯特大学教授史蒂夫·弗伯（Steve Furber）在职业生涯的开始，曾为艾康（Acorn）计算机公司设计ARM 32位微处理器。这个设计在世界各地受到了热捧，如今，ARM内核的出货量已超过200亿个，比英特尔芯片的销量还多（ARM处理器本身也更昂贵）。多年来，全世界90％以上的手机都至少搭载了一个ARM内核。不过，弗伯虽然是正统的计算机设计师出身，但在1998年却决定改变方向。他意识到，生物大脑似乎比计算机处理器的计算和存储部件要优越许多。“最后，我一咬牙，就转方向了，”弗伯表示，“管他呢，反正我感兴趣的是神经网络。”如今，有越来越多的计算机设计师开始研究仿生计算机，弗伯就是其中的一员。他有一项雄心勃勃的设计，称为SpiNNaker。SpiNNaker是一个通用脉冲神经网络结构，其中包含成百上千个并行运转ARM微处理器。弗伯并不是唯一一个具备前沿思想的计算机科学家。如今，各种类型的仿生处理器正在紧锣密鼓的研制当中，它们的性能有的类似于大脑神经元，有的类似于免疫细胞，有的类似于细胞中的基因。有些研究人员甚至在尝试用新的材料代替硅，来制作处理信息的芯片。现在，还有诸多问题等着科学家来解答：我们能否在DNA链中存储信息，让它们跟基因一起重组？我们能否对细菌进行基因改造，从而发明新的计算机？我们能否发明量子计算机，让它根据匪夷所思的物理学量子效应来执行计算？约克大学（University of York）教授安迪·泰瑞尔是一名计算机工程师，专攻仿生计算机。他认为，在未来的一段时间里，计算机体系结构依然会采用经典的冯·诺依曼设计。“但是，你可以想象，有‘一小撮’计算机工程师已经在设计新的体系结构了（希望他们的设计不仅新奇，而且令人振奋）。研制过程中或许采取了新的材料（或材料组合），比如 分子器件、忆阻器（memresister）、生物电材料、各种化学结构（液晶已经被人试过了）。或许还有些新的材料我们根本就不知道。”泰瑞尔认为，自然界中一定隐藏着某些秘诀，能够启发我们改善计算机的性能。毕竟，自然界中存在许多复杂而又高度精巧的事物。“怎样才能在保持原有优势的基础上，将材料换成新的呢？这是一个难关。采用生物材料的系统似乎能搭载更多（也更复杂）的部件，其数量（和复杂度）可能会超乎人的想象。因此，我们面临的一大挑战或许是：怎样才能制造这样的系统？应该采用什么材料？怎样才能发挥它的性能？”]]></content>
      <categories>
        <category>计算机</category>
        <category>历史</category>
      </categories>
      <tags>
        <tag>计算机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机先驱——约翰·冯·诺依曼]]></title>
    <url>%2F2019%2F05%2F18%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%85%88%E9%A9%B12%2F</url>
    <content type="text"><![CDATA[John von Neumann，1903年12月28日—1957年2月8日1921年，冯·诺依曼在布达佩斯大学注册为数学方面的学生。与此同时，冯·诺依曼进入柏林大学（1921年），1923年又进入瑞士苏黎世联邦工业大学学习化学。1926年他在苏黎世联邦工业大学获得化学方面的大学毕业学位，通过在每学期期末回到布达佩斯大学通过课程考试，他也获得了布达佩斯大学数学博士学位。先后执教于柏林大学和汉堡大学，1930年前往美国，后入美国籍。历任普林斯顿大学、普林斯顿高级研究所教授，美国原子能委员会会员。美国全国科学院院士。20世纪最重要的数学家之一，在现代计算机、博弈论、核武器和生化武器等领域内的科学全才之一，被后人称为“计算机之父”和“博弈论之父”。 制造大脑事有凑巧，1943年，当图灵回到英国后，一位名叫约翰·冯·诺依曼的数学家也从美国漂洋过海，来到了英国。冯·诺依曼当时是普林斯顿高等研究院最年轻的成员（他是最先被研究院聘为教授的五人之一，同时入院的还有爱因斯坦），他人脉很广，也认识图灵，因为在1938年，图灵博士毕业，成为研究助理后，他曾要求图灵留在普林斯顿。但图灵拒绝了这个工作机会，回到了英国剑桥。冯·诺依曼也见过香农。那是在1940年，香农还在高级研究所担任研究员。 20世纪30年代，人们越来越热衷于发明自动计算机。几个世纪以来，机械式计算机除了齿轮和螺丝钉以外，什么部件也没有。冯·诺依曼对这些设备深为着迷，他尤其痴迷于19世纪20年代查尔斯·巴贝奇（Charles Babbage）发明的一台机械式计算机，它与如今的现代计算机在设计上有许多共通之处。随着继电器这种电控开关的问世，利用电动设备进行计算已经成为了可能。不少工程师发明了早期计算机。其中最早的机型之一采用了柏林工程师康拉德·楚泽（Konrad Zuse）发明的继电器。这台巨型机器称为Z3，由于缺少条件分支，它的功能受到了一定的局限。也就是说，它不能根据不同的计算结果执行不同的操作，必须在程序中不停地执行相同的计算。它的运行速度也很慢，因为继电器采用了移动部件接通和断开电流。运行速度更快的计算机都采用了没有移动部件的电子管（真空管）。20世纪30年代，美国爱荷华州立大学（Iowa State University）的 约翰·阿塔纳索夫（John Atanasoff）花了几年的时间发明了一台电子计算机，用来解线性代数方程。这台计算机由他和学生克利福德·贝里 （Clifford Berry）共同制造，称为“阿塔纳索夫-克利福德贝里计算机”（Atanasoff-Berry Computer，简称ABC）。它体型较小，性能不甚可靠，内含大约300个电子管。与此同时，英国工程师托马斯·弗劳尔斯（Thomas Flowers）于1934年在继电器的基础上发明了独创的开关系统，并于30年代末投入使用。开关系统采用了3000多个电子管，用于英国电话交换机和简单的数据处理。 1943年，图灵回国后，鼓动马克斯·纽曼接近弗劳尔斯，请他来布莱切利公园，帮忙改进他们在继电器的基础上设计出来的破译机。1943年底，弗劳尔斯发明了巨像I（Colossus I）——一台内含1600个电子管的电子计算机。巨像I后来一共制造了十台，每一台都包含2400个电子管，但它们不是通用机器，必须插入不同的电缆重新编程。 这时候，冯·诺依曼已结束英国之行，回到了美国。由于他名气很大，美国国防部邀请他参与曼哈顿计划（Manhattan Project，美国政府制造第一颗原子弹的计划），负责设计原子弹的爆炸外护层（explosive outer jacket）。要完成这项工作，必须进行大量复杂的数学计算。冯·诺依曼意识到，他需要一台全新的计算机，其性能必须远远超越当前所有的计算机。一次偶然的相遇注定将改变一切。1944年夏，冯·诺依曼在马里兰州的火车站遇到了曾任数学教授的赫尔曼·戈德斯坦中尉（Herman Goldstine）。戈德斯坦当时是宾夕法尼亚大学（University of Pennsylvania）摩尔电气工程学院（Moore School of Electrical Engineering）的军方联络人。在摩尔电气工程学院，一台令人惊叹的全新计算机正在紧锣密鼓的研制当中。时至今日，戈德斯坦依然对当年与冯·诺依曼交谈的情形记忆犹新：“话题很快就转移到了我的工作上。我说我正在关注一项开发任务，任务的目的是制造一台每秒钟可以运算333个乘法的电子计算机。这句话才说完，整个谈话的气氛一下子就变了，原本我们还是比较轻松、随意地聊聊天、打打趣，突然变得像是在 做数学博士学位的口头答辩。”冯·诺依曼马上做出安排，拜访了项目的设计师：约翰·莫奇利（John Mauchly）和约翰·埃克特（John Presper Eckert）。他们设计的是世界上第一台通用计算机：电子数字积分计算机（The Electronic Numerical Integrator and Computer）——简称“埃尼阿克”（ENIAC）。这个庞然大物尺寸为8×3×100英寸（约合2.4米×0.9米×30米），重约三十吨，包含17,000多个电子管和1500多个继电器，运算速度比以往的任何计算机都快。冯·诺依曼很快就开始定期造访摩尔电气工程学院，并受邀参与了埃尼阿克的设计项目。埃尼阿克的研制工作进展缓慢，因此，在研制工作完成之前，军方又布置了一个任务，要求再建造一台更快的计算机。埃尼阿克的后继者称为电子离散变量自动计算机（Electronic Discrete Variable Automatic Computer）——简称“埃德瓦克”（EDVAC），约翰尼·冯·诺依曼成为了设计团队的一员。埃德瓦克的设计持续了好几个月，涉及到很多新思想和新技术。挑战主要来自两大方面，一是保存数据的存储器，需要解决的问题是，数据能否存储在某种形式的雷达甚至电视显像管里？二是指令系统，这里需要考虑的是，有哪些功能是计算机应该具备的？1945年6月，冯·诺依曼撰写了一篇文章，对摩尔学院项目团队的设计理念进行了总结。这只是一份初稿，署名作者只有他一个人，但是文章的终稿版从未出炉。戈德斯坦鼓励将初稿的内容公诸于世，因此，埃德瓦克的设计思想很快在全世界研究人员和工程师中传播开来。文章标题为“关于埃德瓦克的报告初稿”（First Draft of a Report on the EDVAC）。这是第一份系统描述计算机制造方法的公开出版物，具有划时代的革新意义。 数字大脑的解剖尽管“关于埃德瓦克的报告初稿”描述的是工程学和数学领域的研究成果，但它的遣词造句通俗而又浅显，几乎人人都能看懂。报告是冯·诺依曼1945年在火车上手写的，以下是部分摘录：我们只要分析一下这台构想中的设备应该具备哪些功能，就不难看出，该设备的核心部件应该分为几个大类。第一：由于该设备本质上是一台计算机，最起码要能够迅速地执行基本的算术运算，其中包括加法、乘法和除法。由此可见，该设备应该包含专门执行此类运算的部件……也就是说，中央算术器（central arithmetic part）或许是一个必不可缺的部件，它也构成了该设备的第一大部件，我们将其简称为CA。第二：该设备需要对不同的运算操作进行适当的排序，这一过程称 为逻辑控制。中央控制器（central control organ）可以对设备进行高效的逻辑控制……它构成了该设备的第二大部件，我们将其简称为CC。第三：任何设备要想进行长时间的复杂操作（尤其是计算操作），都需要容量相当可观的存储器（memory）……它构成了该设备的第三大部件，我们将其简称为M。……CA、CC、M这三大部件就相当于人体神经系统中的联络神经元。至于哪些部件对应于人的感觉神经元（又称传入神经元）和运动神经元（又称传出神经元），是接下来要讨论的问题。这些部件是该设备的输入装置和输出装置。值得注意的是，这个设计方案包含五大逻辑元件：第一是中央算术器，负责执行所有的运算操作；第二是中央控制器，它决定机器的下一步动作；第三是存储器，用于保存程序及程序输出的结果；第四是输入设备，比如键盘；第五是输出设备，比如打印机。 算术逻辑单元（arithmetic and logic unit，简称ALU）和寄存器（register），用冯·诺依曼的说法就是中央算术器。这个电子装置接收外界输入的电信号，并据此输出各种各样的电信号（即运算结果）。ALU的运作模式固定不变，受到布尔逻辑电路的支配。它设有临时存储区域，称为寄存器，寄存器的运作方式和存储器一样（但是访问速度要快很多），用于保存ALU和存储器输出的结果。存储器。信息以二进制编码1和0的形式存储下来，二进制编码1和0则分别由“高”、“低”两种电压转换而来。在现代计算机中，这种类型的存储器通常被称为随机存取存储器（random access memory，简称RAM）。RAM这个缩写虽然看似神秘，但它的作用其实很简单。用通俗的话来讲，它可以帮助我们直接调取任何零散的信息，不需要像磁带或纸带那样，在庞杂的信息当中大海捞针。冯·诺依曼有很多设计理念（比如采用中央存储器，以保存数据和指令）明显受到了图灵机的影响。冯·诺依曼的同事、洛斯阿拉莫斯国家实验室（Los Alamos National Laboratory）的物理学家斯坦利·弗兰克尔（Stanley Frankel）深知图灵的工作在当时的重要性。“我知道，大约在1943-1944年这段时间，冯·诺依曼非常重视图灵在1936年写的论文……他让我看看这篇论文，于是我好好研究了一下。”冯·诺依曼也很重视香农的布尔逻辑，深知这一理论的重要价值。 他在报告中写道：这台机器的一大重要方面在于，它依据的不是算术原理，而是逻辑原理。非真即假的逻辑系统从本质上讲就是一个二进制的系统。 猝不及防的结束直到1951年，埃德瓦克才被制造出来。尽管它比埃尼阿克要小，但还是安装了6000个电子管（真空管），功率高达56千瓦，需要工业空调才能保持降温。没有人赶在战争结束之前成功造出可以使用的通用计算机。事实上，冯·诺依曼和最初的设计师莫奇利和埃克特之间发生了些许不快，因为莫奇利和埃克特对他们的理念不受重视而忿忿不平，他们想将自己的设计方案申请专利，投入商业使用。冯·诺依曼放弃了埃德瓦克，转而决定在高等研究院制造一台截然不同的计算机。受到此项工作的激发，很多其他计算机被相继设计出来。约翰·冯·诺依曼在高等研 究院开展的电子计算机项目（electronic computer project，简称ECP）比此前所有的项目都更加完善，整个系统运转速度极快，可以在不出现任何错误的情况下，长时间运行数据输入量和输出量都相当可观的程序（比如氢弹试验数据计算、天气预报、人工生命模拟）。ECP的成果和设计方案得到了广泛共享。IBM当年之所以能推出商业计算机（700系列），就是因为在合作参与ECP的过程中学到了关键技术。我们现在生活在冯·诺依曼构建的世界。现代的计算机系统虽然日新月异，但万变不离其宗，大框架都是冯·诺依曼1952年在普林斯顿构建起来的。 冯·诺依曼写下关于埃德瓦克的报告后，才过两年，贝尔实验室就发明了晶体管。从理论层面讲，晶体管能做到的事情和电子管完全相同，但从实际角度讲，晶体管具有无可比拟的优越性，不仅速度快了好几倍，而且耗电量和体积也小了很多。1953年，世界上第一台晶体管计算机由曼切斯特大学研究生迪克· 格里姆斯戴尔（Dick Grimsdale）制造完成。一石激起千层浪，此后15年里，世界各地涌现了一百多台晶体管计算机。但是，第一台晶体管计算机才问世五年，电子工程师就已经面临一个严峻的问题——“数字的暴政”（tyranny of numbers）：为了提高运算能力，就必须安装更多的晶体管，但是一旦安装更多的晶体管，制造和维护成本就会增大，因为每个部件都需要手工焊接到电路板上。这个问题并没有让电子工程师困扰多久。1958年，德州仪器（Texas Instruments）公司的新职员杰克·基尔比（Jack Kilby）产生了一个革命性的想法：为什么不同时制造所有的元件呢？只要蚀刻锗晶片，就可以将电路中所有的元件都集成到一小块芯片上。几个月后，到了1959年，另一位研究人员——罗伯特·诺伊斯（Robert Noyce）也独自想出了同样的主意，只不过他使用的不是锗晶片，而是硅晶片。集成电路（integrated circuit，简称IC），也就是硅芯片就此诞生。1957年，约翰·冯·诺依曼去世，时值图灵去世三年后，硅芯片问世两年前。]]></content>
      <categories>
        <category>计算机</category>
        <category>历史</category>
      </categories>
      <tags>
        <tag>计算机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机先驱——克劳德·艾尔伍德·香农]]></title>
    <url>%2F2019%2F05%2F18%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%85%88%E9%A9%B11%2F</url>
    <content type="text"><![CDATA[Claude Elwood Shannon，1916年4月30日—2001年2月24日1936年获得密歇根大学学士学位。1940年在麻省理工学院获得硕士和博士学位，1941年进入贝尔实验室工作。美国数学家、信息论的创始人。时值1943年初，图灵正在访问他赴美之行的最后一站——贝尔实验室。他之所以来到这里，就是为了协助大西洋通信的语音加密工作（说白了就是给大西洋两岸传输的通话内容加密，这样敌人就无法监听）。不过，这次访问很快就因为另一个原因而变得收获颇丰。每天下午茶时间，图灵都会和实验室里的一位研究人员在食堂里长谈，这位研究人员名叫克劳德·香农（Claude Shannon）。两个人似乎都对计算机的问题非常热衷。图灵看问题主要从数学的视角出发，而香农的视角则完全不同。 逻辑思维香农进入贝尔电话实验室实习，学习操作自动电话交换机。实习期间，他意识到了一件重要的事情。年轻的香农发现，有两个看似截然不同的事物其实具有共同的本质。克劳德·香农回到麻省理工学院，发展他的理论新思想。那时候，他还没有和图灵见过面，图灵当时还是邱奇的学生，正在250英里（约合402公里）以外的普林斯顿大学攻读博士。两人共进午餐是六年以后的事情。 香农已经知道，数学上有一种逻辑代数系统，叫做布尔逻辑，它得名于英国数学家乔治·布尔（George Boole）。在布尔逻辑中，任何逻辑 表达式的计算结果都不是数值，而是“真”、“假”这两种真值。你只需要使用逻辑运算符“与”、“或”、“非”，就可以表达任何你想表达的逻辑语句。这个逻辑语句可以是一个英文句子，比如“在下雨且阴天或无 风的时候，我会带伞。”布尔逻辑可以让我们描述和操纵逻辑表达式，这就和我们通过数学函数来操纵数字是一样的道理（正如上一章所讲的那样，所有的数学问题都可以归结为逻辑问题）。香农取得的突破在于，他注意到，逻辑和开关电路具有共同的本质。他借鉴了布尔逻辑，并运用它来定义带有机电式继电器（电气开关）的电路。香农的理论表明，整个电路都可以用布尔逻辑表述出来，只要巧妙地运用逻辑表达式，就可以简化和改善电路设计。 也就是在这个时候，人们开始着手制造世界上第一台电子计算机。由此可见，只要能够运用逻辑数学表达式设计出简洁而高效的电路，就能创造巨大的实用价值。由于所有的数学问题都可以归结为逻辑问题，而逻辑问题又可以通过电气开关表现出来，香农的理论表明，人们可以设计专门的电机，用来计算任何可计算的数学函数。 香农决定将他的思想写成研究报告发表出来，研究报告的题目是“继电器和开关电路的符号分析”（A Symbolic Analysis of Relay and Switching Circuits）。这项成果给计算机科学领域带来了重大突破。香农很快以此为基础，完成了他在麻省理工学院的硕士论文。这篇论文受到了广泛的赞誉，人们说它“或许是本世纪最重要、也最有名的硕士论文”。24岁时，香农写了一篇博士论文，从代数学的角度描述遗传学和进化论。毕业后，他作为国家研究员（National Research Fellow），在声名远播的普林斯顿高等研究院（Institute for Advanced Study，简称IAS）工作了一年。在那里，他接触到了一些世界上最顶尖的人才，其中包括赫尔曼·外尔（Hermann Weyl）、阿尔伯特·爱因斯坦、库尔特·哥德尔和约翰·冯·诺依曼（John von Neumann）。1941年，香农进入贝尔电话实验室，继续扩充自己的理论思想。两年后，在贝尔实验室的食堂，图灵在与香农交谈的过程中大为振奋——他的声音不由自主地越来越大，引起周围的人纷纷侧目。香农的话让他看到了希望曙光——图灵机或许真的可以变成现实！临走前，图灵买了一本电路入门书，把它带到回国的船上，在危险四伏的海上航程中如饥似渴地阅读起来。 其他贡献香农理论的重要特征是熵（entropy）的概念，他证明熵与信息内容的不确定程度有等价关系。熵曾经是波尔兹曼在热力学第二定律引入的概念，我们可以把它理解为分子运动的混乱度。信息熵也有类似意义，例如在中文信息处理时，汉字的静态平均信息熵比较大，中文是9.65比特，英文是4.03比特。这表明中文的复杂程度高于英文，反映了中文词义丰富、行文简练，但处理难度也大。信息熵大，意味着不确定性也大。 众所周知，质量、能量和信息量是三个非常重要的量。 人们很早就知道用秤或者天平计量物质的质量，而热量和功的关系则是到了19世纪中叶，随着热功当量的明确和能量守恒定律的建立才逐渐清楚。能量一词就是它们的总称，而能量的计量则通过“卡、焦耳”等新单位的出现而得到解决。然而，关于文字、数字、图画、声音的知识已有几千年历史了。但是它们的总称是什么，它们如何统一地计量，直到19世纪末还没有被正确地提出来，更谈不上如何去解决了。20世纪初期，随着电报、电话、照片、电视、无线电、雷达等的发展，如何计量信号中信息量的问题被隐约地提上日程。 1928年哈特利（R.V. H. Harley）考虑到从D个彼此不同的符号中取出N个符号并且组成一个“词”的问题。如果各个符号出现的概率相同，而且是完全随机选取的，就可以得到D^N个不同的词。从这些词里取了特定的一个就对应一个信息量I。哈特利建议用NlogD这个量表示信息量，即I=NlogD。这里的log表示以10为底的对数。后来，1949年控制论的创始人维纳也研究了度量信息的问题，还把它引向热力学第二定律。但是就信息传输给出基本数学模型的核心人物还是香农。1948年香农长达数十页的论文“通信的数学理论”成了信息论正式诞生的里程碑。在他的通信数学模型中，清楚地提出信息的度量问题，他把哈特利的公式扩大到概率Pi不同的情况，得到了著名的计算信息熵H的公式： H=-&sum;PilogPi 如果计算中的对数log是以2为底的，那么计算出来的信息熵就以比特（bit）为单位。在计算机和通信中广泛使用的字节（Byte）、KB、MB、GB等词都是从比特演化而来。“比特”的出现标志着人类知道了如何计量信息量。香农的信息论为明确什么是信息量概念作出决定性的贡献。香农在进行信息的定量计算的时候，明确地把信息量定义为随机不定性程度的减少。这就表明了他对信息的理解：信息是用来减少随机不定性的东西。或香农逆定义：信息是确定性的增加。]]></content>
      <categories>
        <category>计算机</category>
        <category>历史</category>
      </categories>
      <tags>
        <tag>计算机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机先驱——艾伦·麦席森·图灵]]></title>
    <url>%2F2019%2F05%2F17%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%85%88%E9%A9%B1%2F</url>
    <content type="text"><![CDATA[Alan Mathison Turing，1912年6月23日－1954年6月7日1931年图灵进入剑桥大学国王学院，毕业后到美国普林斯顿大学攻读博士学位英国数学家、逻辑学家，被称为计算机科学之父，人工智能之父。 谜题关于数学漏洞的问题，我给大家举个例子。剑桥有位数学家——伯特兰·罗素（Bertrand Russell）发现了一个数学漏洞。此前罗素的工作已经取得了巨大的成功——他证明了所有数学问题都可以还原为逻辑问题，也就是说，所有数学发现都可以用逻辑表达式重新写出来。 这项工作是伟大的，因为它有助于我们了解数学赖以建立的所有基本真理。但是后来，罗素发现了一个问题。他发现了一个悖论——也就是看起来既正确又不正确的论断。数学家经常寻找悖论，因为你如果觉得某件事情既正确又不正确，那么你的想法肯定有漏洞。所以，通过这种方法可以将很多想法证伪。相比之下，罗素悖论的性质要严重许多，因为它似乎预示着，整个数学体系是有漏洞的。罗素悖论给我们出的难题是： 假设有一个集合A，它的所有子集都具有一个共同的性质P——它们不包含自身。问题是：集合A是否包含自身？ 首先，若A包含自身，则A是A的子集，那么A具有性质P，由性质P知A不包含A；其次，若A不包含A，也就是说A具有性质P，而A是由所有具有性质P的集合组成的，所以A包含A。就像理发师悖论一样，唯一说得通的解法是，集合A既包含自身，又不包含自身。这在逻辑上是不可能的。罗素悖论的提出之所以让数学家如临大敌，是因为它预示着数学的理论基础存在漏洞。几个世纪以来，数学思想和证明无不建立在一系列的基本真理之上。连加法和减法的运算法则都是运用集合和逻辑学加以证明的。但是罗素悖论表明，任何数学证明都不再可信。 罗素悖论还只是这一切的开端。1931年，在图灵攻读高级课程的四年前，有位数学家一劳永逸地证明了数学体系必定是不完备的。他的名 字叫库尔特·哥德尔（Kurt Gödel）。哥德尔的第一条定理可以通过类似的方式表述出来：G＝“本命题不可以由理论T证明。”如果命题G事实上可以由理论T证明，则理论T中存在一个自相矛盾的定理G，既然有自相矛盾的地方，那么理论T就是不完备的。也就是说，T要是完备的理论，就不可以证明G，但是这样一来，T就有证明不了的命题，也称不上是完备的理论了。于是，G所指的内容就是真的：G既无法得到证明，但又是真命题。由此可见，有些事物不管能否得到证明，都可以为真。 图灵在学校也学到了一个与此相关的前沿思想。这是由德国数学家大卫·希尔伯特（DavidHilbert）在1928年提出的挑战。这项挑战称为“判定问题”（Entscheidungs problem）。希尔伯特想知道的是，一个命题的真假能否自动判定。他的问题是，对于给定的数学语言，有没有什么方法或者程序可以让机器判定某件事情的真假，并将结果显示出来。虽然这听起来颇为实用，但真正的挑战在于：这种自动化的方法或机器是否有可能存在？自动判定简单的句子似乎并不是遥不可及的事情，但如果是用复杂的数学语言写成的高难度句子，是否仍有可能加以判定？这种万能的真理说明者是否真有可能存在？ 永不停机的图灵机当时没有任何机器能做到这一点，于是图灵构想了一台能做到这一点的机器。他想象的是一台理论计算机。一台能从纸带上读取信息的机器。根据即时读取的指令，机器可以将纸带左移、右移，或在纸带上读取信息、输出结果。虽然这台奇怪的新机器终究只是纸上谈兵的假想机，但是这已经足够了，因为图灵只是想从理论上解决希尔伯特提出的问题而已。或许颇具讽刺意味的是，图灵虽然提出了关于通用计算机的思想，但却并不急着证明他的机器可以解决判定问题。相反，他想证明判定问题不可能得到解决，进而说明有些问题在数学上根本不可判定。为了做到这一点，图灵首先假想他的小计算机正在根据纸带上的信号执行一个运算，接着他提出了一个问题：有没有什么方法可以判断这 台机器究竟是会陷入死循环，不停地计算下去；还是会停止计算，给出结果呢？ 图灵认为，要想判断他的机器会不会停机，那就需要再构造一台图灵机，以对第一台机器进行检测，因为他知道，他假想的机器在理论上 可以进行任何数学运算。于是他假想出第二台图灵机，如果检测到第一台图灵机永不停机，那么第二台机器就会停机，然后输出“不停机”；如 果检测到第一台图灵机停了机，那么第二台机器就会一直运转下去。现在，脑筋急转弯的地方来了。假如第二台机器反观自身，判断自己会不会停止计算，那会发生什么情况？图灵对此进行了设想，他突然发现了一个悖论：如果机器检测到自己会永不停机，那么它就会停机，然后输出“不停机”；如果机器检测到自己停了机，那么它就会一直运转下去。这在逻辑上是不可能的，由此证明，有些图灵机是不可判定的——我们永远也无法判断它们会不会停机。 顺便说一下，图灵当时设计这个图灵机，完全只是为了辅助他证明这个问题而已，这个机器是假想的，不存在的就像画一条辅助线。可是后来他又发现，虽然这个机器不能解决所有的问题，但确实能够解决很多问题，而且真的是可以造出来的。于是…… 图灵就成为了“计算机科学之父”。 P是否等于NP？P和NP指的是两种类型的问题，它们的计算复杂度各不相同。P类问题可以通过多项式时间算法解决。换句话说，凡是可以用O（n^x）算法解决的问题都是P类问题，不管这里的x是什么。排序问题就是典型的P类问题。就算是最好的排序算法，它的时间复杂度在最坏的情况下也是O（n^2），符合多项式关系，因此排序问题属于P类问题。对于NP类问题，我们可以在多项式时间内检验候选解是否正确，但是求解所需要的时间却会漫长许多——而且往往是指数时间。在已知量较小的情况下，所有这些问题乍看之下都很好解决，但是，一旦已知量的数量级增大，比如配送车穿行的城市增加到一百个、装箱的行李数量增加到五百个、硬币的数量限制增加到一百个，那么求解所需要的时间就会呈指数式增长。因此，P是否等于NP的问题实际上是在问：难度很大的NP类问题究竟能否用多项式算法求解？我们现在采用的算法是不是太愚蠢了，就像慢速排序那样？能不能找到像快速排序这种聪明的解法，让原本很难的问题一下子迎刃而解？ 显然，NP类问题很难解决，但早在1936年，图灵对如此艰涩的难题就已经有了自己的思考方法。思考NP类问题的方法之一，就是构造一台特殊的图灵机，称为非确定型图灵机（non-deterministic Turing Machine）。如果我们可以制造出这样的机器，就可以让它在多项式时间内运行NP类问题。之所以称之为非确定型，就是因为我们无法预测它的运作方式，但它总能找到最快的方法解决问题。试想你在干草堆里寻找一根针。你立马就能分辨出自己看到的是一棵干草还是一根针，但是从哪里寻找却是一个很大的问题。你有很大的选择空间，但问题是：“怎样做出选择才能让我找到解法？”非确定型图灵机的道理与之大同小异。它的问题是：“是否存在某种特定的指令，可以使我成功求解？”如果这样的指令存在，那么它就会惊呼“太好了！”然后遵照指令，在最快的时间内找到解法。如果这样的指令不存在，那么它就会唏嘘“太可惜了”，然后停止运转。至于这类聪明的图灵机是如何判断出解题方法的，这一点在某种程度上讲还是个迷。对此，人们设想了两种情况。第一，答案已经摆在那里了。这就好比你有一块魔镜，它无所不知，每次都会告诉你：这是最好的选择。第二，可以采用某种平行或并行操作，也就是说，这类非确定型图灵机所做的，其实就是同时运行所有可能的选择。 这些奇怪的思想是由图灵等业界先驱同时提出的，它们历经发展演进，为一个新的理论研究领域提供了肥沃的土壤，这个研究领域叫做可计算性理论（有时又称为递归论）。 总结可计算性理论以及图灵机图灵先知先觉，在电子计算机远未问世之前，他已经想到所谓“可计算性”的问题。物理学家阿基米得曾宣称:“给我足够长的杠杆和一个支点，我就能撬动地球。”类似的问题是，数学上的某些计算问题，是不是只要给数学家足够长的时间，就能够通过“有限次”的简单而机械的演算步骤而得到最终答案呢？这就是所谓“可计算性”问题，一个必须在理论上做出解释的数学难题。 “图灵机”是一个虚拟的“计算机”，完全忽略硬件状态，考虑的焦点是逻辑结构。图灵在他那篇著名的文章里，还进一步设计出被人们称为“通用图灵机”的模型，它可以模拟其他任何一台解决某个特定数学问题的“图灵机”的工作状态。他甚至还想象在带子上存储数据和程序。“通用图灵机”实际上就是现代通用计算机的最原始的模型。不过图灵在提出图灵机构想之后，又发现了新问题，有些问题图灵机是无法计算的。比如定义模糊的问题，如“人生有何意义”，或者缺乏数据的问题，“明天3D中奖号是多少”，其答案当然是无法计算出来的。但也有一些定义完美的计算问题，它们亦是不可解的，这类问题称为不可计算问题。不可计算的问题在践中几乎碰不到，事实上，很难找到这样的例子，既不可计算但又有人向计算的明确定义的问题。一个罕见的问题是所谓的停机问题。 图灵机的意义图灵提出图灵机的模型并不是为了给出计算机的设计，它的意义我认为有如下几点：1.它证明了通用计算理论，肯定了计算机实现的可能性，同时它给出了计算机应有的主要架构；2.图灵机模型引入了读写与算法与程序语言的概念，极大的突破了过去的计算机器的设计理念；3.图灵机模型理论是计算学科最核心的理论，因为计算机的极限计算能力就是通用图灵机的计算能力，很多问题可以转化到图灵机这个简单的模型来考虑。对图灵机给出如此高的评价并不是高估，因为从它的设计与运行中，我们可以看到其中蕴涵的很深邃的思想。通用图灵机等于向我们展示这样一个过程：程序和其输入可以先保存到存储带上，图灵机就按程序一步一步运行直到给出结果，结果也保存在存储带上。另外，我们可以隐约看到现代计算机主要构成（其实就是冯诺依曼理论的主要构成），存储器（相当于存储带），中央处理器（控制器及其状态，并且其字母表可以仅有0和1两个符号），IO系统（相当于存储带的预先输入）；]]></content>
      <categories>
        <category>计算机</category>
        <category>历史</category>
      </categories>
      <tags>
        <tag>计算机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdowm空格缩进、多层嵌套]]></title>
    <url>%2F2019%2F05%2F17%2Fmarkdowm%E7%A9%BA%E6%A0%BC%E7%BC%A9%E8%BF%9B%2F</url>
    <content type="text"><![CDATA[空格缩进 一个空格表示：&amp;ensp;或&amp;#8194; 两个空格表示：&amp;emsp;或&amp;#8195; 不换行空格：&amp;nbsp;或&amp;#160; 多层嵌套效果： 第一层 第二层 &amp;alpha; &amp;acute; 代码： 12345&gt; 第一层&gt;&gt; 第二层&gt;&gt; &gt;&gt; &amp;alpha;&gt;&gt; &amp;acute;]]></content>
      <categories>
        <category>书写方法</category>
      </categories>
      <tags>
        <tag>markdowm书写方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F05%2F14%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
